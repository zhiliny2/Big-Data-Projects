{"cells": [{"cell_type": "code", "execution_count": null, "id": "ef1ed6bf-e74d-41ee-9d1c-4292e3ad6858", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 1, "id": "a501d176-12de-430a-b7b8-d9f1f9421235", "metadata": {}, "outputs": [], "source": "import os\nimport subprocess\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as F"}, {"cell_type": "code", "execution_count": 2, "id": "1e601f02-fa0f-4054-8ca8-6668beb7737d", "metadata": {}, "outputs": [], "source": "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"}, {"cell_type": "code", "execution_count": 3, "id": "2a8cd389-a12e-40d9-b2f1-89d6db802954", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "22/12/08 03:01:33 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"}], "source": "clean_data = spark.read.parquet('gs://msca-bdp-students-bucket/shared_data/zhiliny/final_project4')"}, {"cell_type": "code", "execution_count": 4, "id": "33fcdc5b-3862-43f4-b97d-b39db6df1706", "metadata": {}, "outputs": [], "source": "clean_data = clean_data.drop\\\n('follower_count','favorite_count')"}, {"cell_type": "code", "execution_count": 5, "id": "f2ae2862-1b24-4626-91e0-bf7df2126b81", "metadata": {}, "outputs": [], "source": "cleandata1 = clean_data.withColumn('description',clean_data.user['description'])\ncleandata1 = cleandata1.withColumn('verified_user',clean_data.user['verified']).\\\n                        withColumn('follower_counted',clean_data.user['followers_count'])\n\n# cleandata1.limit(1).toPandas()"}, {"cell_type": "code", "execution_count": 6, "id": "cc79e623-b73f-4925-b306-fdda606b3660", "metadata": {}, "outputs": [], "source": "## Categorize the Twitterers' organizations by searching the keywords\n## If the follower count is larger than 10000, I categorize the user as a 'social media Influncer'\ngovernment_entities=['[Gg]overnment','[Ss]tate','[Ff]ederal','[Cc]ongress','[Ss]enate','[Ss]enator',\n                    '[Cc]ongressman','[Cc]ongresswoman','[Mm]ayor']\nuniversities=['[Uu]niversit(y)?(ies)?','[Cc]olleg(e)?(es)','[Hh]igher [Ed]ucation','[Aa]cadamy','[Ii]nstitution']\nschools=['[Ss]chool(s)?','[Pp]rimary [Ss]chool', '[Ss]econdary [Ss]chool','[Hh]igh [Ss]chool']\nnonprofit_organizations = ['[Nn]onprofit','NGO','[Ff]oundation(s)?','[Nn]onprofit [Oo]rganization(s)?']\nnews_outlets=['[Nn]ewsletter(s)?','[Nn]ewspaper(s)?','[Jj]ournal(s)?','[Nn]ews']\nsocial_media=['[Ff]acebook','[Ii]nstagram','[Ss]ocial [Mm]edia']\n\ncleandata1 = cleandata1.withColumn('Twitterer_category',\\\n                    when(cleandata1.description.rlike('|'.join(government_entities)),'Government').\\\n                    when(cleandata1.description.rlike('|'.join(universities)),'Universities').\\\n                    when(cleandata1.description.rlike('|'.join(schools)),'Schools').\\\n                    when(cleandata1.description.rlike('|'.join(nonprofit_organizations)),'Nonprofit').\\\n                    when(cleandata1.description.rlike('|'.join(news_outlets)),'News').\\\n                    when(cleandata1.follower_counted>=10000,'Influencer').\\\n                    otherwise('Someone else'))"}, {"cell_type": "code", "execution_count": 7, "id": "ba286480-edf6-4d46-b9c4-b438765dc8c1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]\n3.1.3\n"}], "source": "import sys\nprint(sys.version)\nprint(spark.version)"}, {"cell_type": "code", "execution_count": 8, "id": "c69b6a19-b94d-4387-8a1a-ade2e93c9210", "metadata": {}, "outputs": [], "source": "import pandas as pd\nimport numpy as np\npd.set_option('display.max_colwidth', None)\npd.reset_option('display.max_rows')\nfrom itertools import compress \nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings(action='ignore')"}, {"cell_type": "code", "execution_count": 9, "id": "651b56e9-f034-4c99-b949-b6c39cd02fc3", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found existing installation: nltk 3.7\nUninstalling nltk-3.7:\n  Successfully uninstalled nltk-3.7\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m"}], "source": "!pip uninstall -y nltk"}, {"cell_type": "code", "execution_count": 10, "id": "63e98cf4-696e-4cdd-81c7-7f1fd1b9988c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Collecting nltk\n  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /opt/conda/miniconda3/lib/python3.8/site-packages (from nltk) (2022.10.31)\nRequirement already satisfied: click in /opt/conda/miniconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\nRequirement already satisfied: joblib in /opt/conda/miniconda3/lib/python3.8/site-packages (from nltk) (1.2.0)\nRequirement already satisfied: tqdm in /opt/conda/miniconda3/lib/python3.8/site-packages (from nltk) (4.64.1)\nInstalling collected packages: nltk\nSuccessfully installed nltk-3.7\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m"}], "source": "!pip install nltk --upgrade --no-cache-dir"}, {"cell_type": "code", "execution_count": 11, "id": "8c6531ca-fb2f-47a3-8736-bdd536e2e4d8", "metadata": {}, "outputs": [], "source": "import nltk"}, {"cell_type": "code", "execution_count": 12, "id": "61ab137f-c5f9-4e91-9df0-68ea4b9be830", "metadata": {}, "outputs": [], "source": "# import os\nimport shutil\nimport pandas as pd\n# import sh\nfrom pyspark.sql.functions import *\n#from pyspark.sql import functions as F\nfrom pyspark.sql.types import *\n\nimport os\nimport subprocess\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\n# import pyspark.sql.functions as F"}, {"cell_type": "code", "execution_count": 13, "id": "21124912-1fb5-4b3b-b6e8-394eb56316a2", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"}], "source": "import re\nfrom pyspark.ml.feature import MinHashLSH\nfrom pyspark.ml.feature import CountVectorizer,  IDF, CountVectorizerModel, Tokenizer, RegexTokenizer, StopWordsRemover\nfrom pyspark import SparkContext\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql import Row\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords"}, {"cell_type": "code", "execution_count": 14, "id": "5c04b6e2-ec34-4c10-8a64-92050ef10a75", "metadata": {}, "outputs": [], "source": "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"}, {"cell_type": "markdown", "id": "657f2388-1c90-412f-9b87-dabc763ecc7a", "metadata": {}, "source": "split the text by twitterers"}, {"cell_type": "code", "execution_count": 15, "id": "6653b5bd-c411-48d8-bfc6-2cb909d803ef", "metadata": {}, "outputs": [], "source": "government_entities = cleandata1.filter((col('Twitterer_category') == 'Government')&(cleandata1.retweeted !='RT')&(cleandata1.text.isNotNull()))\nuniversities = cleandata1.filter((col('Twitterer_category') == 'Universities')&(cleandata1.retweeted !='RT')&(cleandata1.text.isNotNull()))\nschools = cleandata1.filter((col('Twitterer_category') == 'Schools')&(cleandata1.retweeted !='RT')&(cleandata1.text.isNotNull()))\nnonprofit_organizations = cleandata1.filter((col('Twitterer_category') == 'Nonprofit')&(cleandata1.retweeted !='RT')&(cleandata1.text.isNotNull()))\nnews_outlets = cleandata1.filter((col('Twitterer_category') == 'News')&(cleandata1.retweeted !='RT')&(cleandata1.text.isNotNull()))\nsocial_media_influencer = cleandata1.filter(col('Twitterer_category') == 'Influencer')"}, {"cell_type": "code", "execution_count": 16, "id": "b0ba26c2-eb76-43b8-807f-f583c0058529", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<table border='1'>\n<tr><th>text</th></tr>\n<tr><td>@Joediesel84 @don...</td></tr>\n<tr><td>@POTUS Did you ev...</td></tr>\n<tr><td>@Equityoyo Is Tin...</td></tr>\n<tr><td>@titilopegb We he...</td></tr>\n<tr><td>@TheRabbitHole84 ...</td></tr>\n</table>\n", "text/plain": "+--------------------+\n|                text|\n+--------------------+\n|@Joediesel84 @don...|\n|@POTUS Did you ev...|\n|@Equityoyo Is Tin...|\n|@titilopegb We he...|\n|@TheRabbitHole84 ...|\n+--------------------+"}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": "gov = government_entities.select([\"text\"])\ngov.limit(5)\n# gov = government_entities.select([\"text\"])"}, {"cell_type": "markdown", "id": "4f27465e-a578-458d-8c90-b01c4a15ceb1", "metadata": {}, "source": "#### Similarity Analysis on Twitters from government entities"}, {"cell_type": "code", "execution_count": 17, "id": "49f26e65-4bee-4f06-8ac8-d789090ec57c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "text = gov.rdd.map(lambda x : x['text']).filter(lambda x: x is not None)\n\nStopWords = stopwords.words(\"english\")\n\ntokens = text\\\n    .map( lambda document: document.strip().lower())\\\n    .map( lambda document: re.split(\" \", document))\\\n    .map( lambda word: [x for x in word if len(x) > 1] )\\\n    .zipWithIndex()"}, {"cell_type": "code", "execution_count": 18, "id": "362db387-6d8f-421c-961f-0ba35a2c1105", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "row = Row('text')\ntext_df=text.map(row).zipWithIndex().toDF(['text','id'])\n# text_df.limit(5)"}, {"cell_type": "code", "execution_count": 19, "id": "d640c22e-ccbe-4d74-9c5e-d3efe9ae1e84", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>list_of_words</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[@joediesel84, @donniepcouncil, @jenv9971, all, you, learn, at, school, now, is, racism, and, perversion]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[@potus, did, you, ever, vote, to, keep, african, americans, out, of, white, schools?, maybe, this, seems, disingenuous,, knowing\u2026, https://t.co/nnnzh6qobz]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[@equityoyo, is, tinubu, well, before, what, is, his, source, of, wealth, which, primary, and, secondary, school, did, he, attend\u2026, https://t.co/7usm97yhxe]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[@titilopegb, we, heard, about, tinubu, not, being, able, to, trace, his, ancestral, origin,, no, records, of, his, school, certificat\u2026, https://t.co/1vipcvqbcm]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[@therabbithole84, @monsoonsharma, don't, worry, colleges, are, actively, trying, to, hold, asians, back, under, the, guise, of, inclusiveness.]</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                                                                                                                                       list_of_words  \\\n0                                                          [@joediesel84, @donniepcouncil, @jenv9971, all, you, learn, at, school, now, is, racism, and, perversion]   \n1       [@potus, did, you, ever, vote, to, keep, african, americans, out, of, white, schools?, maybe, this, seems, disingenuous,, knowing\u2026, https://t.co/nnnzh6qobz]   \n2       [@equityoyo, is, tinubu, well, before, what, is, his, source, of, wealth, which, primary, and, secondary, school, did, he, attend\u2026, https://t.co/7usm97yhxe]   \n3  [@titilopegb, we, heard, about, tinubu, not, being, able, to, trace, his, ancestral, origin,, no, records, of, his, school, certificat\u2026, https://t.co/1vipcvqbcm]   \n4                   [@therabbithole84, @monsoonsharma, don't, worry, colleges, are, actively, trying, to, hold, asians, back, under, the, guise, of, inclusiveness.]   \n\n   id  \n0   0  \n1   1  \n2   2  \n3   3  \n4   4  "}, "execution_count": 19, "metadata": {}, "output_type": "execute_result"}], "source": "df_tokens = spark.createDataFrame(tokens, [\"list_of_words\",'id'])\n\n#Drop records with no tokens\ndf_tokens = df_tokens.where(col('list_of_words').getItem(0).isNotNull())\ndf_tokens.limit(5).toPandas()"}, {"cell_type": "code", "execution_count": 20, "id": "bdccbca8-1402-4673-99f3-4f9b8d8bc8d2", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "vectorize = CountVectorizer(inputCol=\"list_of_words\", outputCol=\"features\", minDF=1.0)\ndf_vectorize = vectorize.fit(df_tokens).transform(df_tokens)"}, {"cell_type": "code", "execution_count": 21, "id": "26eedbd8-d3f6-481f-b6c5-2f3796ad6c37", "metadata": {}, "outputs": [], "source": "mh = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", numHashTables=5)\nmodel = mh.fit(df_vectorize)\ndf_hashed = mh.fit(df_vectorize).transform(df_vectorize)"}, {"cell_type": "code", "execution_count": 22, "id": "82534532-303d-414b-827d-8229b85f149a", "metadata": {}, "outputs": [], "source": "df_hashed_text = text_df.join(df_hashed, \"id\", how = 'left')"}, {"cell_type": "markdown", "id": "90175350-574e-422b-9558-b838f4ba78a9", "metadata": {}, "source": "#### I choose Medium Jaccard Distance 0.5 as my Jaccard Distance"}, {"cell_type": "code", "execution_count": 23, "id": "5627f68c-33a3-42dd-be5e-df5f4b3e91f3", "metadata": {}, "outputs": [], "source": "jaccard_distance = 0.5\n\ndf_dups_text_30 = model.approxSimilarityJoin(df_hashed_text, df_hashed_text, jaccard_distance).filter(\"datasetA.id < datasetB.id\").select(\n            col(\"distCol\"),\n            col(\"datasetA.id\").alias(\"id_A\"),\n            col(\"datasetB.id\").alias(\"id_B\"),\n            col('datasetA.text').alias('text_A'),\n            col('datasetB.text').alias('text_B'),\n#             col('datasetA.list_of_words').alias('words_A'),\n#             col('datasetB.list_of_words').alias('words_B')\n            )"}, {"cell_type": "code", "execution_count": 24, "id": "f5420cac-771b-4d8d-9d12-5e2dda25c555", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distCol</th>\n      <th>id_A</th>\n      <th>id_B</th>\n      <th>text_A</th>\n      <th>text_B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.470588</td>\n      <td>2863</td>\n      <td>7631</td>\n      <td>(Dem-Appointed New York Judge Unravels Liberal Plot to Racialize School Admissions \\nhttps://t.co/V5RhJFxCeh\\nhttps://t.co/V5RhJFxCeh,)</td>\n      <td>(Dem-Appointed NY Judge Unravels Liberal Plot To Racialize School Admissions With Just Four\u00a0Sentences https://t.co/wiDT6Q0HDi,)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.363636</td>\n      <td>1277</td>\n      <td>5756</td>\n      <td>(@Nicoletta0602 @stevetallent @JaeDog105 @EvanMcGuireUSA @riverotter1968 @gracialivie @DeAngelisCorey @PaulVallas\u2026 https://t.co/PG70Wshh9k,)</td>\n      <td>(@RobbCab @Nicoletta0602 @EvanMcGuireUSA @stevetallent @riverotter1968 @gracialivie @DeAngelisCorey @PaulVallas\u2026 https://t.co/6x4LzAkdYQ,)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.105263</td>\n      <td>1451</td>\n      <td>2271</td>\n      <td>(Moms for Liberty is demanding this man resign his position as a high school teacher - for teaching African American\u2026 https://t.co/Z2FQ9EvICQ,)</td>\n      <td>(Moms for Liberty is demanding this man resign his position as a high school teacher - for teaching African American\u2026 https://t.co/UqXtPtiI2w,)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.105263</td>\n      <td>4704</td>\n      <td>6447</td>\n      <td>(Moms for Liberty is demanding this man resign his position as a high school teacher - for teaching African American\u2026 https://t.co/vjU0DEGrF0,)</td>\n      <td>(Moms for Liberty is demanding this man resign his position as a high school teacher - for teaching African American\u2026 https://t.co/I2o4rdz6Hd,)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.363636</td>\n      <td>2746</td>\n      <td>5756</td>\n      <td>(@Nicoletta0602 @stevetallent @JaeDog105 @EvanMcGuireUSA @riverotter1968 @gracialivie @DeAngelisCorey @PaulVallas\u2026 https://t.co/TW6TmnAsFY,)</td>\n      <td>(@RobbCab @Nicoletta0602 @EvanMcGuireUSA @stevetallent @riverotter1968 @gracialivie @DeAngelisCorey @PaulVallas\u2026 https://t.co/6x4LzAkdYQ,)</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "    distCol  id_A  id_B  \\\n0  0.470588  2863  7631   \n1  0.363636  1277  5756   \n2  0.105263  1451  2271   \n3  0.105263  4704  6447   \n4  0.363636  2746  5756   \n\n                                                                                                                                            text_A  \\\n0          (Dem-Appointed New York Judge Unravels Liberal Plot to Racialize School Admissions \\nhttps://t.co/V5RhJFxCeh\\nhttps://t.co/V5RhJFxCeh,)   \n1     (@Nicoletta0602 @stevetallent @JaeDog105 @EvanMcGuireUSA @riverotter1968 @gracialivie @DeAngelisCorey @PaulVallas\u2026 https://t.co/PG70Wshh9k,)   \n2  (Moms for Liberty is demanding this man resign his position as a high school teacher - for teaching African American\u2026 https://t.co/Z2FQ9EvICQ,)   \n3  (Moms for Liberty is demanding this man resign his position as a high school teacher - for teaching African American\u2026 https://t.co/vjU0DEGrF0,)   \n4     (@Nicoletta0602 @stevetallent @JaeDog105 @EvanMcGuireUSA @riverotter1968 @gracialivie @DeAngelisCorey @PaulVallas\u2026 https://t.co/TW6TmnAsFY,)   \n\n                                                                                                                                            text_B  \n0                  (Dem-Appointed NY Judge Unravels Liberal Plot To Racialize School Admissions With Just Four\u00a0Sentences https://t.co/wiDT6Q0HDi,)  \n1       (@RobbCab @Nicoletta0602 @EvanMcGuireUSA @stevetallent @riverotter1968 @gracialivie @DeAngelisCorey @PaulVallas\u2026 https://t.co/6x4LzAkdYQ,)  \n2  (Moms for Liberty is demanding this man resign his position as a high school teacher - for teaching African American\u2026 https://t.co/UqXtPtiI2w,)  \n3  (Moms for Liberty is demanding this man resign his position as a high school teacher - for teaching African American\u2026 https://t.co/I2o4rdz6Hd,)  \n4       (@RobbCab @Nicoletta0602 @EvanMcGuireUSA @stevetallent @riverotter1968 @gracialivie @DeAngelisCorey @PaulVallas\u2026 https://t.co/6x4LzAkdYQ,)  "}, "execution_count": 24, "metadata": {}, "output_type": "execute_result"}], "source": "df_dups_txt_30 = df_dups_text_30\n# df_dups_text_30.cache()\ndf_dups_text_30.limit(5).toPandas()"}, {"cell_type": "code", "execution_count": 25, "id": "524c2fe9-ef87-4990-a9a7-2d7ce1947c7d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 47:======================================================> (34 + 1) / 35]\r"}, {"name": "stdout", "output_type": "stream", "text": "Total records:  7983\nDuplicate titles based on { 0.5 } jaccard distance:  712\nUnique titles based on { 0.5 } jaccard distance:  0.5 :  7271\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "records = df_hashed_text.count()\ndups_30 = df_dups_text_30.select('id_A').distinct().count()\nuniques = records - dups_30\n\nprint ('Total records: ', records)\nprint ('Duplicate titles based on {', jaccard_distance, '} jaccard distance: ', dups_30)\nprint ('Unique titles based on {', jaccard_distance, '} jaccard distance: ', jaccard_distance, ': ', uniques)"}, {"cell_type": "code", "execution_count": 26, "id": "4ae73d32-ccb4-4afb-bb88-0958de9bdf64", "metadata": {}, "outputs": [{"data": {"image/png": "iVBORw0KGgoAAAANSUhEUgAAAvMAAAHECAYAAAC0kqVfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAABuPUlEQVR4nO3deXwN9/4/8NfJdrKfSMhGSErs+3IjtlCRWIKgtpDSqqVVpCjV6m263Ljc1tJq3VJF7W2/5dJqGntprCH2orWTCJWcCJH1/fvD70ydnJMNEROv5+NxHmTmMzOfmTkz8zqfM+czGhEREBERERGR6liUdwWIiIiIiOjhMMwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBM9RS5cuACNRoOOHTuWWx00Gg18fX2Nhj0N9SqMufpS0cpjm/n6+kKj0ZTpMtLS0uDm5obBgwcbDV+6dCk0Gg2GDx9epstXm+joaGg0GixdurRE5Q3ngQdfWq0W7u7uaNGiBUaPHo3NmzejsAfLP83nETX68ccfERQUBJ1OB2dnZwQFBeHHH38s9XwM74PCXm+99ZbJNBMmTICdnR0uXbr0UHXfvHkz2rVrBycnJ2U5T5LhnFCaV3R09BOtY2lYlXcF6OkwfPhwLFu2DNu3by/1idbX1xcXL14s9ASuFjt27ECnTp0wbNiwEl/cqGxxn1Bp/Otf/0JaWhrefffd8q5Khebg4IAXXngBAJCXl4e0tDQcP34cCxcuxMKFC9GiRQusWrUKtWvXfuzLjo6Oxvvvv48lS5Y80x/OPv30U0yYMAFWVlYIDg6GVqtFXFwcevbsiXnz5mH8+PGlnmfbtm1Rq1Ytk+EtWrQwGfbWW29h4cKFmD59Or755ptSLefSpUvo06cPsrOzERwcDHd391LX9VHVqlULw4YNMxm+bNkyAEC/fv3g6OhoNK5p06ZlVp+lS5fipZdewnvvvfdQHxoY5omoWFWrVsWpU6dgb29f3lUxcerUKVhbW5d3NagYW7duRU5OTpnNPykpCZ999hl69eqF+vXrl9lyCKhcubLZD9dHjhzBxIkTsW3bNnTo0AEHDhyAj4+PMv5pPo+oyZkzZzBp0iRotVps374dgYGByvA2bdpg0qRJ6NatG/z9/Us131deeaXEH5C8vLwwbNgwLFy4EFOnTkWDBg1KvJwtW7bgzp07ePfdd/HBBx+Uqo6PS7t27dCuXTuT4YYw//HHH6vqG1/eZkNExbK2tkbdunVRvXr18q6Kibp166JmzZrlXQ0qRs2aNVG3bt0ym//XX3+NrKwsvPjii2W2DCpakyZNEBcXh5CQEFy/fh0TJkwwGv80n0fUZN68ecjNzcWYMWOUIA8AtWvXxjvvvIPc3Fx8+umnZV6PoUOHQkTw5Zdflmq6K1euAACee+65sqjWs0kewtq1a6Vly5Zia2sr7u7uMnz4cElOTpZhw4YJANm+fbvJNCdOnJCIiAjx9PQUa2tr8fb2lsjISPn999+Nyn3//fcCQAYOHFjo8l999VUBIAsXLjQafvv2bXn//felYcOGYmdnJ05OTtKhQwdZt26dyTzOnz8vACQoKEj0er1MnDhRfH19xcrKSiZMmCAiIjVq1BDDJlq0aJE0atRIbG1txcPDQ0aNGiWpqakm8w0KChIAcv78eVmzZo20bNlS7OzsxNvbW958803JysoSEZE//vhDBg0aJFWqVBE7Ozvp1KmTHDlypNB13rBhg4SEhIirq6totVrx9/eX6dOny+3bt4usw7p16yQgIEDs7e2lUqVKMmjQILl8+bJReQCFvs6fP19onbZv317odDVq1BARkRdffFEAyI4dO4ym/e677wpdxn/+8x8BIPPnzzcanpWVJXPnzpWWLVuKo6Oj2NvbS6tWreSrr76S/Px8s3VMSUmRSZMmSe3atUWr1YqLi4t07dpVdu7caVTO8N4193rvvfeUcidPnpShQ4fKc889J1qtVipXrixNmjSRCRMmyLVr1wrdVgXduHFDRo0aJR4eHmJnZydNmzaVZcuWGb0vzdXP3LElIkbb3GDJkiVK/U+fPi19+/YVV1dXsbe3lzZt2shPP/1U4nkVVi+D+Ph46d+/v3h5eYmNjY14e3tLSEiILF++3Kjcr7/+KmPHjpVGjRqJi4uL2NraSp06dWTq1Kkmx1NJ94m5+hr89NNPEhwcLC4uLqLVaqV27dpmlyUi8t577wkAWbJkiRw9elR69uwpLi4uYm9vLx06dJDffvvN7DIKc/bsWXnvvfekdevW4uHhIdbW1lK1alWJjIyU06dPm53GsC65ubkyc+ZM8ff3FxsbG6lWrZpMmTJF7t27ZzLN4cOH5c0335TmzZtL5cqVxcbGRvz8/OTVV1+Vq1evFrkcg2+//VYASERERKHrM3z4cAFgtE9v3rwp06ZNk/r164uDg4M4OzuLv7+/REZGyr59+4ymf/B8+qDHcUzl5+eLn5+fuLi4KOfYBxmOhWHDhhkNT01NlU8//VRCQkKkevXqYmNjI66urhIaGipxcXGFLi87O1s+//xzadOmjeh0OrGzsxN/f3955ZVX5NixYybly+L4EPn7HDxs2DBJSkqSESNGSNWqVcXS0lLmzJmjlNuxY4cEBQWJg4ODuLq6Snh4uJw6dcroPV8ShvNAYcebwdmzZ0Wj0YhGo5GLFy+aTG/uPBIbGyshISFStWpVsbGxES8vL2nbtq1ER0crZQzvIXMvw7kxMzNTvvrqK+nVq5f4+fmJra2t6HQ6ad++vaxevdpsfR88v+7cuVM6deokjo6O4uTkJN27d5cTJ04Uuq6bNm2SHj16SJUqVcTGxkZ8fHykd+/e8uOPP5rdfqNGjZIaNWqIjY2NVK5cWfr161fktd+c6tWrCwDZtWuXybjLly+XaB89qLTvA4P8/HypXr26VKpUSTIzM4stX1RmePCcnpOTI59++qk0b95cHBwcxMHBQVq1aiVffPGF5Obmmsz3wcyzcuVKCQgIEEdHR9HpdKVaH5G/85C57FPS/ffTTz8JAKlZs6ZJRsvPz5fnn39eAMisWbOM6m/uVdJ9UuowP2fOHAEglpaW0rlzZxk4cKBUrVpVfH19pVevXmYDx5YtW8TOzk4ASPPmzWXQoEHStGlTASCOjo7y66+/KmXv3bunnBzNBdWcnBzlgnXr1i1leHJystSvX18ASNWqVaVXr14SHBwsDg4OAkBmzJhhNB/DSeUf//iHNG3aVCpVqiTh4eHSt29f5eRhOHG8+eabYmNjI23btpXw8HBxd3cXANK+fXuTEGnYKVFRUWJlZSWBgYESHh4ulStXFgDy4osvypkzZ6Ry5cry3HPPSd++faVRo0YCQFxdXSU5OdlknSdOnCgAxNbWVjp06CB9+/ZV6taiRQvJyMgwW4c333xTLCws5B//+If07dtXfHx8BID4+/vL3bt3lfLDhg2TmjVrCgAJDQ2VYcOGKa8bN24U+l44deqUDBs2TNnGD043adIkERH5+uuvTQ5UEZGxY8cW+mbt0aOHADC6KGZkZEj79u0FgFSuXFm6du0q3bt3l0qVKgkAGT16tNn6Va1aVTmo+vTpIx06dBAbGxuxsLCQlStXKmUXLVokoaGhStkH18XwYTAhIUHs7OxEo9FIQECADBo0SHr06CH16tUrMmgXdPPmTaldu7YAkGrVqsnAgQMlKChILCws5LXXXnvsYX7o0KGi0+nEz89PBg0aJB06dFAutOZOFKUN83PmzBGNRiMApFWrVjJo0CB5/vnnpXLlyibzCQgIEK1WKy1atJC+fftKjx49xMvLSwBIgwYNjI75kuyTwuorIhITEyMAxMrKSjlXVatWTQBI7dq1TY41wwVt7NixYm9vL7Vr15Z+/fpJkyZNlOPPXFArzNSpUwWA1K9fX3r06CH9+vVT3ivOzs5mL+CGdRk4cKA4ODhIp06dJCwsTHQ6nQCQIUOGmEwzcOBAsbS0lCZNmkjv3r0lPDxcfH19BYB4eXmZDfQFt1l2drZ4enqKVquVv/76y6S8Xq8XBwcHcXFxUS7at2/fllq1ainnlL59+0rfvn2lZcuWYmVlZXLMmwvzj+uYOn78uACQbt26mR1fWJj/+eefBYD4+Pgo75HAwEDl+Fi8eLHJvB48Fzk6Okq3bt1kwIAB0qpVK7PrXVbHh8jf4ah79+5SrVo18fT0lBdeeEHCwsLkyy+/FBGR9evXi6WlpQCQNm3ayKBBg+S5554TZ2dnGTJkSJmEeRGRli1bCgD55ptvTKYveB5ZsGCBABCtVivBwcEyePBgCQ4OVs7fBpMmTVKOx7Zt2xqdE06dOiUi98/7AMTDw0OCgoKU86u1tbXZa5HI3+fXiRMnKsdSv379lPO0m5ubJCUlmUxnuDZbWlpKu3btlPOrs7OzyTru2rVLnJ2dlX35wgsvKO81Ozs72bZtW7HbVOT+B1DDtbPgtd/AkDfS0tJKNE/DuS8yMlImTJggo0ePlg8//FAOHjxY7LSRkZECQLZu3VpsWUNmMLcPDef03Nxc6d69u3Ke7N27t/Tu3VucnJwEgPTp00fy8vKM5mvIPKNGjRILCwtp3769DBo0SNq2bVui9X9QYWG+tPvPkHFeeuklo+GGxspOnTop6zFjxgxp27atAJAmTZoYva/NfWAzW+/SrOSff/4pNjY2YmtraxTAMzMzlQBW8ASckZEhHh4eAkAWLFhgNL/Zs2crgebBFqeXX37Z5CRgYPjEEx4ebjS8W7duAkCmTJki2dnZRnWuWbOmWFpaGl08DScVABIYGGi21cNw8fHy8pLDhw8rw2/cuKFcxAq+gQ1vKicnJ6NtlJSUJB4eHqLRaKRevXoyceJEZUfm5+crLdj//Oc/jea3du1aASDNmjUzenNlZ2fLqFGjBIBMnjzZbB0cHByM6nfnzh1p06aNADC5SBUXFotSWIubiMi5c+fMnrwbNGigtDo+eIHNy8sTnU4nlStXNvqgZPg2JjIy0uiClpKSIgEBAQLAqCUkNzdXGjZsKABk3rx5RvM6dOiQuLm5iYODg1y/fl0Z/mArlzmGbfR///d/JuNOnjxZ4lZEw37r3bu30ft+06ZNYmVl9djDvOFDZE5OjjJu48aNYmlpKQ4ODib1Lk2Y37lzp2g0GnF2djapW1ZWlsTGxhoN++mnn4w+hIvc/wBv2Cbvv/++0bji9klh9d2/f79YWFiIk5OTUQvxvXv3pH///gJA+vfvbzSN4YIGQGbOnGk0LioqSnn/ldSePXvkjz/+MBlu+IDbqVMns+sCQOrVq2d0vJ87d0754Fpwnlu3bjXZh3l5efL++++bvZgYllNwm7399tsCQObOnWtS3hC2xo0bpwwzvL8eHGZw/fp1kw8+5s4Tj+uYMtSv4PmzYF0Lvo/OnTtn9huXQ4cOiYuLizg7O5sE6BEjRij77+bNm0bjrly5YhSAntTxYQg5BVtH09PTlWC3atUqZXhOTo7RN19lEeZfeeUVASDTpk0zmb7geaRGjRri7OxsEqDy8/NNQlJxrcg3b96UX375xSTwnTt3Tnx9fcXCwsJkOYZtYWFhYbSdcnNzpV+/fgJA3n33XaNpli9fruSXgh/MMzIyjK69er1euSvhu+++Myq7efNmsbGxkapVq5r9VqmgI0eOCACpVKlSoWUMjaVHjx4tdn4ixue+gq9+/fqZbVg1+OyzzwSA0TcoJV2euX348ccfCwBp1KiR0fX52rVrUqdOHQEgn3/+udE0hsxja2trchdAaZkL8w+z/+7evas0ShjOb4mJiWJjYyMuLi5y6dIlo/k8+E36Q9W7NIXfeecdAcy3gv7xxx9iYWFhEjgMF6727dubnWeLFi0EgNHXX1u3bhXgfitxQYaWhAc36OHDh5VWB3O3W6xfv97kovNgmD9w4IDZuhkuPl999ZXJuE8++cTshje8qcxdVAyf4mvWrGkUrET+PkALnuQMn2AL3o4kcv9DlKenp7i4uBiduAx1mD59usk0//d//2f2olZWYV7k/leCWq1WudDcuHFDNBqNjBs3Ttq2bWt0YTh48KByAjG4fv26WFtbi5+fn9nbDBITEwWA9OzZUxm2bt06ASCDBw82W6e5c+cKAPnkk0+UYcUFR8MHRnMf/Erq9u3bYmdnJ1ZWVkZfPxsMHjz4sYd5R0dHk4Agcr9FF4DExMQUO6/CLsKGbfLxxx+brVdJ3b17V6ysrKR58+ZGwx82zBs+HBe8AIvcfz/Z2dmJhYWFXLlyRRluuMC0a9fOZJqbN2+WOMSURNu2bUWj0Zi0nBnOSVu2bDGZZty4caUKXiIiVatWFVdXV5Phhe1jCwsLadiwoUl5w3n6wdAyc+ZMAWD2NkZzzJ0nHscxJfL3h/0Hv217UGFhviiG692GDRuUYdeuXRNLS0uxs7MzuV3RnCd1fGi1WqP3ssHixYsFgHTp0sVk3K1bt8TR0bHMwvxbb70lAGTMmDEm0xc8j9jZ2UmTJk1KVIeHvSVE5P63fQDk008/NRpuOL8OHTrUZJqEhASzdTYEte+//77Y5RruaHjwg82DDI0F5j7UFvTbb78JcP8OhMIYWnnj4+OLnZ/I/Q8mH3/8sZw4cUIyMjLk8uXLsnLlSuWbkYKNpw/avHmz8mGypIrah4ZbiMy19G/YsEEASJ06dYyGGzLP2LFjS1yHwpgL8w+7/w4fPiw2Njbi5uYmf/zxh3L3yJo1a0zm8ahhvlS92cTHxwMA+vfvbzKuZs2aaNasGRISEoyG79q1CwAwZMgQs/McOnQoEhISsGvXLgwaNAgA0LFjR1StWhVbtmxBSkqK0m3R3bt38b///Q/Ozs4ICwtT5rF582YAQO/evc32VWr4xfKBAwdMxnl5eaFly5ZFrndISIjJMEOXW0lJSWan6dKli8kww489OnbsCCsr401v+AHfg/NLSUnBkSNHUK9ePdSpU8dkfra2tmjZsiV+/PFHnD171qTMw9S7LAQFBWH58uXYu3cvOnbsiJ07d0JE0LFjRzg7O+Nf//oXLly4AF9fX+zYsUOZxmDnzp3IyclB165dodVqTebfpEkTODk5Ge1fw3siPDzcbJ2Kek8UpkWLFvj555/x4osvYvr06WjZsiUsLEr3G/JDhw4hMzMTbdu2NfsjsMGDB2P16tWlmmdxQkJCUKlSJbPLWrt2LXbv3v1Q883Ly1P216hRo0o83dWrV7Fx40b8/vvvSE9PR35+PgDAxsYGZ8+efai6FFTUecfd3R0hISH43//+h/j4eJPzmbnjxs3NDW5ubqU+bjIyMrBx40YkJibi1q1bSm8uSUlJEBH8+eefaN68udE01tbWZruHLerY/euvv7BhwwYcP34caWlpyMvLAwDk5OTg1q1buHXrFlxdXYusq6+vL0JDQ/Hzzz9j7969aN26NQDg8OHDSEhIQEBAABo3bqyUN3RX9/bbbyvd49na2pZwy/w9j0c9poD750oAZt/nxcnLy8PWrVsRHx+P5ORk3Lt3DwCU9+KD78nt27cjLy8P3bt3R7Vq1Yqd75M6Ppo3b46qVauaDDcc2wMGDDAZV6lSJYSEhOCHH34ocd1K434uQon6D2/RogV2796Nt956CyNHjnwsP2jfvXs3duzYgatXr+LevXsQEeXYKWw7lvSaee3aNZw6dQpubm7o169fsXUpyfVo7ty5OHDgAPr27VvkvEqyXQ1lSmro0KFGfzs4OCAiIgKdOnVCo0aNsH79esTHx6NNmzYm0xrOKzdu3CjVMs25dOkSLl26BE9PTzz//PMm48PCwuDi4oLTp0/jxo0bqFKlitH4Xr16PXIdzHnY/de0aVN89NFHmDJlCpo3b4709HRERkZi4MCBj72OpQrz165dAwCjrqYeVL16dZMwb5imsC5+DMMN5QDAwsICgwYNwieffIK1a9di3LhxAIANGzYgIyMDL730ktFF48KFCwCAqVOnYurUqYXW/+bNm2brXBxzJ21D/6NZWVlmpzF3YnVwcCh23IPzu3jxIoD7Xe8Vd0K8efOmSZh/mHqXhY4dO2L58uXYsWMHOnbsiB07dkCj0SAoKEgJ8zt27MDw4cOVi9+DYcawfxcsWIAFCxYUupzMzEyTaQYOHFjkgWPuPVGYN998E7t378bGjRuxceNG6HQ6BAQEICwsDMOHD4eTk1Ox8zC8zwt735VFLw81atQwO9zcsVcaN2/eRGZmJtzd3Uu07gAwe/ZsTJs2DdnZ2Q+1zJK6du0aNBrNQ617YSHN0dERf/31V4nrsG3bNgwaNKjIi9zt27dNhnl5ecHS0tLs8gHTY3f16tUYNWoUMjIyilxOcWEeAEaPHo2ff/4ZixYtUsL8okWLAAAjR440Ktu5c2e88cYbmDt3Lnr27AkbGxs0bdoUISEhGDFiRIm6dXscxxQA6PV6AChxeYMrV64gLCwMR44cKbTMg/vo8uXLAFCisPkkj4/Czhvlcb4xMJxbS/K++/zzzxEeHo6ZM2di5syZ8Pb2Rvv27fHCCy+gb9++pfqAp9fr0bdvX2zbtq3QMuaOO6Dk18zSvA+Av69HAQEBRZYryfXI8F66c+dOoWXu3r0LACb9pJeWl5cXXnrpJXz88cf45ZdfzIZ5Z2dnAH8fg4+iuLxoOKenpaXh2rVrJmG+rN7Pj7L/Jk2ahLVr1yIhIQFVq1bF/Pnzy6KKD9fPfGHBsqhPg8WF0YLjhwwZgk8++QSrVq1SwvyqVauUcQ8ytEK1b9++yK6OKleubDKsJC1JD/NksqKmKen8DOvl5eVltsXgQW5ubg+9nLJmaGU3BPWdO3eiUaNGcHNzQ9u2bWFjY4MdO3bgxRdfxO7du+Hm5oaGDRsq0xu2Q7NmzYxaBotimKZbt25FPpCiNF3lOTs7Y9u2bfjtt9+wceNG7NixA1u3bkVcXBxmzJiBXbt2FXtyL01rVUkZWu5Kq7StN4Up6brs3bsXkyZNgk6nw8KFC9GxY0d4enoq37Z4e3s/0W+MAPN1fxz7JiMjAwMGDMBff/2Fd999F4MHD0aNGjVgZ2cHjUaDiIgIrF692uw+KM3yL168iOHDh0NEMHfuXPTo0QNVq1aFnZ0dAKBNmzbYs2dPifd1WFgYqlWrhrVr12Lu3LmwsrLCqlWr4OTkZPZD8ezZszF69Gj873//w9atW/Hbb79h//79mDVrFtauXVtoS5bB4zimAECn0wEA0tPTS7SeBq+88gqOHDmCvn37YurUqahTpw6cnJxgYWGBhQsXYvTo0Y+8j57E8VHYdawszjcllZiYCAAl6vO/cePGOHnyJGJjY7Fp0ybs3LkTa9euxdq1a9GuXTts3boVNjY2JVru1KlTlX7uP/jgAzRs2BAuLi6wtLREXFwcQkNDCz0eSrudSnst79+/f5F97BcXFoG/A2tqairu3LmjNAQ+yND14+MIt4a+6gt77xlCvOEYfBxKsl3NlSntN4Ml9Sj778SJEzh+/DiA+2H/4sWLaNSo0WOvY6nCvJeXF06fPo1Lly6ZfRiB4dPqg7y9vQEA58+fNztPQ+uzl5eX0fBmzZqhXr162Lt3L86dO4dKlSrhl19+gZeXFzp16mRU1vBp+oUXXniop549rQzr5enpqeqnX9asWRM+Pj7Yu3cvrl69iuPHjysf0Ozs7NCqVSvs2LEDiYmJSEtLQ58+fYwOVMN26NixI2bPnl2iZRqmGTNmzGP96k2j0Rg9bOLGjRuYMGECVq9ejbfffhtr164tcnrD8WB43xdU2KOxDRcyc62v5o67BxW3LEOdSqty5cqws7PD9evXcfv27WJbH9etWwcA+Oijj0yevJeZmYnk5OSHqoc53t7eOH/+PC5evGj2FrXCzjuPy65du/DXX3+hX79+Zh+Kcu7cuceynE2bNiE7OxuTJk0y6dP7YZZjaWmJV155BdHR0Vi9ejW0Wi30ej1GjRpVaCtfnTp1MGXKFEyZMgX37t3D559/jsmTJ2P06NHFhnng0Y8pAMoH9lu3bpV4Xe/cuYPNmzfDw8MD3377rcm3Iea2neFb6T/++KPY+T8Nx8fDnm8e1dmzZ3Ho0CFYWFigQ4cOJZrG1tYW4eHhynvm5MmTGDx4MHbv3o3Fixfj1VdfLdF81q1bB0tLS2zYsMEkYD6u46407wPg/vXo9OnTmD59eokbpArj4uKC6tWr49KlSzh8+LDJg4+uXLmCmzdvonr16o8lYKempgIovJXfML5gK/nDKC4vAn+/Z8vq3G3Ow+6/rKwsDBkyBFlZWRg6dChWrFiBIUOG4MCBA2ZvGX4Upbo50fAVy/fff28y7ty5czh8+LDJ8Pbt2wMAVq5caXaehuGGcg8ytMCvWrUK3333HbKzszF48GCTr9yCg4MBAOvXry/hmqhDtWrVUKdOHRw9erTIN/fjYAiLubm5ZTJtUFAQsrKyMHPmTIiI0Qeyjh074uLFi8oHloL3C3fq1AmWlpb48ccflU/IxXmY98TDbIMqVaooj14+duxYseVbtGgBW1tb7Nu3z2wIX7NmjdnpDCeuM2fOmIyLi4srcplxcXFIS0szGW64N79t27bFVdssS0tLZV8ZbsUoiuGkb+42ve+++85sa9nDvi+LOu/cuHEDcXFxsLCwMPu18eNQ1Lr+8ccfOHToUJkv59dff8X169dLPc9XXnkFlpaWWLRoUaG32BTG1tYWkyZNgpeXF1JSUpR72UujtMcUcP93MwDw+++/l3g5er0e+fn5Zm9rys3NVcL1gzp27AhLS0ts2rQJV69eLXL+T+L4KI4h6H333Xcm49LS0oo9dzyMvLw8vP766xAR9OvXr9jfFhSmfv36GDt2LADj90Fx54TU1FQ4OTmZDbLffvvtQ9WlIG9vb9SrVw9//fVXiX5z8LgzSo8ePQCYz2KGff3g7woflogox4HhNzIFnTp1CsD9+8MfVfXq1VG9enUkJyebvU3qp59+QmpqKurUqfNYPjyU1MPuv7feegvHjh3DkCFDsHz5ckRERODYsWN46623TMo+SgYDShnmX3rpJVhbW2Pp0qXKj2EB4N69e4iKijL7df+AAQPg4eGBXbt2YeHChUbjPv30Uxw4cADVqlVDnz59TKaNiIgAcP+CXNgtNgDQunVrdO7cGdu3b8cbb7xh0nqZn5+PuLi4h/6hX3maPn068vLy0K9fP+Wrmgf9+eef+Prrrx95OYZPxKdPny6TaQ232ixatAgajcaotabgBa9gmK9atSqGDx+Os2fPIjIy0ux9afHx8di0aZPy9wsvvIC6deti6dKlmDlzpslj5LOzs/HDDz8YXSSKW4///ve/Zj9U/fzzzwBK9pWmo6MjhgwZgtzcXEyYMMHoPsy4uLhCLzaG7bdgwQKj+7YPHTqEd999t8hlZmRkYOLEiUYniU2bNuG7776Dvb29SStgaUydOhUajQYffvih8qNTg5ycHPzyyy/K34Yfki1evNhof5w8ebLQ37o87Pty7NixsLCwwLx583Dw4EFleHZ2NsaNG4e7d++ib9++Zn+/8jgY1vWHH34wumc+LS0NI0aMMHk/PupyVqxYYXQP7dWrVzFmzJiHmmfVqlURFhaGgwcP4rfffkOTJk3MdhKwfv167N2712T44cOHcf36dTg5ORX7g9THcUwBf394279/f4nKA/db83U6HY4fP47ffvtNGZ6Xl4cpU6aY/eDs7e2NF198EZmZmRg+fLjJNwHXrl0z+qBW1sdHcfr37w9XV1eTc0teXh4mTZpU5O8sHsbRo0cREhKCuLg4eHl5Yc6cOcVOc/fuXXz66acmDQ6G6zZg/D4o7pxQu3ZtpKWlmXyjM2fOHGzfvr00q1MkQyCLiorCiRMnjMbduXPHKIyOHj0aVapUQUxMDJYsWWLywezOnTv45ptvlNtjijNhwgRYWlriv//9r9ExePbsWfzrX/+CpaWlyV0KV69eRd26dU1uLb158ya++eYbk9/iZGRk4NVXX8W+ffvg6elpNqMBfx9z5hpkH4bhW/s33njD6NyZnJyMN99806jMk/Iw+2/z5s2YN28eqlevjs8//xzA/d+GVK9eHfPmzVN+VGvwKBkMQBH9CRbC0OG9paWlBAcHKw9iqV69uvTs2VMAmPTb++BDo1q0aCGDBw+WZs2aCXC/L/QH+2MvyNAvOgCpW7duoeWSk5OlcePGAtx/+NLzzz8vAwcOlHbt2kmVKlUEgNET8Yp7oqVI0V0uFtZl3oNPIiuouK6HUEiXX1OmTFG2ecuWLaV///4SGhoqdevWFQAmXXoVVYfC1vvgwYOi0WhEq9VK7969ZcSIETJixAiTfpTNMXTT6eHhIYMGDZIRI0bI1KlTjcqcPXtW2Y8F63vnzh2xsbFR9p257kXv3LkjnTp1EuB+H/7t27dXHgZi6D7L8OReg1OnTindXHl5eUloaKj0799fWrduLS4uLma71TO8h1q1aiXDhw+XESNGyP/+9z8R+bub0Pr160u/fv1k4MCBSn++dnZ2Je4G7MHnFPj4+MigQYOkU6dOYmFhoXSxV3D/5OfnK/vV3d1d+vTpI+3atRNra2uZPHmy2feO4f02ZMgQo4dGBQUFKQ+xWbRokUn9zM2rqOPFcE4A7j+EbfDgwdK5c2eTh+LcvHlTPD09BYD4+fnJgAEDJDg4WKytraV///6FHm9F7ZPC6isi8q9//UuA+w+NCg4OlkGDBhk9OK2wh0YV1uVdcV2wFtSlSxcBIC4uLhIeHi7h4eHi4uIitWrVkt69ewvMdDVa2LqImD9/ZGVlSYMGDQSAeHp6Sr9+/aRHjx7KU34N58+C54KiliNy/5kHhn1asE9ngwkTJihd5IWFhUlERIR07NhReVZCwf7qzW2/x3VMGZ4A6+TkZPZJlIZtV7DPfcN7xNLSUrp06SIDBw4UX19fsbOzUx76UvB8nZ6eLoGBgcq5qHv37jJgwAD5xz/+YfahUWV5fJSk69bvv/9e6Ta6bdu2MnjwYKlZs+YjPTTKwcFBeajN0KFDpWfPnvLcc88p69mqVSs5e/ZsodM/eB4xPATJxsZGWrduLYMGDZK+ffsq5+7nnnvOqGvdq1eviq2trVhaWkrXrl3l5ZdflhEjRijdN69YsUKpR/v27WXw4MFSv359sbCwkDfeeMPs9nqYrn9FRF5//XXl/WNYVlBQkNmHRu3evVtcXV2VefXo0UN5yJrhwYsPPs+mOIbn9FhZWUm3bt2kd+/eSs6aPXu2SfkHu+M2N9zZ2VkCAgKkf//+0qVLF3Fzc1POX7t37zZbh/z8fPHx8TF6mFxJFHWuzc3NVbp01el00qdPHwkPD1ceGhUeHl7oQ6OKemJ9SRm2UcF5lWb/3bx5U7y9vcXCwsKk3/vt27eLhYWFeHt7G+WrzMxM5YGkQUFB8tJLL8mIESNK/OTxUod5EZHVq1dL8+bNRavVSpUqVSQyMlKuXbsmwcHBApjvE/348eMyePBg5bHmXl5eMnToULNlH/T5558rG/eDDz4osuzdu3dl9uzZEhAQIE5OTqLVasXX11dCQkLk888/N3qaqZrCvMj9vvf79OmjPLjA3d1dmjdvLm+++aYkJCSUuA5FrffKlSulefPmygmhpAdHTk6OTJ8+XWrWrKk8Zc/cehievlkwdIv83S9uUf3Z5uTkyFdffSVBQUFSqVIl5TH3HTp0kFmzZpnt9/nWrVsSHR0tTZo0EQcHB7G3t5eaNWtKr169ZMmSJSYPwzh79qyEh4eLm5ubcgE07K8NGzbIyy+/LA0aNBAXFxflKaGjRo0ye+EqyvXr1+WVV14Rd3d3sbW1lcaNG8vixYuL3D9paWkyZswY8fDwEK1WKw0aNFAexFZUmH/vvffk5MmT0rt3b6lUqZLY2dlJYGCgbNy40WzdShvmRe4/Lr53795SpUoVsba2lqpVq0poaKhJv9+XL1+WiIgIqVq1qtja2kq9evVkxowZkpubW+jxVtQ+Kay+Bj/++KN07txZdDqd2NjYSK1atWTKlClm+91/3GH+7t278s4774i/v79otVrx8fGRMWPGyM2bNwsND6UN8yL33+Ovvvqq+Pr6ilarleeee06mTp0qd+7cKfRcUFyYv3PnjtKfemFPkTx8+LBMmjRJWrVqJe7u7qLVaqVGjRrSq1cvs6HI3PZ7nMeUIZh/++23JuMMD5V6/fXXTcYtW7ZMmjVrJvb29uLm5ia9e/eWI0eOFHm+vnfvnsyZM0e5kD9Y7+PHj5uUL6vjoyRhXuT+9aN9+/Zib28vLi4u0rNnTzlx4kSp+2x/MBAaXtbW1lK5cmVp3ry5jBo1SuLi4sw2yDw4/YPnkZycHPn888+lb9++UrNmTaWOTZo0kQ8//NDsMwh++eUXadu2rdJPfsFj6aeffpLWrVuLk5OTuLi4SHBwsOzYsaPQ7fWwYV7k/jNNQkJClGtS9erVpU+fPrJp0yaTslevXpVJkyZJ3bp1xc7OThwdHaV27doycOBAWbt2bYkeGvWgDRs2SPv27cXR0VEcHR2lXbt2Rg0dDyoszKenp8vUqVOVhjGtViv29vbSoEEDmTRpktnnFxj8+uuvAph/cFxRinvf5eTkyLx585Tj0t7eXlq2bCmff/655ObmmpR/EmFepOT7r2/fvgLcf4ipOW+++aYAkL59+xoNP3DggHTp0kV0Op3S4FbSY1Pz/yv/yO7cuQNfX19kZmZCr9eb7VqNiJ6cpUuX4qWXXsJ7772n3INMVBKrVq3CkCFDMGzYMNX8+D45ORl+fn7o0qULNmzYYDRuypQp+M9//oNZs2YpX9UT0aMZPXo0Fi1ahGPHjqFBgwblXZ1nWqmfznHu3DmT/kQzMjIwZswY3Lx5EwMHDmSQJyJSqZycHMyaNQsAlB8gqoGnpyfGjRuHH3/80ege5pSUFOV+cXMP4yKi0ktKSsI333yDoUOHMsg/BUod5r/99lt4eHigbdu2GDhwIEJCQuDn54cVK1bA19cXMTExZVFPIiIqQxs2bMDLL7+MZs2a4ciRI+jTpw9atWpV3tUqlbfffhuVKlXChx9+iPXr16NPnz5o0KABLl68iO7du6tufYieVjNnzgRwvytVKn+lDvOdO3dGeHi48sjpXbt2wdXVFZMmTcL+/fvh4eFRFvUkIqIydOjQISxZsgTXrl3DkCFDHksvWU+ai4sL/vrrL6xZswaJiYn48ccf4eTkhDfffNNs94xE9HDmzp2LzMzMMn2KMJXcY7tnnoiIiIiInqxSt8wTEREREdHTgWGeiIiIiEilrMq7AlT+8vPzce3aNTg5OUGj0ZR3dYiIiKgERAS3b9+Gt7c3LCzYPvusYpgnXLt2DT4+PuVdDSIiInoIly9fRrVq1cq7GlROGOYJTk5OAO6fDJydncu5NkRERFQS6enp8PHxUa7j9GximCfl1hpnZ2eGeSIiIpXhLbLPNt5gRURERESkUgzzREREREQqxTBPRERERKRSvGeeSiwvLw85OTnlXQ16zKytrWFpaVne1SAiIqKHwDBPxRIRJCcnIy0trbyrQmXExcUFnp6e/BEVERGRyjDMU7EMQd7d3R329vYMfBWIiODu3btISUkBAHh5eZVzjYiIiKg0GOapSHl5eUqQd3NzK+/qUBmws7MDAKSkpMDd3Z233BAREakIfwBLRTLcI29vb1/ONaGyZNi//E0EERGRujDMU4nw1pqKjfuXiIhInRjmiYiIiIhUimGeqJxduHABGo0GiYmJ5V0VIiIiUhn+AJYeiu9bPz3R5V34d48nujwiIiIiNWDLPNFjlJ2dXd5VICIiomcIwzxVWB07dsT48eMxZcoUuLq6wtPTE9HR0cp4vV6PUaNGwd3dHc7Oznj++edx5MgRZfyff/6J3r17w8PDA46OjmjVqhW2bNlitAxfX1989NFHGD58OHQ6HUaOHFlsvfbv349mzZrB1tYWLVu2xOHDh43GL126FC4uLkbD1q9fb/Qj1ejoaDRt2hRffvklfHx8YG9vj/79+xs92GvHjh34xz/+AQcHB7i4uKBt27a4ePFiCbYcERERqQXDPFVoy5Ytg4ODA/bt24dZs2bhgw8+wObNmyEi6NGjB5KTk7Fp0yYkJCSgefPm6Ny5M27dugUAyMjIQPfu3bFlyxYcPnwYoaGh6NmzJy5dumS0jP/85z9o2LAhEhIS8O677xZZnzt37iAsLAx16tRBQkICoqOjMXny5Idatz/++APffvstNm7ciNjYWCQmJmLs2LEAgNzcXISHhyMoKAhHjx7Fnj17MGrUKPZaQ0REVMHwnnmq0Bo3boz33nsPAODv74/58+dj69atsLS0xLFjx5CSkgKtVgsA+Pjjj7F+/Xp8//33GDVqFJo0aYImTZoo8/roo4+wbt06bNiwAa+//roy/Pnnny9xIF+5ciXy8vLw9ddfw97eHg0aNMCVK1fw6quvlnrd7t27h2XLlqFatWoAgM8++ww9evTAJ598AhsbG+j1eoSFhaFmzZoAgHr16pV6GVRBROvKuwZU0UXry7sGRM8stsxThda4cWOjv728vJCSkoKEhARkZGTAzc0Njo6Oyuv8+fP4888/AdxvRZ8yZQrq168PFxcXODo64vfffzdpmW/ZsmWJ63Pq1Ck0adLE6CFcgYGBD7Vu1atXV4K8YT75+fk4ffo0XF1dMXz4cOXbhHnz5iEpKemhlkNERERPL7bMU4VmbW1t9LdGo0F+fj7y8/Ph5eWFHTt2mExjuF/9zTffxC+//IKPP/4YtWrVgp2dHV544QWTH7k6ODiUuD4iUmwZCwsLk3IleTKr4RYaw79LlizB+PHjERsbi7Vr12L69OnYvHkzWrduXeL6EhER0dONYZ6eSc2bN0dycjKsrKzg6+trtsyuXbswfPhw9OnTB8D9e+gvXLjwSMutX78+li9fjszMTNjZ2QEA9u7da1SmSpUquH37Nu7cuaN8UDDXB/2lS5dw7do1eHt7AwD27NkDCwsL1K5dWynTrFkzNGvWDNOmTUNgYCBWrVrFME9ERFSB8DYbeiYFBwcjMDAQ4eHh+OWXX3DhwgXEx8dj+vTpOHjwIACgVq1a+OGHH5CYmIgjR44gIiIC+fn5j7TciIgIWFhYYMSIETh58iQ2bdqEjz/+2KhMQEAA7O3t8fbbb+OPP/7AqlWrsHTpUpN52draYtiwYThy5Ah27dqF8ePHY8CAAfD09MT58+cxbdo07NmzBxcvXkRcXBzOnDnD++aJiIgqGIZ5eiZpNBps2rQJHTp0wMsvv4zatWtj0KBBuHDhAjw8PAAAc+bMQaVKldCmTRv07NkToaGhaN68+SMt19HRERs3bsTJkyfRrFkzvPPOO5g5c6ZRGVdXV6xYsQKbNm1Co0aNsHr1aqMuNQ1q1aqFvn37onv37ggJCUHDhg3xxRdfAADs7e3x+++/o1+/fqhduzZGjRqF119/HaNHj36k+hMREdHTRSMluYmXKrT09HTodDro9Xo4Ozsbjbt37x7Onz8PPz8/2NrallMNqaDo6GisX7/e7O03D4P7uYJjbzZU1tibTbko6vpNzw62zBMRERERqRTDPNFjFBMTY9TV5YOvbt26lXf1iIiIqIJhmC8jvr6+0Gg0Ji/DEzpFBNHR0fD29oadnR06duyIEydOGM0jKysL48aNQ+XKleHg4IBevXrhypUrRmVSU1MRGRkJnU4HnU6HyMhIpKWlPanVpALGjBmDxMREs6+vvvrqsS0nOjr6sd1iQ0REROrFMF9GDhw4gKSkJOW1efNmAED//v0BALNmzcLs2bMxf/58HDhwAJ6enujSpQtu376tzCMqKgrr1q3DmjVrsHv3bmRkZCAsLAx5eXlKmYiICCQmJiI2NhaxsbFITExEZGTkk11ZUri6uqJWrVpmX1WrVi3v6hEREVEFw37my0iVKlWM/v73v/+NmjVrIigoCCKCuXPn4p133kHfvn0BAMuWLYOHhwdWrVqF0aNHQ6/XY/HixVi+fDmCg4MBACtWrICPjw+2bNmC0NBQnDp1CrGxsdi7dy8CAgIAAIsWLUJgYCBOnz6NOnXqPNmVJiIiIqInii3zT0B2djZWrFiBl19+GRqNBufPn0dycjJCQkKUMlqtFkFBQYiPjwcAJCQkICcnx6iMt7c3GjZsqJTZs2cPdDqdEuQBoHXr1tDpdEoZc7KyspCenm70IiIiIiL1YZh/AtavX4+0tDQMHz4cAJCcnAwASn/mBh4eHsq45ORk2NjYoFKlSkWWcXd3N1meu7u7UsacGTNmKPfY63Q6+Pj4PPS6EREREVH5YZh/AhYvXoxu3brB29vbaLhGozH6W0RMhhVUsIy58sXNZ9q0adDr9crr8uXLJVkNIiIiInrKMMyXsYsXL2LLli145ZVXlGGenp4AYNJ6npKSorTWe3p6Ijs7G6mpqUWWuX79uskyb9y4YdLq/yCtVgtnZ2ejFxERERGpD8N8GVuyZAnc3d3Ro0cPZZifnx88PT2VHm6A+/fV79y5E23atAEAtGjRAtbW1kZlkpKScPz4caVMYGAg9Ho99u/fr5TZt28f9Hq9UoYezo4dO6DRaNjNJxERET3V2JtNGcrPz8eSJUswbNgwWFn9vak1Gg2ioqIQExMDf39/+Pv7IyYmBvb29oiIiAAA6HQ6jBgxApMmTYKbmxtcXV0xefJkNGrUSOndpl69eujatStGjhyJL7/8EgAwatQohIWFlX1PNk/68fBP+FHhbdq0QVJSEnS6J7yeRERERKXAMF+GtmzZgkuXLuHll182GTdlyhRkZmbitddeQ2pqKgICAhAXFwcnJyelzJw5c2BlZYUBAwYgMzMTnTt3xtKlS2FpaamUWblyJcaPH6/0etOrVy/Mnz+/7FeugrOxsVFuhyIiIiJ6WvE2mzIUEhICEUHt2rVNxmk0GkRHRyMpKQn37t3Dzp070bBhQ6Mytra2+Oyzz/DXX3/h7t272Lhxo0nPM66urlixYoXSxeSKFSvg4uJSlqulCr6+vpg7d67RsKZNmyI6OhrA/e3/1VdfoU+fPrC3t4e/vz82bNiglDV3m83SpUtRvXp12Nvbo0+fPvjkk0+MtvXw4cMRHh5utMyoqCh07NhR+VtEMGvWLDz33HOws7NDkyZN8P333z+mtSYiIqJnDcM8PbPef/99DBgwAEePHkX37t0xZMgQ3Lp1y2zZffv24eWXX8Zrr72GxMREdOrUCR999FGplzl9+nQsWbIECxYswIkTJ/DGG29g6NCh2Llz56OuDhERET2DeJsNPbOGDx+OwYMHAwBiYmLw2WefYf/+/ejatatJ2Xnz5iE0NBRvvfUWAKB27dqIj49HbGxsiZd3584dzJ49G9u2bUNgYCAA4LnnnsPu3bvx5ZdfIigo6DGsFRERET1LGObpmdW4cWPl/w4ODnByckJKSorZsqdOnUKfPn2MhgUGBpYqzJ88eRL37t1Dly5djIZnZ2ejWbNmpag5ERER0X0M81QhWVhYQESMhuXk5Bj9bW1tbfS3RqNBfn6+2fkVnNfDLNMw759++glVq1Y1KqfVaoudPxEREVFBDPNUIVWpUgVJSUnK3+np6Th//vxDz69+/frYu3ev0bCCf1epUgXHjx83GpaYmKh8aKhfvz60Wi0uXbrEW2qIiIjosWCYpwrp+eefx9KlS9GzZ09UqlQJ7777rlGXnqU1fvx4tGnTBrNmzUJ4eDji4uJMbrF5/vnn8Z///AfffPMNAgMDsWLFChw/fly5hcbJyQmTJ0/GG2+8gfz8fLRr1w7p6emIj4+Ho6Mjhg0b9kjrTERERM8e9mZDFdK0adPQoUMHhIWFoXv37ggPD0fNmjUfen6tW7fGV199hc8++wxNmzZFXFwcpk+fblQmNDQU7777LqZMmYJWrVrh9u3bePHFF43KfPjhh/jnP/+JGTNmoF69eggNDcXGjRvh5+f30HUjIiKiZ5dGSnIzMFVo6enp0Ol00Ov1cHZ2Nhp37949nD9/Hn5+frC1tS2nGj6dli5diqioKKO+6NWK+7mCe9JPbKZnzxN+SjfdV9T1m54dbJknIiIiIlIphnkiIiIiIpVimCd6SMOHD68Qt9gQERGRejHMExERERGpFMM8EREREZFKMcxTiRT2ZFSqGLh/iYiI1IkPjaIi2djYwMLCAteuXUOVKlVgY2MDjUZT3tWix0REkJ2djRs3bsDCwgI2NjblXSUiIiIqBYZ5KpKFhQX8/PyQlJSEa9eulXd1qIzY29ujevXqsLDgl3VERERqwjBPxbKxsUH16tWRm5uLvLy88q4OPWaWlpawsrLiNy5EREQqxDBPJaLRaGBtbQ1ra+vyrgoRERER/X/8Tp2IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5svQ1atXMXToULi5ucHe3h5NmzZFQkKCMl5EEB0dDW9vb9jZ2aFjx444ceKE0TyysrIwbtw4VK5cGQ4ODujVqxeuXLliVCY1NRWRkZHQ6XTQ6XSIjIxEWlrak1hFIiIiIipHDPNlJDU1FW3btoW1tTV+/vlnnDx5Ep988glcXFyUMrNmzcLs2bMxf/58HDhwAJ6enujSpQtu376tlImKisK6deuwZs0a7N69GxkZGQgLC0NeXp5SJiIiAomJiYiNjUVsbCwSExMRGRn5JFeXiIiIiMqBRkSkvCtREb311lv47bffsGvXLrPjRQTe3t6IiorC1KlTAdxvhffw8MDMmTMxevRo6PV6VKlSBcuXL8fAgQMBANeuXYOPjw82bdqE0NBQnDp1CvXr18fevXsREBAAANi7dy8CAwPx+++/o06dOsXWNT09HTqdDnq9Hs7Ozo9pCxDRUyNaV941oIouWl/eNXgm8fpNAFvmy8yGDRvQsmVL9O/fH+7u7mjWrBkWLVqkjD9//jySk5MREhKiDNNqtQgKCkJ8fDwAICEhATk5OUZlvL290bBhQ6XMnj17oNPplCAPAK1bt4ZOp1PKFJSVlYX09HSjFxERERGpD8N8GTl37hwWLFgAf39//PLLLxgzZgzGjx+Pb775BgCQnJwMAPDw8DCazsPDQxmXnJwMGxsbVKpUqcgy7u7uJst3d3dXyhQ0Y8YM5f56nU4HHx+fR1tZIiIiIioXDPNlJD8/H82bN0dMTAyaNWuG0aNHY+TIkViwYIFROY1GY/S3iJgMK6hgGXPli5rPtGnToNfrldfly5dLulpERERE9BRhmC8jXl5eqF+/vtGwevXq4dKlSwAAT09PADBpPU9JSVFa6z09PZGdnY3U1NQiy1y/ft1k+Tdu3DBp9TfQarVwdnY2ehERERGR+jDMl5G2bdvi9OnTRsPOnDmDGjVqAAD8/Pzg6emJzZs3K+Ozs7Oxc+dOtGnTBgDQokULWFtbG5VJSkrC8ePHlTKBgYHQ6/XYv3+/Umbfvn3Q6/VKGSIiIiKqmKzKuwIV1RtvvIE2bdogJiYGAwYMwP79+7Fw4UIsXLgQwP1bY6KiohATEwN/f3/4+/sjJiYG9vb2iIiIAADodDqMGDECkyZNgpubG1xdXTF58mQ0atQIwcHBAO639nft2hUjR47El19+CQAYNWoUwsLCStSTDRERERGpF8N8GWnVqhXWrVuHadOm4YMPPoCfnx/mzp2LIUOGKGWmTJmCzMxMvPbaa0hNTUVAQADi4uLg5OSklJkzZw6srKwwYMAAZGZmonPnzli6dCksLS2VMitXrsT48eOVXm969eqF+fPnP7mVJSIiIqJywX7mif3UElV07Geeyhr7mS8XvH4TwHvmiYiIiIhUi2GeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimG+jERHR0Oj0Ri9PD09lfEigujoaHh7e8POzg4dO3bEiRMnjOaRlZWFcePGoXLlynBwcECvXr1w5coVozKpqamIjIyETqeDTqdDZGQk0tLSnsQqEhEREVE5Y5gvQw0aNEBSUpLyOnbsmDJu1qxZmD17NubPn48DBw7A09MTXbp0we3bt5UyUVFRWLduHdasWYPdu3cjIyMDYWFhyMvLU8pEREQgMTERsbGxiI2NRWJiIiIjI5/oehIRERFR+bAq7wpUZFZWVkat8QYigrlz5+Kdd95B3759AQDLli2Dh4cHVq1ahdGjR0Ov12Px4sVYvnw5goODAQArVqyAj48PtmzZgtDQUJw6dQqxsbHYu3cvAgICAACLFi1CYGAgTp8+jTp16jy5lSUiIiKiJ44t82Xo7Nmz8Pb2hp+fHwYNGoRz584BAM6fP4/k5GSEhIQoZbVaLYKCghAfHw8ASEhIQE5OjlEZb29vNGzYUCmzZ88e6HQ6JcgDQOvWraHT6ZQyRERERFRxsWW+jAQEBOCbb75B7dq1cf36dXz00Udo06YNTpw4geTkZACAh4eH0TQeHh64ePEiACA5ORk2NjaoVKmSSRnD9MnJyXB3dzdZtru7u1LGnKysLGRlZSl/p6enP9xKEhEREVG5YpgvI926dVP+36hRIwQGBqJmzZpYtmwZWrduDQDQaDRG04iIybCCCpYxV764+cyYMQPvv/9+idaDiIiIiJ5evM3mCXFwcECjRo1w9uxZ5T76gq3nKSkpSmu9p6cnsrOzkZqaWmSZ69evmyzrxo0bJq3+D5o2bRr0er3yunz58iOtGxERERGVD4b5JyQrKwunTp2Cl5cX/Pz84Onpic2bNyvjs7OzsXPnTrRp0wYA0KJFC1hbWxuVSUpKwvHjx5UygYGB0Ov12L9/v1Jm37590Ov1ShlztFotnJ2djV5EREREpD68zaaMTJ48GT179kT16tWRkpKCjz76COnp6Rg2bBg0Gg2ioqIQExMDf39/+Pv7IyYmBvb29oiIiAAA6HQ6jBgxApMmTYKbmxtcXV0xefJkNGrUSOndpl69eujatStGjhyJL7/8EgAwatQohIWFsScbIiIiomcAw3wZuXLlCgYPHoybN2+iSpUqaN26Nfbu3YsaNWoAAKZMmYLMzEy89tprSE1NRUBAAOLi4uDk5KTMY86cObCyssKAAQOQmZmJzp07Y+nSpbC0tFTKrFy5EuPHj1d6venVqxfmz5//ZFeWiIiIiMqFRkSkvCtB5Ss9PR06nQ56vZ633BBVRNG68q4BVXTR+vKuwTOJ128CeM88EREREZFqMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUw/wTMGPGDGg0GkRFRSnDRATR0dHw9vaGnZ0dOnbsiBMnThhNl5WVhXHjxqFy5cpwcHBAr169cOXKFaMyqampiIyMhE6ng06nQ2RkJNLS0p7AWhERERFReWOYL2MHDhzAwoUL0bhxY6Phs2bNwuzZszF//nwcOHAAnp6e6NKlC27fvq2UiYqKwrp167BmzRrs3r0bGRkZCAsLQ15enlImIiICiYmJiI2NRWxsLBITExEZGfnE1o+IiIiIyg/DfBnKyMjAkCFDsGjRIlSqVEkZLiKYO3cu3nnnHfTt2xcNGzbEsmXLcPfuXaxatQoAoNfrsXjxYnzyyScIDg5Gs2bNsGLFChw7dgxbtmwBAJw6dQqxsbH46quvEBgYiMDAQCxatAg//vgjTp8+XS7rTERERERPjlV5V6AiGzt2LHr06IHg4GB89NFHyvDz588jOTkZISEhyjCtVougoCDEx8dj9OjRSEhIQE5OjlEZb29vNGzYEPHx8QgNDcWePXug0+kQEBCglGndujV0Oh3i4+NRp04ds/XKyspCVlaW8nd6evrjXG0iojLnO/c2LurFZPhrLa0xt6stpm/LwqY/cnEuNR86rQbBz1nh38FaeDvdb8O6kJYPv3kZZuf97Qt26N/AGgDwr1+z8NPZXCQm58HGEkh7y7nYuokI3t+ZhYUJOUi9JwioaonPu9uigbvlI6wxEZF5DPNlZM2aNTh06BAOHDhgMi45ORkA4OHhYTTcw8MDFy9eVMrY2NgYtegbyhimT05Ohru7u8n83d3dlTLmzJgxA++//37pVoiI6ClyYKQD8h7I8sdT8tFl+V30b2CNuznAoeQ8vNtBiyYeFki9J4iKzUKv1XdxcJQjAMDHWYOkSY5G81yYkINZv2Whm//fl8bsPEH/+lYIrGaJxYezS1S3Wb9lY/aebCwNt0NtNwt89GsWuiy/i9OvO8JJq3n0lSciegDDfBm4fPkyJkyYgLi4ONja2hZaTqMxPqmLiMmwggqWMVe+uPlMmzYNEydOVP5OT0+Hj49PkcslInqaVHEwvkv037uzUbOSBkE1LKHRaLA50sFo/GfdNPjHV3dwSZ+P6joLWFpo4OlofJ5c93sOBjawhqPN38Pf73T/HL40sWRBXkQwd1823mmvRd9691v3l4XbwePj21h1LAejW9qUel2JiIrCe+bLQEJCAlJSUtCiRQtYWVnBysoKO3fuxKeffgorKyulRb5g63lKSooyztPTE9nZ2UhNTS2yzPXr102Wf+PGDZNW/wdptVo4OzsbvYiI1Co7T7DiaA5ebmZTaEOGPkugAeBia358wrU8JCbnY0Rz60eqy/k0QXKGIKTm321lWisNgnytEH8lr4gpiYgeDsN8GejcuTOOHTuGxMRE5dWyZUsMGTIEiYmJeO655+Dp6YnNmzcr02RnZ2Pnzp1o06YNAKBFixawtrY2KpOUlITjx48rZQIDA6HX67F//36lzL59+6DX65UyREQV3frfc5F2TzC8qfkgfi9X8NaWe4hoZA3nQm5zWXw4G/UqW6CNz6N9YZ2ckQ8A8CjQ6u/hoFHGERE9TrzNpgw4OTmhYcOGRsMcHBzg5uamDI+KikJMTAz8/f3h7++PmJgY2NvbIyIiAgCg0+kwYsQITJo0CW5ubnB1dcXkyZPRqFEjBAcHAwDq1auHrl27YuTIkfjyyy8BAKNGjUJYWFihP34lIqpoFh/ORjd/K+XHrQ/KyRMM+j4T+QJ80cP8bY+ZOYJVx3LwbgftY6tTwY8MIqbDiIgeB4b5cjJlyhRkZmbitddeQ2pqKgICAhAXFwcnJyelzJw5c2BlZYUBAwYgMzMTnTt3xtKlS2Fp+XePCCtXrsT48eOVXm969eqF+fPnP/H1ISIqDxfT8rHlXB5+GGBnMi4nTzDg+0ycT8vHthftC22V//5kDu7mAC82ebRbbADA0/H+B4rkDIHX36dzpNwVeDjyy3Aievw0ImLatxc9U9LT06HT6aDX63n/PFFFFK0r7xqUmegd9/BlQg4uv+EIK4u/w7ohyJ/9Kx/bh9mb/GD2QR2X3kFlew2+H2BfaJmlidmIir1XbNeUIgLv2Rl4o7UNprS939KfnSdw/89tzAy2rbg/gI3Wl3cNnkm8fhPAe+aJiEil8kWwJDEHw5pYGwX53HzBC99l4uC1PKzsa4c8uX8ve3JGPrLzjNuv/riVj18v5uGV5uZD9iV9PhKT83BJL8gTIDE5D4nJecjI/ns+dednYN2pHAD3exiLCrBBzK4srDuVg+MpeRi+PhP21hpENHr0ln8iooJ4mw0REanSlnP3Q/bLzYxD8pV0wYbTuQCApl/eMRq3fZg9Ovr+fen7+nA2qjprEFLT/AOd/rk9C8uO5Ch/N/v/83twPqf/yoc+6+9wP6WtDTJzBa9tuofUTEFANUvERdqzj3kiKhO8zYb4NR1RRVeBb7OhpwRvsykXvH4TwNtsiIiIiIhUi2GeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IiIiISKUY5svIggUL0LhxYzg7O8PZ2RmBgYH4+eeflfEigujoaHh7e8POzg4dO3bEiRMnjOaRlZWFcePGoXLlynBwcECvXr1w5coVozKpqamIjIyETqeDTqdDZGQk0tLSnsQqEhEREVE5Y5gvI9WqVcO///1vHDx4EAcPHsTzzz+P3r17K4F91qxZmD17NubPn48DBw7A09MTXbp0we3bt5V5REVFYd26dVizZg12796NjIwMhIWFIS8vTykTERGBxMRExMbGIjY2FomJiYiMjHzi60tERERET55GRKS8K/GscHV1xX/+8x+8/PLL8Pb2RlRUFKZOnQrgfiu8h4cHZs6cidGjR0Ov16NKlSpYvnw5Bg4cCAC4du0afHx8sGnTJoSGhuLUqVOoX78+9u7di4CAAADA3r17ERgYiN9//x116tQpUb3S09Oh0+mg1+vh7OxcNitPROUnWlfeNaCKLlpf3jV4JvH6TQBb5p+IvLw8rFmzBnfu3EFgYCDOnz+P5ORkhISEKGW0Wi2CgoIQHx8PAEhISEBOTo5RGW9vbzRs2FAps2fPHuh0OiXIA0Dr1q2h0+mUMkRERERUcVmVdwUqsmPHjiEwMBD37t2Do6Mj1q1bh/r16ytB28PDw6i8h4cHLl68CABITk6GjY0NKlWqZFImOTlZKePu7m6yXHd3d6WMOVlZWcjKylL+Tk9Pf7gVJCIiIqJyxZb5MlSnTh0kJiZi7969ePXVVzFs2DCcPHlSGa/RaIzKi4jJsIIKljFXvrj5zJgxQ/nBrE6ng4+PT0lXiYiIiIieIgzzZcjGxga1atVCy5YtMWPGDDRp0gTz5s2Dp6cnAJi0nqekpCit9Z6ensjOzkZqamqRZa5fv26y3Bs3bpi0+j9o2rRp0Ov1yuvy5cuPtJ5EREREVD4Y5p8gEUFWVhb8/Pzg6emJzZs3K+Oys7Oxc+dOtGnTBgDQokULWFtbG5VJSkrC8ePHlTKBgYHQ6/XYv3+/Umbfvn3Q6/VKGXO0Wq3SZabhRURERETqw3vmy8jbb7+Nbt26wcfHB7dv38aaNWuwY8cOxMbGQqPRICoqCjExMfD394e/vz9iYmJgb2+PiIgIAIBOp8OIESMwadIkuLm5wdXVFZMnT0ajRo0QHBwMAKhXrx66du2KkSNH4ssvvwQAjBo1CmFhYSXuyYaIiIiI1Ithvoxcv34dkZGRSEpKgk6nQ+PGjREbG4suXboAAKZMmYLMzEy89tprSE1NRUBAAOLi4uDk5KTMY86cObCyssKAAQOQmZmJzp07Y+nSpbC0tFTKrFy5EuPHj1d6venVqxfmz5//ZFeWiIiIiMoF+5kn9lNLVNGxn3kqa+xnvlzw+k0A75knIiIiIlIthnkiIiIiIpVimCciIiIiUimGeSIiIiIilWKYJyIiIiJSKYZ5IiIiIiKVYpgnIiIiIlIphnkiIiIiIpVimCciIiIiUimGeSIiIiIilWKYJyIiIiJSKYZ5IiIiIiKVYpgnIiIiIlIphnkiIiIiIpVimCciIiIiUimGeSIiIiIilWKYJyIiIiJSKYZ5IiIiIiKVYpgnIiIiIlIphnkiIiIiIpVimCciIiIiUimGeSIiIiIilWKYJyIiIiJSKYZ5IiIiIiKVYpgnIiIiIlIphnkiIiIiIpVimCciIiIiUimGeSIiIiIilWKYJyIiIiJSKYZ5IiIiIiKVYpgnIiIiIlIphnkiIiIiIpVimCciIiIiUimGeSIiIiIilWKYJyIiIiJSKYZ5IiIiIiKVYpgnIiIiIlIphnkiIiIiIpVimC8jM2bMQKtWreDk5AR3d3eEh4fj9OnTRmVEBNHR0fD29oadnR06duyIEydOGJXJysrCuHHjULlyZTg4OKBXr164cuWKUZnU1FRERkZCp9NBp9MhMjISaWlpZb2KRERERFTOGObLyM6dOzF27Fjs3bsXmzdvRm5uLkJCQnDnzh2lzKxZszB79mzMnz8fBw4cgKenJ7p06YLbt28rZaKiorBu3TqsWbMGu3fvRkZGBsLCwpCXl6eUiYiIQGJiImJjYxEbG4vExERERkY+0fUlIiIioidPIyJS3pV4Fty4cQPu7u7YuXMnOnToABGBt7c3oqKiMHXqVAD3W+E9PDwwc+ZMjB49Gnq9HlWqVMHy5csxcOBAAMC1a9fg4+ODTZs2ITQ0FKdOnUL9+vWxd+9eBAQEAAD27t2LwMBA/P7776hTp06xdUtPT4dOp4Ner4ezs3PZbQQiKh/RuvKuAVV00fryrsEziddvAtgy/8To9fdPdK6urgCA8+fPIzk5GSEhIUoZrVaLoKAgxMfHAwASEhKQk5NjVMbb2xsNGzZUyuzZswc6nU4J8gDQunVr6HQ6pUxBWVlZSE9PN3oRERERkfowzD8BIoKJEyeiXbt2aNiwIQAgOTkZAODh4WFU1sPDQxmXnJwMGxsbVKpUqcgy7u7uJst0d3dXyhQ0Y8YM5f56nU4HHx+fR1tBIiIiIioXDPNPwOuvv46jR49i9erVJuM0Go3R3yJiMqyggmXMlS9qPtOmTYNer1dely9fLslqEBEREdFThmG+jI0bNw4bNmzA9u3bUa1aNWW4p6cnAJi0nqekpCit9Z6ensjOzkZqamqRZa5fv26y3Bs3bpi0+htotVo4OzsbvYiIiIhIfRjmy4iI4PXXX8cPP/yAbdu2wc/Pz2i8n58fPD09sXnzZmVYdnY2du7ciTZt2gAAWrRoAWtra6MySUlJOH78uFImMDAQer0e+/fvV8rs27cPer1eKUNEREREFZNVeVegoho7dixWrVqF//3vf3ByclJa4HU6Hezs7KDRaBAVFYWYmBj4+/vD398fMTExsLe3R0REhFJ2xIgRmDRpEtzc3ODq6orJkyejUaNGCA4OBgDUq1cPXbt2xciRI/Hll18CAEaNGoWwsLAS9WRDREREROrFMF9GFixYAADo2LGj0fAlS5Zg+PDhAIApU6YgMzMTr732GlJTUxEQEIC4uDg4OTkp5efMmQMrKysMGDAAmZmZ6Ny5M5YuXQpLS0ulzMqVKzF+/Hil15tevXph/vz5ZbuCRERERFTu2M88sZ9aooqO/cxTWWM/8+WC128CeM88EREREZFqMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcyXkV9//RU9e/aEt7c3NBoN1q9fbzReRBAdHQ1vb2/Y2dmhY8eOOHHihFGZrKwsjBs3DpUrV4aDgwN69eqFK1euGJVJTU1FZGQkdDoddDodIiMjkZaWVsZrR0RERERPA4b5MnLnzh00adIE8+fPNzt+1qxZmD17NubPn48DBw7A09MTXbp0we3bt5UyUVFRWLduHdasWYPdu3cjIyMDYWFhyMvLU8pEREQgMTERsbGxiI2NRWJiIiIjI8t8/YiIiIio/GlERMq7EhWdRqPBunXrEB4eDuB+q7y3tzeioqIwdepUAPdb4T08PDBz5kyMHj0aer0eVapUwfLlyzFw4EAAwLVr1+Dj44NNmzYhNDQUp06dQv369bF3714EBAQAAPbu3YvAwED8/vvvqFOnTonql56eDp1OB71eD2dn58e/AYiofEXryrsGVNFF68u7Bs8kXr8JYMt8uTh//jySk5MREhKiDNNqtQgKCkJ8fDwAICEhATk5OUZlvL290bBhQ6XMnj17oNPplCAPAK1bt4ZOp1PKmJOVlYX09HSjFxERERGpD8N8OUhOTgYAeHh4GA338PBQxiUnJ8PGxgaVKlUqsoy7u7vJ/N3d3ZUy5syYMUO5x16n08HHx+eR1oeIiIiIygfDfDnSaDRGf4uIybCCCpYxV764+UybNg16vV55Xb58uZQ1JyIiIqKnAcN8OfD09AQAk9bzlJQUpbXe09MT2dnZSE1NLbLM9evXTeZ/48YNk1b/B2m1Wjg7Oxu9iIiIiEh9GObLgZ+fHzw9PbF582ZlWHZ2Nnbu3Ik2bdoAAFq0aAFra2ujMklJSTh+/LhSJjAwEHq9Hvv371fK7Nu3D3q9XilDRERERBWXVXlXoKLKyMjAH3/8ofx9/vx5JCYmwtXVFdWrV0dUVBRiYmLg7+8Pf39/xMTEwN7eHhEREQAAnU6HESNGYNKkSXBzc4OrqysmT56MRo0aITg4GABQr149dO3aFSNHjsSXX34JABg1ahTCwsJK3JMNEREREakXw3wZOXjwIDp16qT8PXHiRADAsGHDsHTpUkyZMgWZmZl47bXXkJqaioCAAMTFxcHJyUmZZs6cObCyssKAAQOQmZmJzp07Y+nSpbC0tFTKrFy5EuPHj1d6venVq1ehfdsTERERUcXCfuaJ/dQSVXTsZ57KGvuZLxe8fhPAe+aJiIiIiFSLYZ6IiIiISKUY5omIiIiIVIphnoiIiIhIpRjmiYiIiIhUimGeiIiIiEilGOaJ6Inw9fWFRqMxeY0dOxYA8MMPPyA0NBSVK1eGRqNBYmKi0fS3bt3CuHHjUKdOHdjb26N69eoYP3489Priu8T74osv4OfnB1tbW7Ro0QK7du0qi1UkIiJ64tjPPLGf2nLm+9ZP5V2FJyLvrh7Iz1f+zr55ESlrp8NjcAxsqzdGxvFtyNVfh6WjK27Ffgav4Z/CxuO5v8vfuAD97lVwaNQZ1m7VkZueglu/fA6bKr6o0uftQpd759SvuPnjbLiGvArbqvVxO/FnZByNg/crX8DK2b1M1/lpccE2oryrQBUd+5kvF7x+E8AnwBLRE2Jpb/zgosy938HKxQtan0YAAMeGzwMAcvXXzU5fMLRbV/KCS4cXcfPHjyH5edBYWJqdLv3Aejg27gKnJqEAANfgUcg8fwi3D29CpaDhj7paRERE5Yq32RDREyd5ObhzcgccG3eBRqN56PnkZ92BhY19oUFe8nKQnfwH7PyaGQ2382uGrKu/P/RyiYiInhYM80T0xN09sxf59zLg0LDzQ88jLzMd+vg1cGzarfAyd9MByYeFfSWj4ZYOlZB3J/Whl01ERPS0YJgnoicu42gc7J5rASsnt4eaPj/rLlK+ex/WbtXh0nZwseVNGv9FADz8NwJERERPC4Z5InqicvUpuHfxCBz//z3spZWfdRcp3/4TFja2cO/7DjSWhf/0x9LeGdBYmLTC591Ng6WDy0Mtn4iI6GnCME9ET1TGsc2wtNfBrmarUk+bn3UX1799F7C0QpV+70JjZVNkeY2lNWw8ayHzQqLR8HsXEqGtWrfUyyciInraMMwT0RMjko+MY1vg0LCzyY9W8zJvI/v6OeTcvAQAyLl1BdnXzyEv436ren7WXVxf+y4kJwtu3SZAsjKRl5GKvIxUSH6eMp/ra95GesJG5W/nVuHIOBKHjKNxyLl5Gbe2LkJu+g04Ne3+BNaYiIiobLFrSiJ6Yu5dSERe+g04Nu5iMi7zj334a9Nc5e+bG2YBAHRtB8Ol3RBkX/8D2UmnAQDXFo40mrbqmMWw0nkAAHJSk6HNTFfGOdTrgPzM20j7bQ3y7tyCTeUacO8fDSvds9HHPBERVWx8aBTxoRPl7Fl5aBSVHz40isocHxpVLnj9JoC32RARERERqRbDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMExERERGpFMM8EREREZFKMcwTEREREakUwzwRERERkUoxzBMRERERqRTDPBERERGRSjHMVxBffPEF/Pz8YGtrixYtWmDXrl3lXSUiIiIiKmMM8xXA2rVrERUVhXfeeQeHDx9G+/bt0a1bN1y6dKm8q0ZEREREZYhhvgKYPXs2RowYgVdeeQX16tXD3Llz4ePjgwULFpR31YiIiIioDDHMq1x2djYSEhIQEhJiNDwkJATx8fHlVCsiIiIiehKsyrsC9Ghu3ryJvLw8eHh4GA338PBAcnKy2WmysrKQlZWl/K3X6wEA6enpZVdRKlR+1t3yrgJVcOkaKe8qUEXH60e5MFy3RXiMP8sY5isIjUZj9LeImAwzmDFjBt5//32T4T4+PmVSNyIqX7ryrgBVfP/mu6w83b59Gzod98GzimFe5SpXrgxLS0uTVviUlBST1nqDadOmYeLEicrf+fn5uHXrFtzc3Ar9AEBE6pSeng4fHx9cvnwZzs7O5V0dInqMRAS3b9+Gt7d3eVeFyhHDvMrZ2NigRYsW2Lx5M/r06aMM37x5M3r37m12Gq1WC61WazTMxcWlLKtJROXM2dmZYZ6oAmKLPDHMVwATJ05EZGQkWrZsicDAQCxcuBCXLl3CmDFjyrtqRERERFSGGOYrgIEDB+Kvv/7CBx98gKSkJDRs2BCbNm1CjRo1yrtqRERERFSGNMKfQBMRVVhZWVmYMWMGpk2bZnJ7HRERqR/DPBERERGRSvGhUUREREREKsUwT0RERESkUgzzREREREQqxTBPRERERKRSDPNERERERCrFfuaJiCqQK1euYMGCBYiPj0dycjI0Gg08PDzQpk0bjBkzBj4+PuVdRSIieozYNSURUQWxe/dudOvWDT4+PggJCYGHhwdEBCkpKdi8eTMuX76Mn3/+GW3bti3vqhIR0WPCME9EVEG0atUK7dq1w5w5c8yOf+ONN7B7924cOHDgCdeMiIjKCsM8EVEFYWdnh8TERNSpU8fs+N9//x3NmjVDZmbmE64ZERGVFf4AloiogvDy8kJ8fHyh4/fs2QMvL68nWCMiIipr/AEsEVEFMXnyZIwZMwYJCQno0qULPDw8oNFokJycjM2bN+Orr77C3Llzy7uaRET0GPE2GyKiCmTt2rWYM2cOEhISkJeXBwCwtLREixYtMHHiRAwYMKCca0hERI8TwzwRUQWUk5ODmzdvAgAqV64Ma2vrcq4RERGVBYZ5IiIiIiKV4g9giYiIiIhUimGeiIiIiEilGOaJiIiIiFSKYZ6IqASWLl0KFxcX5e/o6Gg0bdq03OrzLOjYsSOioqLKuxpERE81hnkiUqXhw4dDo9FAo9HA2toaHh4e6NKlC77++mvk5+eX+fInT56MrVu3Prb5FfywoFaFBfD169dDo9GUal4//PADPvzww8dUMyKiiolhnohUq2vXrkhKSsKFCxfw888/o1OnTpgwYQLCwsKQm5tbpst2dHSEm5tbmS7jWefq6gonJ6fyrgYR0VONYZ6IVEur1cLT0xNVq1ZF8+bN8fbbb+N///sffv75ZyxduhQAcOHCBWg0GiQmJirTpaWlQaPRYMeOHQCAHTt2QKPR4KeffkKTJk1ga2uLgIAAHDt2rNBlm7vN5uuvv0aDBg2g1Wrh5eWF119/XRk3e/ZsNGrUCA4ODvDx8cFrr72GjIwMZfkvvfQS9Hq98m1DdHQ0ACA7OxtTpkxB1apV4eDggICAAKXeAHDx4kX07NkTlSpVgoODAxo0aIBNmzaZrfO0adPQunVrk+GNGzfGe++9p9TlH//4BxwcHODi4oK2bdvi4sWLhW6Hh2XYfsuXL4evry90Oh0GDRqE27dvK2UKtvKnpKSgZ8+esLOzg5+fH1auXAlfX1/lqbYl2dcAcPLkSXTv3h2Ojo7w8PBAZGSk0ic/EZHaMMwTUYXy/PPPo0mTJvjhhx9KPe2bb76Jjz/+GAcOHIC7uzt69eqFnJycEk27YMECjB07FqNGjcKxY8ewYcMG1KpVSxlvYWGBTz/9FMePH8eyZcuwbds2TJkyBQDQpk0bzJ07F87OzkhKSkJSUhImT54MAHjppZfw22+/Yc2aNTh69Cj69++Prl274uzZswCAsWPHIisrC7/++iuOHTuGmTNnwtHR0WwdhwwZgn379uHPP/9Uhp04cQLHjh3DkCFDkJubi/DwcAQFBeHo0aPYs2cPRo0aVerbY0rqzz//xPr16/Hjjz/ixx9/xM6dO/Hvf/+70PLDhw/HhQsXsG3bNnz//ff44osvkJKSUqplJiUlISgoCE2bNsXBgwcRGxuL69ev88m4RKRaVuVdASKix61u3bo4evRoqad777330KVLFwDAsmXLUK1aNaxbt65EQe+jjz7CpEmTMGHCBGVYq1atlP8/2MLs5+eHDz/8EK+++iq++OIL2NjYQKfTQaPRwNPTUyn3559/YvXq1bhy5Qq8vb0B3L9XPzY2FkuWLEFMTAwuXbqEfv36oVGjRgCA5557rtA6NmzYEI0bN8aqVavw7rvvAgBWrlyJVq1aoXbt2rh16xb0ej3CwsJQs2ZNAEC9evWKXfeHlZ+fj6VLlyq30kRGRmLr1q3417/+ZVL2zJkz+Pnnn7F3714EBAQAABYvXlzq+i1YsADNmzdHTEyMMuzrr7+Gj48Pzpw5g9q1az/CGhERPXlsmSeiCkdEHqo1OTAwUPm/q6sr6tSpg1OnThU7XUpKCq5du4bOnTsXWmb79u3o0qULqlatCicnJ7z44ov466+/cOfOnUKnOXToEEQEtWvXhqOjo/LauXOn0ro+fvx4fPTRR2jbti3ee++9Yj/EDBkyBCtXrgRwfzutXr0aQ4YMUdZ5+PDhCA0NRc+ePTFv3jwkJSUVu/4Py9fX1+ieeC8vr0Jb2k+dOgUrKyu0bNlSGVa3bt1S/2g4ISEB27dvN9qedevWBQCjbyyIiNSCYZ6IKpxTp07Bz88PwP3bW4D7wdWgpLfOACjRhwI7O7six1+8eBHdu3dHw4YN8X//939ISEjA559/Xmxd8vPzYWlpiYSEBCQmJiqvU6dOYd68eQCAV155BefOnUNkZCSOHTuGli1b4rPPPit0nhEREThz5gwOHTqE+Ph4XL58GYMGDVLGL1myBHv27EGbNm2wdu1a1K5dG3v37i12Gxg4OztDr9ebDE9LS4Ozs7PRMGtra6O/NRpNoT0RGfZfUfujJPs6Pz8fPXv2NNqeiYmJOHv2LDp06FDEmhERPZ0Y5omoQtm2bRuOHTuGfv36AQCqVKkCAEYtzA/+QPJBD4bW1NRUnDlzRmm1LYqTkxN8fX0L7ary4MGDyM3NxSeffILWrVujdu3auHbtmlEZGxsb5OXlGQ1r1qwZ8vLykJKSglq1ahm9Hrwdx8fHB2PGjMEPP/yASZMmYdGiRYXWtVq1aujQoQNWrlyJlStXIjg4GB4eHibLnTZtGuLj49GwYUOsWrWq2G1gULduXRw8eNBk+IEDB1CnTp0Sz6egevXqITc312jep0+fRlpamvJ3SfZ18+bNceLECfj6+ppsUwcHh4euHxFReWGYJyLVysrKQnJyMq5evYpDhw4hJiYGvXv3RlhYGF588UUA91vNW7dujX//+984efIkfv31V0yfPt3s/D744ANs3boVx48fx/Dhw1G5cmWEh4eXqC7R0dH45JNP8Omnn+Ls2bM4dOiQ0kJes2ZN5Obm4rPPPsO5c+ewfPly/Pe//zWa3tfXFxkZGdi6dStu3ryJu3fvonbt2hgyZAhefPFF/PDDDzh//jwOHDiAmTNnKj3WREVF4ZdffsH58+dx6NAhbNu2rdj7yIcMGYI1a9bgu+++w9ChQ5Xh58+fx7Rp07Bnzx5cvHgRcXFxOHPmjDK//fv3o27durh69Wqh837ttdfw559/YuzYsThy5AjOnDmDzz//HIsXL8abb75Zom1pTp06ddC1a1eMHDkS+/btQ0JCAl555RWjb0VKsq/Hjh2LW7duYfDgwdi/fz/OnTuHuLg4vPzyyyYfpoiIVEGIiFRo2LBhAkAAiJWVlVSpUkWCg4Pl66+/lry8PKOyJ0+elNatW4udnZ00bdpU4uLiBIBs375dRES2b98uAGTjxo3SoEEDsbGxkVatWkliYqIyjyVLlohOp1P+fu+996RJkyZGy/nvf/8rderUEWtra/Hy8pJx48Yp42bPni1eXl5iZ2cnoaGh8s033wgASU1NVcqMGTNG3NzcBIC89957IiKSnZ0t//znP8XX11esra3F09NT+vTpI0ePHhURkddff11q1qwpWq1WqlSpIpGRkXLz5s0it11qaqpotVqxt7eX27dvK8OTk5MlPDxcvLy8xMbGRmrUqCH//Oc/le1p2E7nz58vcv4HDx6U0NBQcXd3F2dnZ2nZsqWsXr3aqIy57TdnzhypUaOG8ndQUJBMmDBB+TspKUl69OghWq1WqlevLt98843UqFFD5syZo5Qpbl+LiJw5c0b69OkjLi4uYmdnJ3Xr1pWoqCjJz88vcr2IiJ5GGpEHbi4kInoG7dixA506dUJqamqFeArrs8TX1xdRUVFmnzpLRPQs4G02REREREQqxTBPRERERKRSvM2GiIiIiEil2DJPRERERKRSDPNERERERCrFME9EREREpFIM80REREREKsUwT0RERESkUgzzREREREQqxTBPRERERKRSDPNERERERCrFME9EREREpFL/D/rI6jwvSCc7AAAAAElFTkSuQmCC\n", "text/plain": "<Figure size 640x480 with 1 Axes>"}, "metadata": {}, "output_type": "display_data"}], "source": "dups_df = pd.DataFrame.from_dict({'near_dups': [dups_30], 'unique': [uniques]})\n\nax=dups_df.plot(kind = 'bar',y=['near_dups', 'unique'], fontsize=10, color=['C0', 'C1'], align='center', width=0.8, xlabel=\"Duplicates vs. Unique\")\nax.set_title('government tweets duplication analysis (Jaccard Distance 0.5) for Text', fontsize=15)\nfor p in ax.patches:\n       ax.annotate(format(p.get_height(), '.1f'), \n                   (p.get_x() + p.get_width() / 2., p.get_height()/2), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points') "}, {"cell_type": "markdown", "id": "a6982259-a97a-4b88-a897-f7f2015858df", "metadata": {}, "source": "##### Similarity Analysis on Universities"}, {"cell_type": "code", "execution_count": 27, "id": "0b440184-e13a-481b-ba79-744b4bdb2b7f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<table border='1'>\n<tr><th>text</th></tr>\n<tr><td>@FoxNews It follo...</td></tr>\n<tr><td>@JohnHolbein1 Jul...</td></tr>\n<tr><td>Hotdogs \nMost US ...</td></tr>\n<tr><td>Brown&#x27;s MAT stude...</td></tr>\n<tr><td>Can experiences w...</td></tr>\n</table>\n", "text/plain": "+--------------------+\n|                text|\n+--------------------+\n|@FoxNews It follo...|\n|@JohnHolbein1 Jul...|\n|Hotdogs \nMost US ...|\n|Brown's MAT stude...|\n|Can experiences w...|\n+--------------------+"}, "execution_count": 27, "metadata": {}, "output_type": "execute_result"}], "source": "univ = universities.select([\"text\"])\nuniv.limit(5)\n# gov = government_entities.select([\"text\"])"}, {"cell_type": "code", "execution_count": 28, "id": "b2b714ea-ab84-4d45-a0ba-de23b3503c0b", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "text = univ.rdd.map(lambda x : x['text']).filter(lambda x: x is not None)\n\nStopWords = stopwords.words(\"english\")\ntokens = text\\\n    .map( lambda document: document.strip().lower())\\\n    .map( lambda document: re.split(\" \", document))\\\n    .map( lambda word: [x for x in word if len(x) > 1] )\\\n    .zipWithIndex()\n"}, {"cell_type": "code", "execution_count": 29, "id": "0aab3abc-04fb-48cc-b1cd-962cd1ac54aa", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "row = Row('text')\ntext_df=text.map(row).zipWithIndex().toDF(['text','id'])\n# text_df.limit(5)"}, {"cell_type": "code", "execution_count": 30, "id": "db77d37c-c05a-4a6d-a36a-35b94e03d937", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>list_of_words</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[@foxnews, it, follows, that, fascists, would, find, classes, in, \"diversity,, equity, and, inclusion\", objectionable, for, college\u2026, https://t.co/hqemeiyahr]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[@johnholbein1, julio, angel, alicea,, phd, candidate, in, urban, schooling, at, \\n@ucla., am, sociologist, of, education,, race\u2026, https://t.co/zzyudiroxb]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[hotdogs, \\nmost, us, presidents\\nbp\\nfirst, interracial, college, \\ndesign, of, golf, ball, \\nlight, savers, \\ngas, mask, \\nfish, filet, f\u2026, https://t.co/it2ape6axd]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[brown's, mat, students, receive, comprehensive,, critical,, and, equity-based, preparation, for, secondary-school, teaching, ca\u2026, https://t.co/gt9kz1y5jr]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[can, experiences, with, religious, diversity, improve, college, students\u2019, attitudes, about, sexual, diversity?, it, turns, out, t\u2026, https://t.co/fpvfojfxw0]</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                                                                                                                                            list_of_words  \\\n0          [@foxnews, it, follows, that, fascists, would, find, classes, in, \"diversity,, equity, and, inclusion\", objectionable, for, college\u2026, https://t.co/hqemeiyahr]   \n1             [@johnholbein1, julio, angel, alicea,, phd, candidate, in, urban, schooling, at, \\n@ucla., am, sociologist, of, education,, race\u2026, https://t.co/zzyudiroxb]   \n2  [hotdogs, \\nmost, us, presidents\\nbp\\nfirst, interracial, college, \\ndesign, of, golf, ball, \\nlight, savers, \\ngas, mask, \\nfish, filet, f\u2026, https://t.co/it2ape6axd]   \n3             [brown's, mat, students, receive, comprehensive,, critical,, and, equity-based, preparation, for, secondary-school, teaching, ca\u2026, https://t.co/gt9kz1y5jr]   \n4          [can, experiences, with, religious, diversity, improve, college, students\u2019, attitudes, about, sexual, diversity?, it, turns, out, t\u2026, https://t.co/fpvfojfxw0]   \n\n   id  \n0   0  \n1   1  \n2   2  \n3   3  \n4   4  "}, "execution_count": 30, "metadata": {}, "output_type": "execute_result"}], "source": "df_tokens = spark.createDataFrame(tokens, [\"list_of_words\",'id'])\n\n#Drop records with no tokens\ndf_tokens = df_tokens.where(col('list_of_words').getItem(0).isNotNull())\ndf_tokens.limit(5).toPandas()"}, {"cell_type": "code", "execution_count": 31, "id": "a1ca3bb6-c3e0-465c-861c-74e0f48f5a25", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "vectorize = CountVectorizer(inputCol=\"list_of_words\", outputCol=\"features\", minDF=1.0)\ndf_vectorize = vectorize.fit(df_tokens).transform(df_tokens)"}, {"cell_type": "code", "execution_count": 32, "id": "b26bb320-a984-42b0-a908-910a87c051f6", "metadata": {}, "outputs": [], "source": "\nmh = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", numHashTables=5)\nmodel = mh.fit(df_vectorize)\ndf_hashed = mh.fit(df_vectorize).transform(df_vectorize)"}, {"cell_type": "code", "execution_count": 33, "id": "9ca78ff3-604d-4104-88b3-17bb38f55ebc", "metadata": {}, "outputs": [], "source": "df_hashed_text = text_df.join(df_hashed, \"id\", how = 'left')"}, {"cell_type": "code", "execution_count": 34, "id": "aa163f81-cd5b-4670-85fb-b0c73f31ab84", "metadata": {}, "outputs": [], "source": "jaccard_distance = 0.5\n\ndf_dups_text_30 = model.approxSimilarityJoin(df_hashed_text, df_hashed_text, jaccard_distance).filter(\"datasetA.id < datasetB.id\").select(\n            col(\"distCol\"),\n            col(\"datasetA.id\").alias(\"id_A\"),\n            col(\"datasetB.id\").alias(\"id_B\"),\n            col('datasetA.text').alias('text_A'),\n            col('datasetB.text').alias('text_B'),\n#             col('datasetA.list_of_words').alias('words_A'),\n#             col('datasetB.list_of_words').alias('words_B')\n            )\n"}, {"cell_type": "code", "execution_count": 35, "id": "bc24661b-c8c9-40b8-b4b6-081875aa0d89", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distCol</th>\n      <th>id_A</th>\n      <th>id_B</th>\n      <th>text_A</th>\n      <th>text_B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.454545</td>\n      <td>185</td>\n      <td>673</td>\n      <td>(Why does Google racialize universities by policing white supremacy?,)</td>\n      <td>(Why does Google racialize universities by warping cameras?,)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.285714</td>\n      <td>274</td>\n      <td>1911</td>\n      <td>(@NorioFujikawa Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted abo\u2026 https://t.co/0NlG90YAJt,)</td>\n      <td>(@oralia_neria Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted abou\u2026 https://t.co/zFFiXvyjJo,)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.285714</td>\n      <td>1850</td>\n      <td>1912</td>\n      <td>(@Deschampions2 Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted abo\u2026 https://t.co/vkH6g5KjxZ,)</td>\n      <td>(@xbluerendezvous Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted a\u2026 https://t.co/tnncC6f95y,)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.285714</td>\n      <td>278</td>\n      <td>1912</td>\n      <td>(@PadsTrashy Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted about\u2026 https://t.co/hZTDp6fYfE,)</td>\n      <td>(@xbluerendezvous Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted a\u2026 https://t.co/tnncC6f95y,)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.285714</td>\n      <td>162</td>\n      <td>1914</td>\n      <td>(@idekwiadwml Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted about\u2026 https://t.co/mHjQ8vJT62,)</td>\n      <td>(@Rob_Liu Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted about the\u2026 https://t.co/CE7nQi7i6G,)</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "    distCol  id_A  id_B  \\\n0  0.454545   185   673   \n1  0.285714   274  1911   \n2  0.285714  1850  1912   \n3  0.285714   278  1912   \n4  0.285714   162  1914   \n\n                                                                                                                                            text_A  \\\n0                                                                           (Why does Google racialize universities by policing white supremacy?,)   \n1  (@NorioFujikawa Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted abo\u2026 https://t.co/0NlG90YAJt,)   \n2  (@Deschampions2 Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted abo\u2026 https://t.co/vkH6g5KjxZ,)   \n3   (@PadsTrashy Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted about\u2026 https://t.co/hZTDp6fYfE,)   \n4  (@idekwiadwml Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted about\u2026 https://t.co/mHjQ8vJT62,)   \n\n                                                                                                                                            text_B  \n0                                                                                    (Why does Google racialize universities by warping cameras?,)  \n1  (@oralia_neria Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted abou\u2026 https://t.co/zFFiXvyjJo,)  \n2  (@xbluerendezvous Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted a\u2026 https://t.co/tnncC6f95y,)  \n3  (@xbluerendezvous Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted a\u2026 https://t.co/tnncC6f95y,)  \n4  (@Rob_Liu Hi, I am a PhD student at Howard University conducting a study about BLM on Twitter. You tweeted about the\u2026 https://t.co/CE7nQi7i6G,)  "}, "execution_count": 35, "metadata": {}, "output_type": "execute_result"}], "source": "df_dups_txt_30 = df_dups_text_30\n# df_dups_text_30.cache()\ndf_dups_text_30.limit(5).toPandas()"}, {"cell_type": "code", "execution_count": 36, "id": "d571744a-c9c5-4ebe-8307-e9c66140869b", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "22/12/08 03:17:49 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 38.0 in stage 102.0 (TID 6852) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal executor 13): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:550)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:539)\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:657)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.EOFException\n\tat java.io.DataInputStream.readInt(DataInputStream.java:392)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:642)\n\t... 21 more\n\n22/12/08 03:17:49 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 12 for reason Container marked as failed: container_1670420302918_0013_01_000012 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:17:49 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 13 for reason Container marked as failed: container_1670420302918_0013_01_000013 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:17:49 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 12 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal: Container marked as failed: container_1670420302918_0013_01_000012 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:17:50 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 13 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal: Container marked as failed: container_1670420302918_0013_01_000013 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:18:44 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 16 for reason Container marked as failed: container_1670420302918_0013_01_000016 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:18:44 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 17 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal: Container marked as failed: container_1670420302918_0013_01_000017 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:18:44 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 17 for reason Container marked as failed: container_1670420302918_0013_01_000017 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:18:44 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 16 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal: Container marked as failed: container_1670420302918_0013_01_000016 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:18:48 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 10 for reason Container marked as failed: container_1670420302918_0013_01_000010 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:18:48 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 10 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal: Container marked as failed: container_1670420302918_0013_01_000010 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:18:48 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 11 for reason Container marked as failed: container_1670420302918_0013_01_000011 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:18:48 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 11 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal: Container marked as failed: container_1670420302918_0013_01_000011 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:18:52 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 18 for reason Container marked as failed: container_1670420302918_0013_01_000018 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:18:52 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 19 for reason Container marked as failed: container_1670420302918_0013_01_000019 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:18:52 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 18 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal: Container marked as failed: container_1670420302918_0013_01_000018 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:18:52 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 19 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal: Container marked as failed: container_1670420302918_0013_01_000019 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:18:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 6.1 in stage 105.0 (TID 7372) (hub-msca-bdp-dphub-students-backup-zhiliny-w-0.c.msca-bdp-students.internal executor 7): FetchFailed(BlockManagerId(13, hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal, 7337, None), shuffleId=25, mapIndex=6, mapId=6802, reduceId=2, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:04 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 24.1 in stage 105.0 (TID 7375) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 9): FetchFailed(BlockManagerId(13, hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal, 7337, None), shuffleId=25, mapIndex=24, mapId=6820, reduceId=5, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:04 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1.2 in stage 105.0 (TID 7376) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 8): FetchFailed(BlockManagerId(12, hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal, 7337, None), shuffleId=25, mapIndex=1, mapId=6797, reduceId=12, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:04 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 19.1 in stage 105.0 (TID 7374) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 4): FetchFailed(BlockManagerId(12, hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal, 7337, None), shuffleId=25, mapIndex=19, mapId=6815, reduceId=3, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:21 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 105.1 (TID 7381) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 6): FetchFailed(BlockManagerId(12, hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal, 7337, None), shuffleId=25, mapIndex=1, mapId=6797, reduceId=12, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:21 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 2.0 in stage 105.1 (TID 7382) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 3): FetchFailed(BlockManagerId(12, hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal, 7337, None), shuffleId=25, mapIndex=19, mapId=6815, reduceId=3, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 79.0 in stage 107.0 (TID 7649) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 3): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=79, mapId=6990, reduceId=5, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 157.0 in stage 107.0 (TID 7654) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 9): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=157, mapId=7145, reduceId=0, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 95.0 in stage 107.0 (TID 7650) (hub-msca-bdp-dphub-students-backup-zhiliny-w-0.c.msca-bdp-students.internal executor 7): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=95, mapId=7021, reduceId=6, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 17.0 in stage 107.0 (TID 7645) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 8): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=17, mapId=6849, reduceId=12, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 164.0 in stage 107.0 (TID 7655) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 8): FetchFailed(BlockManagerId(16, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=164, mapId=7156, reduceId=6, message=\norg.apache.spark.shuffle.FetchFailedException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 111.0 in stage 107.0 (TID 7651) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 4): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=111, mapId=7053, reduceId=6, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 186.0 in stage 107.0 (TID 7657) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 6): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=186, mapId=7178, reduceId=11, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 47.0 in stage 107.0 (TID 7647) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 6): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=47, mapId=6931, reduceId=2, message=\norg.apache.spark.shuffle.FetchFailedException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 126.0 in stage 107.0 (TID 7652) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 2): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=126, mapId=7083, reduceId=3, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 142.0 in stage 107.0 (TID 7653) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-0nkj.c.msca-bdp-students.internal executor 15): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=142, mapId=7115, reduceId=3, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 185.0 in stage 107.0 (TID 7656) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-0nkj.c.msca-bdp-students.internal executor 14): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=185, mapId=7177, reduceId=13, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 188.0 in stage 107.0 (TID 7658) (hub-msca-bdp-dphub-students-backup-zhiliny-w-0.c.msca-bdp-students.internal executor 5): FetchFailed(BlockManagerId(16, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=188, mapId=7180, reduceId=15, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 63.0 in stage 107.0 (TID 7648) (hub-msca-bdp-dphub-students-backup-zhiliny-w-0.c.msca-bdp-students.internal executor 5): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=63, mapId=6961, reduceId=1, message=\norg.apache.spark.shuffle.FetchFailedException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:19:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 31.0 in stage 107.0 (TID 7646) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-0nkj.c.msca-bdp-students.internal executor 14): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=31, mapId=6899, reduceId=5, message=\norg.apache.spark.shuffle.FetchFailedException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:19:45 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 17.0 in stage 108.0 (TID 7665) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-mhh8.c.msca-bdp-students.internal executor 21): FetchFailed(null, shuffleId=26, mapIndex=-1, mapId=-1, reduceId=0, message=\norg.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 26\n\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:210)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\n)\n22/12/08 03:19:45 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 31.0 in stage 108.0 (TID 7666) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-mhh8.c.msca-bdp-students.internal executor 21): FetchFailed(null, shuffleId=26, mapIndex=-1, mapId=-1, reduceId=0, message=\norg.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 26\n\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:210)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\n)\n22/12/08 03:19:45 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 47.0 in stage 108.0 (TID 7667) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-mhh8.c.msca-bdp-students.internal executor 20): FetchFailed(null, shuffleId=26, mapIndex=-1, mapId=-1, reduceId=0, message=\norg.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 26\n\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:210)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\n)\n22/12/08 03:19:45 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 63.0 in stage 108.0 (TID 7668) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-mhh8.c.msca-bdp-students.internal executor 20): FetchFailed(null, shuffleId=26, mapIndex=-1, mapId=-1, reduceId=0, message=\norg.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 26\n\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2(MapOutputTracker.scala:1013)\n\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$2$adapted(MapOutputTracker.scala:1009)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1009)\n\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:821)\n\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:133)\n\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:210)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\n)\n22/12/08 03:19:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 79.0 in stage 108.0 (TID 7669) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 3): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=79, mapId=6990, reduceId=5, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 95.0 in stage 108.0 (TID 7670) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 9): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=95, mapId=7021, reduceId=6, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 142.0 in stage 108.0 (TID 7673) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 8): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=142, mapId=7115, reduceId=3, message=\norg.apache.spark.shuffle.FetchFailedException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:19:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 126.0 in stage 108.0 (TID 7672) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 8): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=126, mapId=7083, reduceId=3, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 111.0 in stage 108.0 (TID 7671) (hub-msca-bdp-dphub-students-backup-zhiliny-w-0.c.msca-bdp-students.internal executor 7): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=111, mapId=7053, reduceId=6, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 186.0 in stage 108.0 (TID 7677) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 2): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=186, mapId=7178, reduceId=11, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 185.0 in stage 108.0 (TID 7676) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 6): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=185, mapId=7177, reduceId=13, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 164.0 in stage 108.0 (TID 7675) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 6): FetchFailed(BlockManagerId(16, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=164, mapId=7156, reduceId=6, message=\norg.apache.spark.shuffle.FetchFailedException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:19:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 188.0 in stage 108.0 (TID 7678) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-0nkj.c.msca-bdp-students.internal executor 15): FetchFailed(BlockManagerId(16, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=188, mapId=7180, reduceId=15, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:19:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 157.0 in stage 108.0 (TID 7674) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 4): FetchFailed(BlockManagerId(17, hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=157, mapId=7145, reduceId=0, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-789l.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:20:19 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 20 for reason Container marked as failed: container_1670420302918_0013_01_000020 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-mhh8.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:20:19 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 21 for reason Container marked as failed: container_1670420302918_0013_01_000021 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-mhh8.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:20:19 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 20 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-mhh8.c.msca-bdp-students.internal: Container marked as failed: container_1670420302918_0013_01_000020 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-mhh8.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:20:19 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 21 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-mhh8.c.msca-bdp-students.internal: Container marked as failed: container_1670420302918_0013_01_000021 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-mhh8.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:20:42 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 51.0 in stage 107.1 (TID 7730) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 9): FetchFailed(BlockManagerId(19, hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=160, mapId=7152, reduceId=14, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:20:57 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 50.0 in stage 108.1 (TID 7739) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 9): FetchFailed(BlockManagerId(18, hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=159, mapId=7151, reduceId=20, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:21:47 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 5.0 in stage 107.1 (TID 7736) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 8): FetchFailed(BlockManagerId(10, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=20, mapId=6874, reduceId=2, message=\norg.apache.spark.shuffle.FetchFailedException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:47 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 7.0 in stage 107.1 (TID 7738) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 8): FetchFailed(BlockManagerId(10, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=25, mapId=6879, reduceId=15, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n)\n22/12/08 03:21:47 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 3.0 in stage 107.1 (TID 7735) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 6): FetchFailed(BlockManagerId(10, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=15, mapId=6847, reduceId=1, message=\norg.apache.spark.shuffle.FetchFailedException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:47 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 6.0 in stage 107.1 (TID 7737) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 6): FetchFailed(BlockManagerId(11, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=23, mapId=6877, reduceId=7, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n)\n22/12/08 03:21:47 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1.0 in stage 107.1 (TID 7733) (hub-msca-bdp-dphub-students-backup-zhiliny-w-0.c.msca-bdp-students.internal executor 7): FetchFailed(BlockManagerId(10, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=8, mapId=6840, reduceId=2, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n)\n22/12/08 03:21:51 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 107.1 (TID 7732) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-0nkj.c.msca-bdp-students.internal executor 15): FetchFailed(BlockManagerId(11, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=3, mapId=6835, reduceId=7, message=\norg.apache.spark.shuffle.FetchFailedException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:51 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 8.0 in stage 107.0 (TID 7663) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-0nkj.c.msca-bdp-students.internal executor 15): FetchFailed(BlockManagerId(10, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=8, mapId=6840, reduceId=2, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n)\n22/12/08 03:21:51 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 2.0 in stage 107.1 (TID 7734) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 2): FetchFailed(BlockManagerId(11, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=11, mapId=6843, reduceId=1, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n)\n22/12/08 03:21:51 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 3.0 in stage 107.0 (TID 7662) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 2): FetchFailed(BlockManagerId(11, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=3, mapId=6835, reduceId=7, message=\norg.apache.spark.shuffle.FetchFailedException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:51 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 107.2 (TID 7749) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 9): FetchFailed(BlockManagerId(11, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=3, mapId=6835, reduceId=7, message=\norg.apache.spark.shuffle.FetchFailedException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:51 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 11.0 in stage 107.0 (TID 7664) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 9): FetchFailed(BlockManagerId(11, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=11, mapId=6843, reduceId=1, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal/10.128.0.34:7337\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n)\n22/12/08 03:21:56 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 6.0 in stage 107.2 (TID 7760) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 9): FetchFailed(BlockManagerId(10, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=25, mapId=6879, reduceId=15, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1748474093001,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1748474093001,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:56 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 5.0 in stage 107.2 (TID 7759) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 9): FetchFailed(BlockManagerId(11, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=23, mapId=6877, reduceId=7, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1748474093005,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=11)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1748474093005,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=11)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:56 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 4.0 in stage 107.2 (TID 7757) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 2): FetchFailed(BlockManagerId(10, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=20, mapId=6874, reduceId=2, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1748474093004,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1748474093004,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:56 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 4.0 in stage 108.2 (TID 7758) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 2): FetchFailed(BlockManagerId(10, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=20, mapId=6874, reduceId=2, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1748474093002,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1748474093002,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:56 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 3.0 in stage 108.2 (TID 7756) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-0nkj.c.msca-bdp-students.internal executor 15): FetchFailed(BlockManagerId(10, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=15, mapId=6847, reduceId=1, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1748474093000,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1748474093000,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:56 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 3.0 in stage 107.2 (TID 7755) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-0nkj.c.msca-bdp-students.internal executor 15): FetchFailed(BlockManagerId(10, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=15, mapId=6847, reduceId=1, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1748474093003,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1748474093003,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:57 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1.0 in stage 107.2 (TID 7751) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 8): FetchFailed(BlockManagerId(10, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=8, mapId=6840, reduceId=2, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1748474093006,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1748474093006,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:57 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 108.2 (TID 7750) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 8): FetchFailed(BlockManagerId(11, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=3, mapId=6835, reduceId=7, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1748474093007,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=11)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1748474093007,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=11)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:57 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 2.0 in stage 107.2 (TID 7753) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 6): FetchFailed(BlockManagerId(11, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=11, mapId=6843, reduceId=1, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1748474093008,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=11)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1748474093008,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=11)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:57 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1.0 in stage 108.2 (TID 7752) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 6): FetchFailed(BlockManagerId(10, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=8, mapId=6840, reduceId=2, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1748474093009,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1748474093009,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=10)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:57 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 2.0 in stage 108.2 (TID 7754) (hub-msca-bdp-dphub-students-backup-zhiliny-w-0.c.msca-bdp-students.internal executor 7): FetchFailed(BlockManagerId(11, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=11, mapId=6843, reduceId=1, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1748474093010,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=11)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1748474093010,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=11)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 160.0 in stage 108.0 (TID 7680) (hub-msca-bdp-dphub-students-backup-zhiliny-w-0.c.msca-bdp-students.internal executor 5): FetchFailed(BlockManagerId(19, hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=160, mapId=7152, reduceId=14, message=\norg.apache.spark.shuffle.FetchFailedException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal/10.128.0.89:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal/10.128.0.89:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 168.0 in stage 108.0 (TID 7681) (hub-msca-bdp-dphub-students-backup-zhiliny-w-0.c.msca-bdp-students.internal executor 5): FetchFailed(BlockManagerId(19, hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=168, mapId=7160, reduceId=7, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal/10.128.0.89:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal/10.128.0.89:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal/10.128.0.89:7337\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n)\n22/12/08 03:21:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 159.0 in stage 108.0 (TID 7679) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-0nkj.c.msca-bdp-students.internal executor 14): FetchFailed(BlockManagerId(18, hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=159, mapId=7151, reduceId=20, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal/10.128.0.89:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal/10.128.0.89:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal/10.128.0.89:7337\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n)\n22/12/08 03:21:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 3.0 in stage 108.0 (TID 7682) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-0nkj.c.msca-bdp-students.internal executor 14): FetchFailed(BlockManagerId(11, hub-msca-bdp-dphub-students-backup-zhiliny-sw-pqwf.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=3, mapId=6835, reduceId=7, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1748474093011,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=11)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1748474093011,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=11)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 50.0 in stage 107.1 (TID 7729) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 3): FetchFailed(BlockManagerId(18, hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=159, mapId=7151, reduceId=20, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=544440908000,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=18)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=544440908000,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=18)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 159.0 in stage 107.0 (TID 7659) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 3): FetchFailed(BlockManagerId(18, hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=159, mapId=7151, reduceId=20, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=544440908002,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=18)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=544440908002,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=18)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 168.0 in stage 107.0 (TID 7661) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 4): FetchFailed(BlockManagerId(19, hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=168, mapId=7160, reduceId=7, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=544440908001,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=19)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=544440908001,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=19)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 53.0 in stage 107.1 (TID 7731) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 4): FetchFailed(BlockManagerId(19, hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=168, mapId=7160, reduceId=7, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=544440908003,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=19)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=544440908003,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=19)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:21:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 160.0 in stage 107.0 (TID 7660) (hub-msca-bdp-dphub-students-backup-zhiliny-w-0.c.msca-bdp-students.internal executor 7): FetchFailed(BlockManagerId(19, hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal, 7337, None), shuffleId=26, mapIndex=160, mapId=7152, reduceId=14, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=544440908004,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=19)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=544440908004,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=19)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n[Stage 117:==================================================>    (23 + 2) / 25]\r"}, {"name": "stdout", "output_type": "stream", "text": "Total records:  5650\nDuplicate titles based on { 0.5 } jaccard distance:  771\nUnique titles based on { 0.5 } jaccard distance:  0.5 :  4879\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "records = df_hashed_text.count()\ndups_30 = df_dups_text_30.select('id_A').distinct().count()\nuniques = records - dups_30\nprint ('Total records: ', records)\nprint ('Duplicate titles based on {', jaccard_distance, '} jaccard distance: ', dups_30)\nprint ('Unique titles based on {', jaccard_distance, '} jaccard distance: ', jaccard_distance, ': ', uniques)\n"}, {"cell_type": "code", "execution_count": 37, "id": "ce45a095-3c90-4359-9c94-b9a73f3b1bc9", "metadata": {}, "outputs": [{"data": {"image/png": "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\n", "text/plain": "<Figure size 640x480 with 1 Axes>"}, "metadata": {}, "output_type": "display_data"}], "source": "dups_df = pd.DataFrame.from_dict({'near_dups': [dups_30], 'unique': [uniques]})\nax=dups_df.plot(kind = 'bar',y=['near_dups', 'unique'], fontsize=10, color=['C0', 'C1'], align='center', width=0.8, xlabel=\"Duplicates vs. Unique\")\nax.set_title('University tweets duplication analysis (Jaccard Distance 0.\uff15) for Text', fontsize=15)\nfor p in ax.patches:\n       ax.annotate(format(p.get_height(), '.1f'), \n                   (p.get_x() + p.get_width() / 2., p.get_height()/2), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points') "}, {"cell_type": "markdown", "id": "088490b3-6d44-492b-af6d-10286b30a721", "metadata": {}, "source": "##### Similarity Analysis on schools"}, {"cell_type": "code", "execution_count": 38, "id": "7a67a00c-1497-4037-98c3-2c697bdf0c6b", "metadata": {}, "outputs": [{"data": {"text/html": "<table border='1'>\n<tr><th>text</th></tr>\n<tr><td>@PennMedicine thi...</td></tr>\n<tr><td>.@Edu_Historian: ...</td></tr>\n<tr><td>@ClaytonTramel @_...</td></tr>\n<tr><td>Sandra Lin \u6797\u828d\u5f64 5-...</td></tr>\n<tr><td>District 65 Schoo...</td></tr>\n</table>\n", "text/plain": "+-----------------------+\n|                   text|\n+-----------------------+\n|   @PennMedicine thi...|\n|   .@Edu_Historian: ...|\n|   @ClaytonTramel @_...|\n|Sandra Lin \u6797\u828d\u5f64 5-...|\n|   District 65 Schoo...|\n+-----------------------+"}, "execution_count": 38, "metadata": {}, "output_type": "execute_result"}], "source": "sch = schools.select([\"text\"])\nsch.limit(5)"}, {"cell_type": "code", "execution_count": 39, "id": "332b6fb3-4ac6-433e-9926-f08ee9c3eb9f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "22/12/08 03:22:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 105.0 in stage 131.0 (TID 8432) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal executor 22): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:550)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:539)\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:657)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2244)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.EOFException\n\tat java.io.DataInputStream.readInt(DataInputStream.java:392)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:642)\n\t... 29 more\n\n22/12/08 03:22:44 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 22 for reason Container marked as failed: container_1670420302918_0013_01_000023 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:22:44 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 22 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal: Container marked as failed: container_1670420302918_0013_01_000023 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:22:44 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 23 for reason Container marked as failed: container_1670420302918_0013_01_000024 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:22:44 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 23 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal: Container marked as failed: container_1670420302918_0013_01_000024 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-dqtm.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n                                                                                \r"}], "source": "text = sch.rdd.map(lambda x : x['text']).filter(lambda x: x is not None)\nStopWords = stopwords.words(\"english\")\ntokens = text\\\n    .map( lambda document: document.strip().lower())\\\n    .map( lambda document: re.split(\" \", document))\\\n    .map( lambda word: [x for x in word if len(x) > 1] )\\\n    .zipWithIndex()"}, {"cell_type": "code", "execution_count": 40, "id": "23e56dcf-e5e3-4dd9-9700-ec453c260708", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "row = Row('text')\ntext_df=text.map(row).zipWithIndex().toDF(['text','id'])\n# text_df.limit(5)"}, {"cell_type": "code", "execution_count": 41, "id": "b69cb2f2-d6c2-4db8-8317-e27f50ff42ee", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>list_of_words</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[@pennmedicine, this, is, the, dean, of, curriculum, at, you, school, promoting, racial, essentialism?!?!?]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[.@edu_historian:, we, simply, don't, have, valid, measures, of, school, quality., they, are, measures, of, family, income,, racial\u2026, https://t.co/yya3nnwosr]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[@claytontramel, @_natemorris, radical, gender, theory,, sexual, orientation, training,, and, critical, race, theory, which, has\u2026, https://t.co/sbxoaamrk8]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[sandra, lin, \u6797\u828d\u5f64, 5-2, is, the, latest, asian, d1, player., she, played, for, georgia, highlands, college, 2020-22, after, graduating\u2026, https://t.co/a9afck8dvm]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[district, 65, school, board, welcomes, mya, wilkins, as, its, newest, member., mya, sees, improving, equity, in, education, as, cruci\u2026, https://t.co/y6fl4lpmba]</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                                                                                                                                       list_of_words  \\\n0                                                        [@pennmedicine, this, is, the, dean, of, curriculum, at, you, school, promoting, racial, essentialism?!?!?]   \n1     [.@edu_historian:, we, simply, don't, have, valid, measures, of, school, quality., they, are, measures, of, family, income,, racial\u2026, https://t.co/yya3nnwosr]   \n2        [@claytontramel, @_natemorris, radical, gender, theory,, sexual, orientation, training,, and, critical, race, theory, which, has\u2026, https://t.co/sbxoaamrk8]   \n3  [sandra, lin, \u6797\u828d\u5f64, 5-2, is, the, latest, asian, d1, player., she, played, for, georgia, highlands, college, 2020-22, after, graduating\u2026, https://t.co/a9afck8dvm]   \n4  [district, 65, school, board, welcomes, mya, wilkins, as, its, newest, member., mya, sees, improving, equity, in, education, as, cruci\u2026, https://t.co/y6fl4lpmba]   \n\n   id  \n0   0  \n1   1  \n2   2  \n3   3  \n4   4  "}, "execution_count": 41, "metadata": {}, "output_type": "execute_result"}], "source": "df_tokens = spark.createDataFrame(tokens, [\"list_of_words\",'id'])\n\n#Drop records with no tokens\ndf_tokens = df_tokens.where(col('list_of_words').getItem(0).isNotNull())\ndf_tokens.limit(5).toPandas()"}, {"cell_type": "code", "execution_count": 42, "id": "d3c09aae-47b4-4f5e-b074-aed966daef06", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "vectorize = CountVectorizer(inputCol=\"list_of_words\", outputCol=\"features\", minDF=1.0)\ndf_vectorize = vectorize.fit(df_tokens).transform(df_tokens)\n"}, {"cell_type": "code", "execution_count": 43, "id": "5e29d75f-f427-473c-9d97-4fb318a98cbc", "metadata": {}, "outputs": [], "source": "mh = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", numHashTables=5)\nmodel = mh.fit(df_vectorize)\ndf_hashed = mh.fit(df_vectorize).transform(df_vectorize)"}, {"cell_type": "code", "execution_count": 44, "id": "3d51a129-a4a9-4917-bd92-396f83d59f15", "metadata": {}, "outputs": [], "source": "df_hashed_text = text_df.join(df_hashed, \"id\", how = 'left')"}, {"cell_type": "code", "execution_count": 45, "id": "c67fad44-6089-4d1a-94f3-2f8e24730673", "metadata": {}, "outputs": [], "source": "jaccard_distance = 0.5\n\ndf_dups_text_30 = model.approxSimilarityJoin(df_hashed_text, df_hashed_text, jaccard_distance).filter(\"datasetA.id < datasetB.id\").select(\n            col(\"distCol\"),\n            col(\"datasetA.id\").alias(\"id_A\"),\n            col(\"datasetB.id\").alias(\"id_B\"),\n            col('datasetA.text').alias('text_A'),\n            col('datasetB.text').alias('text_B'),\n#             col('datasetA.list_of_words').alias('words_A'),\n#             col('datasetB.list_of_words').alias('words_B')\n            )\n"}, {"cell_type": "code", "execution_count": 46, "id": "8cba1d47-88b3-49d0-abd2-d19a2d5feaf0", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distCol</th>\n      <th>id_A</th>\n      <th>id_B</th>\n      <th>text_A</th>\n      <th>text_B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.333333</td>\n      <td>2102</td>\n      <td>5881</td>\n      <td>(Graceville High School at sunset and it's 76.3 F. https://t.co/NudJOlt8I5,)</td>\n      <td>(Graceville High School at sunset and it's 81.7 F. https://t.co/eDB73wsFww,)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.333333</td>\n      <td>3161</td>\n      <td>9630</td>\n      <td>(Graceville High School at sunrise and it's 74.5 F. https://t.co/raYbv48I2B,)</td>\n      <td>(Graceville High School at sunrise and it's 67.7 F. https://t.co/dqTqioNkRS,)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.461538</td>\n      <td>3160</td>\n      <td>5783</td>\n      <td>(Graceville High School at sunrise and it's 72.5 F. https://t.co/9wxP0hHIUb,)</td>\n      <td>(Graceville High School at sunset and it's 82.7 F. https://t.co/ysrNFb6KyJ,)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.333333</td>\n      <td>4994</td>\n      <td>9045</td>\n      <td>(Graceville High School at sunrise and it's 75.8 F. https://t.co/KxAU5MChTG,)</td>\n      <td>(Graceville High School at sunrise and it's 41.5 F. https://t.co/s7mGxSE6qJ,)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.461538</td>\n      <td>5881</td>\n      <td>10257</td>\n      <td>(Graceville High School at sunset and it's 81.7 F. https://t.co/eDB73wsFww,)</td>\n      <td>(Graceville High School at sunrise and it's 50 F. https://t.co/Aivn2T8m8o,)</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "    distCol  id_A   id_B  \\\n0  0.333333  2102   5881   \n1  0.333333  3161   9630   \n2  0.461538  3160   5783   \n3  0.333333  4994   9045   \n4  0.461538  5881  10257   \n\n                                                                          text_A  \\\n0   (Graceville High School at sunset and it's 76.3 F. https://t.co/NudJOlt8I5,)   \n1  (Graceville High School at sunrise and it's 74.5 F. https://t.co/raYbv48I2B,)   \n2  (Graceville High School at sunrise and it's 72.5 F. https://t.co/9wxP0hHIUb,)   \n3  (Graceville High School at sunrise and it's 75.8 F. https://t.co/KxAU5MChTG,)   \n4   (Graceville High School at sunset and it's 81.7 F. https://t.co/eDB73wsFww,)   \n\n                                                                          text_B  \n0   (Graceville High School at sunset and it's 81.7 F. https://t.co/eDB73wsFww,)  \n1  (Graceville High School at sunrise and it's 67.7 F. https://t.co/dqTqioNkRS,)  \n2   (Graceville High School at sunset and it's 82.7 F. https://t.co/ysrNFb6KyJ,)  \n3  (Graceville High School at sunrise and it's 41.5 F. https://t.co/s7mGxSE6qJ,)  \n4    (Graceville High School at sunrise and it's 50 F. https://t.co/Aivn2T8m8o,)  "}, "execution_count": 46, "metadata": {}, "output_type": "execute_result"}], "source": "df_dups_txt_30 = df_dups_text_30\n# df_dups_text_30.cache()\ndf_dups_text_30.limit(5).toPandas()"}, {"cell_type": "code", "execution_count": null, "id": "42c6f4fe-4253-4524-b7ce-7fdc243b6b13", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "22/12/08 03:26:44 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1670420302918_0013_01_000004 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-08 03:26:44.849]Container killed on request. Exit code is 143\n[2022-12-08 03:26:44.863]Container exited with a non-zero exit code 143. \n[2022-12-08 03:26:44.865]Killed by external signal\n.\n22/12/08 03:26:44 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1670420302918_0013_01_000006 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-08 03:26:44.843]Container killed on request. Exit code is 143\n[2022-12-08 03:26:44.845]Container exited with a non-zero exit code 143. \n[2022-12-08 03:26:44.849]Killed by external signal\n.\n22/12/08 03:26:44 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 4 for reason Container from a bad node: container_1670420302918_0013_01_000004 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-08 03:26:44.849]Container killed on request. Exit code is 143\n[2022-12-08 03:26:44.863]Container exited with a non-zero exit code 143. \n[2022-12-08 03:26:44.865]Killed by external signal\n.\n22/12/08 03:26:44 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 6 for reason Container from a bad node: container_1670420302918_0013_01_000006 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-08 03:26:44.843]Container killed on request. Exit code is 143\n[2022-12-08 03:26:44.845]Container exited with a non-zero exit code 143. \n[2022-12-08 03:26:44.849]Killed by external signal\n.\n22/12/08 03:26:44 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 4 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal: Container from a bad node: container_1670420302918_0013_01_000004 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-08 03:26:44.849]Container killed on request. Exit code is 143\n[2022-12-08 03:26:44.863]Container exited with a non-zero exit code 143. \n[2022-12-08 03:26:44.865]Killed by external signal\n.\n22/12/08 03:26:44 WARN org.apache.spark.deploy.yarn.YarnAllocator: Cannot find executorId for container: container_1670420302918_0013_01_000040\n22/12/08 03:26:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 103.0 in stage 166.0 (TID 11267) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1670420302918_0013_01_000004 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-08 03:26:44.849]Container killed on request. Exit code is 143\n[2022-12-08 03:26:44.863]Container exited with a non-zero exit code 143. \n[2022-12-08 03:26:44.865]Killed by external signal\n.\n22/12/08 03:26:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 96.0 in stage 166.0 (TID 11254) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1670420302918_0013_01_000004 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-08 03:26:44.849]Container killed on request. Exit code is 143\n[2022-12-08 03:26:44.863]Container exited with a non-zero exit code 143. \n[2022-12-08 03:26:44.865]Killed by external signal\n.\n22/12/08 03:26:44 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 6 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal: Container from a bad node: container_1670420302918_0013_01_000006 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-08 03:26:44.843]Container killed on request. Exit code is 143\n[2022-12-08 03:26:44.845]Container exited with a non-zero exit code 143. \n[2022-12-08 03:26:44.849]Killed by external signal\n.\n22/12/08 03:26:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 135.0 in stage 165.0 (TID 11274) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container from a bad node: container_1670420302918_0013_01_000006 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-08 03:26:44.843]Container killed on request. Exit code is 143\n[2022-12-08 03:26:44.845]Container exited with a non-zero exit code 143. \n[2022-12-08 03:26:44.849]Killed by external signal\n.\n22/12/08 03:26:44 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 98.0 in stage 166.0 (TID 11261) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container from a bad node: container_1670420302918_0013_01_000006 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-08 03:26:44.843]Container killed on request. Exit code is 143\n[2022-12-08 03:26:44.845]Container exited with a non-zero exit code 143. \n[2022-12-08 03:26:44.849]Killed by external signal\n.\n22/12/08 03:29:20 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 67.0 in stage 168.0 (TID 11604) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 3): FetchFailed(BlockManagerId(6, hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal, 7337, None), shuffleId=41, mapIndex=67, mapId=11142, reduceId=3, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1192645599006,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=6)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1192645599006,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=6)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:20 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 9.0 in stage 168.0 (TID 11600) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 8): FetchFailed(BlockManagerId(6, hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal, 7337, None), shuffleId=41, mapIndex=9, mapId=11042, reduceId=3, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1192645599000,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=6)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1192645599000,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=6)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:20 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 23.0 in stage 168.0 (TID 11601) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-0nkj.c.msca-bdp-students.internal executor 15): FetchFailed(BlockManagerId(4, hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal, 7337, None), shuffleId=41, mapIndex=23, mapId=11056, reduceId=0, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1192645599005,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=4)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1192645599005,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=4)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:20 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 90.0 in stage 168.0 (TID 11605) (hub-msca-bdp-dphub-students-backup-zhiliny-w-0.c.msca-bdp-students.internal executor 5): FetchFailed(BlockManagerId(6, hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal, 7337, None), shuffleId=41, mapIndex=90, mapId=11186, reduceId=1, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1192645599004,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=6)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1192645599004,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=6)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:20 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 46.0 in stage 168.0 (TID 11603) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-mhh8.c.msca-bdp-students.internal executor 29): FetchFailed(BlockManagerId(6, hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal, 7337, None), shuffleId=41, mapIndex=46, mapId=11101, reduceId=1, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1192645599007,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=6)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1192645599007,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=6)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:20 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 112.0 in stage 168.0 (TID 11606) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal executor 33): FetchFailed(BlockManagerId(6, hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal, 7337, None), shuffleId=41, mapIndex=112, mapId=11228, reduceId=0, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1192645599001,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=6)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1192645599001,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=6)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:20 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 31.0 in stage 168.0 (TID 11602) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-z0x6.c.msca-bdp-students.internal executor 30): FetchFailed(BlockManagerId(6, hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal, 7337, None), shuffleId=41, mapIndex=31, mapId=11064, reduceId=0, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1192645599003,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=6)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1192645599003,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=6)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:20 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1.0 in stage 168.0 (TID 11599) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal executor 36): FetchFailed(BlockManagerId(4, hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal, 7337, None), shuffleId=41, mapIndex=1, mapId=11034, reduceId=7, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1192645599002,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=4)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1192645599002,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=4)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:35 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1670420302918_0013_01_000038 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-08 03:29:35.801]Container killed on request. Exit code is 143\n[2022-12-08 03:29:35.802]Container exited with a non-zero exit code 143. \n[2022-12-08 03:29:35.802]Killed by external signal\n.\n22/12/08 03:29:35 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 36 for reason Container from a bad node: container_1670420302918_0013_01_000038 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-08 03:29:35.801]Container killed on request. Exit code is 143\n[2022-12-08 03:29:35.802]Container exited with a non-zero exit code 143. \n[2022-12-08 03:29:35.802]Killed by external signal\n.\n22/12/08 03:29:35 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 36 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal: Container from a bad node: container_1670420302918_0013_01_000038 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal. Exit status: 143. Diagnostics: [2022-12-08 03:29:35.801]Container killed on request. Exit code is 143\n[2022-12-08 03:29:35.802]Container exited with a non-zero exit code 143. \n[2022-12-08 03:29:35.802]Killed by external signal\n.\n22/12/08 03:29:36 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 6.0 in stage 175.0 (TID 12021) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 3): FetchFailed(BlockManagerId(36, hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal, 7337, None), shuffleId=43, mapIndex=0, mapId=11974, reduceId=70, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1749514895002,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:774)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1749514895002,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:36 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 3.0 in stage 175.0 (TID 12019) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 8): FetchFailed(BlockManagerId(36, hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal, 7337, None), shuffleId=43, mapIndex=0, mapId=11974, reduceId=39, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1749514895000,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:774)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1749514895000,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:36 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 2.0 in stage 175.0 (TID 12017) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 3): FetchFailed(BlockManagerId(36, hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal, 7337, None), shuffleId=43, mapIndex=0, mapId=11974, reduceId=28, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1749514895001,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:774)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1749514895001,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:36 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 175.0 (TID 12015) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-tz4g.c.msca-bdp-students.internal executor 8): FetchFailed(BlockManagerId(36, hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal, 7337, None), shuffleId=43, mapIndex=0, mapId=11974, reduceId=0, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1749514895003,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:774)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1749514895003,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:36 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1.0 in stage 175.0 (TID 12016) (hub-msca-bdp-dphub-students-backup-zhiliny-w-0.c.msca-bdp-students.internal executor 5): FetchFailed(BlockManagerId(36, hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal, 7337, None), shuffleId=43, mapIndex=0, mapId=11974, reduceId=18, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1749514895011,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:774)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1749514895011,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:36 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 8.0 in stage 175.0 (TID 12023) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 3): FetchFailed(BlockManagerId(36, hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal, 7337, None), shuffleId=43, mapIndex=0, mapId=11974, reduceId=76, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1749514895013,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:774)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1749514895013,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:36 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 5.0 in stage 175.0 (TID 12020) (hub-msca-bdp-dphub-students-backup-zhiliny-w-0.c.msca-bdp-students.internal executor 5): FetchFailed(BlockManagerId(36, hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal, 7337, None), shuffleId=43, mapIndex=0, mapId=11974, reduceId=55, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1749514895010,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:774)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1749514895010,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:36 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 7.0 in stage 175.0 (TID 12022) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-mhh8.c.msca-bdp-students.internal executor 29): FetchFailed(BlockManagerId(36, hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal, 7337, None), shuffleId=43, mapIndex=0, mapId=11974, reduceId=73, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1749514895005,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:774)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1749514895005,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:29:36 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 4.0 in stage 175.0 (TID 12018) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-mhh8.c.msca-bdp-students.internal executor 29): FetchFailed(BlockManagerId(36, hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal, 7337, None), shuffleId=43, mapIndex=0, mapId=11974, reduceId=42, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1749514895004,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage11.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:774)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1749514895004,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=36)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 03:30:43 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 41 for reason Container marked as failed: container_1670420302918_0013_01_000044 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:30:43 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 41 on hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal: Container marked as failed: container_1670420302918_0013_01_000044 on host: hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n22/12/08 03:30:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 3.1 in stage 173.0 (TID 12042) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 3): FetchFailed(BlockManagerId(37, hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal, 7337, None), shuffleId=42, mapIndex=140, mapId=11344, reduceId=7, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:30:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 2.1 in stage 173.0 (TID 12043) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-z0x6.c.msca-bdp-students.internal executor 30): FetchFailed(BlockManagerId(37, hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal, 7337, None), shuffleId=42, mapIndex=139, mapId=11343, reduceId=10, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal\n\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n\tat java.net.InetAddress.getAllByName0(InetAddress.java:1277)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1136)\n\tat java.net.InetAddress.getAllByName(InetAddress.java:1064)\n\tat java.net.InetAddress.getByName(InetAddress.java:1014)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t... 2 more\n\n)\n22/12/08 03:33:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 8.0 in stage 174.0 (TID 12032) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal executor 42): FetchFailed(BlockManagerId(37, hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal, 7337, None), shuffleId=42, mapIndex=139, mapId=11343, reduceId=10, message=\norg.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal/10.128.0.46:7337\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal/10.128.0.46:7337\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\nCaused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal/10.128.0.46:7337\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\n\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n)\n22/12/08 03:33:59 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 9.0 in stage 174.0 (TID 12033) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-qtln.c.msca-bdp-students.internal executor 42): FetchFailed(BlockManagerId(37, hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal, 7337, None), shuffleId=42, mapIndex=140, mapId=11344, reduceId=7, message=\norg.apache.spark.shuffle.FetchFailedException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal/10.128.0.46:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.IOException: Connecting to hub-msca-bdp-dphub-students-backup-zhiliny-sw-rpbf.c.msca-bdp-students.internal/10.128.0.46:7337 failed in the last 4750 ms, fail this connection directly\n\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n[Stage 180:===========================================>           (15 + 4) / 19]\r"}, {"name": "stdout", "output_type": "stream", "text": "Total records:  11010\nDuplicate titles based on { 0.5 } jaccard distance:  1469\nUnique titles based on { 0.5 } jaccard distance:  0.5 :  9541\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "records = df_hashed_text.count()\ndups_30 = df_dups_text_30.select('id_A').distinct().count()\nuniques = records - dups_30\nprint ('Total records: ', records)\nprint ('Duplicate titles based on {', jaccard_distance, '} jaccard distance: ', dups_30)\nprint ('Unique titles based on {', jaccard_distance, '} jaccard distance: ', jaccard_distance, ': ', uniques)\n\n"}, {"cell_type": "code", "execution_count": null, "id": "c2efb286-6c49-444e-b27c-6de40ef450e2", "metadata": {}, "outputs": [{"data": {"image/png": "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\n", "text/plain": "<Figure size 640x480 with 1 Axes>"}, "metadata": {}, "output_type": "display_data"}], "source": "dups_df = pd.DataFrame.from_dict({'near_dups': [dups_30], 'unique': [uniques]})\nax=dups_df.plot(kind = 'bar',y=['near_dups', 'unique'], fontsize=10, color=['C0', 'C1'], align='center', width=0.8, xlabel=\"Duplicates vs. Unique\")\nax.set_title('School Tweets duplication analysis (Jaccard Distance 0.5 for Text', fontsize=15)\nfor p in ax.patches:\n       ax.annotate(format(p.get_height(), '.1f'), \n                   (p.get_x() + p.get_width() / 2., p.get_height()/2), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points') "}, {"cell_type": "markdown", "id": "a5d0ce6e-3168-426c-9fd7-c1740e5e173a", "metadata": {}, "source": "##### Similarity Analysis on nonprofit organizations"}, {"cell_type": "code", "execution_count": null, "id": "25180999-63a5-444c-af46-8e68f7854239", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<table border='1'>\n<tr><th>text</th></tr>\n<tr><td>School psychology...</td></tr>\n<tr><td>@SpeakinFromTN Fo...</td></tr>\n<tr><td>Revenge of the pr...</td></tr>\n<tr><td>Our midyear refle...</td></tr>\n<tr><td>University endowm...</td></tr>\n</table>\n", "text/plain": "+--------------------+\n|                text|\n+--------------------+\n|School psychology...|\n|@SpeakinFromTN Fo...|\n|Revenge of the pr...|\n|Our midyear refle...|\n|University endowm...|\n+--------------------+"}, "execution_count": 49, "metadata": {}, "output_type": "execute_result"}], "source": "non = nonprofit_organizations.select([\"text\"])\nnon.limit(5)"}, {"cell_type": "code", "execution_count": null, "id": "724e3d41-4b2e-410b-8c28-734ef2a10e89", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "text = non.rdd.map(lambda x : x['text']).filter(lambda x: x is not None)\nStopWords = stopwords.words(\"english\")\ntokens = text\\\n    .map( lambda document: document.strip().lower())\\\n    .map( lambda document: re.split(\" \", document))\\\n    .map( lambda word: [x for x in word if len(x) > 1] )\\\n    .zipWithIndex()"}, {"cell_type": "code", "execution_count": null, "id": "baa570ad-1731-4fec-9559-4986b66aa7f1", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "22/12/08 03:35:57 WARN org.apache.spark.network.server.TransportChannelHandler: Exception in connection from /10.128.1.19:53232\njava.io.IOException: Connection timed out\n\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253)\n\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1133)\n\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n22/12/08 03:35:57 WARN org.apache.spark.network.server.TransportChannelHandler: Exception in connection from /10.128.1.19:53236\njava.io.IOException: Connection timed out\n\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253)\n\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1133)\n\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n                                                                                \r"}], "source": "row = Row('text')\ntext_df=text.map(row).zipWithIndex().toDF(['text','id'])\n# text_df.limit(5)"}, {"cell_type": "code", "execution_count": null, "id": "ebfb42ef-ac59-413e-b89d-7a393d6b5633", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>list_of_words</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[school, psychology, has, diversity, problem,, especially, when, it, comes, to, black, men, npr, https://t.co/3irj7lqszj]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[@speakinfromtn, for, the, undercard, races,, i\u2019m, not, very, well, prepared, this, cycle., has, anyone, published, good, summary?\u2026, https://t.co/bq2jnksnrj]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[revenge, of, the, privileged, and, the, angry., saying, that, college, admissions, cannot, consider, race, but, can, consider, legac\u2026, https://t.co/yo5jp3qvai]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[our, midyear, reflection, asks, what, it, would, take, to, put, equity, at, the, center, of, our, economy,, schools, at, the, center, of\u2026, https://t.co/3xsvngvknk]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[university, endowments, brace, for, losses, with, private, equity, values, tumbling, https://t.co/sibymjzwta, via, @crainsdetroit]</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                                                                                                                                          list_of_words  \\\n0                                             [school, psychology, has, diversity, problem,, especially, when, it, comes, to, black, men, npr, https://t.co/3irj7lqszj]   \n1         [@speakinfromtn, for, the, undercard, races,, i\u2019m, not, very, well, prepared, this, cycle., has, anyone, published, good, summary?\u2026, https://t.co/bq2jnksnrj]   \n2      [revenge, of, the, privileged, and, the, angry., saying, that, college, admissions, cannot, consider, race, but, can, consider, legac\u2026, https://t.co/yo5jp3qvai]   \n3  [our, midyear, reflection, asks, what, it, would, take, to, put, equity, at, the, center, of, our, economy,, schools, at, the, center, of\u2026, https://t.co/3xsvngvknk]   \n4                                   [university, endowments, brace, for, losses, with, private, equity, values, tumbling, https://t.co/sibymjzwta, via, @crainsdetroit]   \n\n   id  \n0   0  \n1   1  \n2   2  \n3   3  \n4   4  "}, "execution_count": 52, "metadata": {}, "output_type": "execute_result"}], "source": "df_tokens = spark.createDataFrame(tokens, [\"list_of_words\",'id'])\n\n#Drop records with no tokens\ndf_tokens = df_tokens.where(col('list_of_words').getItem(0).isNotNull())\ndf_tokens.limit(5).toPandas()"}, {"cell_type": "code", "execution_count": null, "id": "722fbd77-fde0-482b-b222-5dcc61ee9fc6", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "vectorize = CountVectorizer(inputCol=\"list_of_words\", outputCol=\"features\", minDF=1.0)\ndf_vectorize = vectorize.fit(df_tokens).transform(df_tokens)"}, {"cell_type": "code", "execution_count": null, "id": "13cc813e-5d2b-4527-8c51-a6c422d7b0b6", "metadata": {}, "outputs": [], "source": "mh = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", numHashTables=5)\nmodel = mh.fit(df_vectorize)\ndf_hashed = mh.fit(df_vectorize).transform(df_vectorize)"}, {"cell_type": "code", "execution_count": null, "id": "dc2fc248-2b28-4dcf-b1bc-6b95f389bd5f", "metadata": {}, "outputs": [], "source": "df_hashed_text = text_df.join(df_hashed, \"id\", how = 'left')"}, {"cell_type": "code", "execution_count": null, "id": "d59fab71-fbff-46c0-9617-aafd0bbd5ca6", "metadata": {}, "outputs": [], "source": "jaccard_distance = 0.5\n\ndf_dups_text_30 = model.approxSimilarityJoin(df_hashed_text, df_hashed_text, jaccard_distance).filter(\"datasetA.id < datasetB.id\").select(\n            col(\"distCol\"),\n            col(\"datasetA.id\").alias(\"id_A\"),\n            col(\"datasetB.id\").alias(\"id_B\"),\n            col('datasetA.text').alias('text_A'),\n            col('datasetB.text').alias('text_B'),\n#             col('datasetA.list_of_words').alias('words_A'),\n#             col('datasetB.list_of_words').alias('words_B')\n            )"}, {"cell_type": "code", "execution_count": null, "id": "a2ddcbdf-6130-4f96-89f9-51c2b3bbd8e3", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distCol</th>\n      <th>id_A</th>\n      <th>id_B</th>\n      <th>text_A</th>\n      <th>text_B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.095238</td>\n      <td>366</td>\n      <td>550</td>\n      <td>(If we really want equal opportunities for kids from all races, ethnicities, and family income levels, we must let e\u2026 https://t.co/RTagK30nVp,)</td>\n      <td>(If we really want equal opportunities for kids from all races, ethnicities, and family income levels, we must let e\u2026 https://t.co/3rko3zc0ii,)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.142857</td>\n      <td>99</td>\n      <td>209</td>\n      <td>(LGBTQ students protected from discrimination, proposed rules say #TitleIX #LGBTQIA #EdChat #k12 https://t.co/wQUPrI2vio,)</td>\n      <td>(LGBTQ students protected from discrimination, proposed rules say #TitleIX #LGBTQIA #EdChat #k12 https://t.co/RYkg6CVIg2,)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.200000</td>\n      <td>464</td>\n      <td>796</td>\n      <td>(@_lesliethomas @Miss_Snuffy @BlackEquityOrg @DavidLammy @TrevorPTweets @CliveMyrieBBC @skygillian @darshnasoni\u2026 https://t.co/WDdUgBVsRP,)</td>\n      <td>(@_lesliethomas @Miss_Snuffy @BlackEquityOrg @DavidLammy @TrevorPTweets @CliveMyrieBBC @skygillian @darshnasoni\u2026 https://t.co/1vhqq8A2RD,)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.142857</td>\n      <td>639</td>\n      <td>826</td>\n      <td>(New NYC high school admissions rules could slow pandemic-era gains in diversity https://t.co/s9VxwApcGe,)</td>\n      <td>(New NYC high school admissions rules could slow pandemic-era gains in diversity https://t.co/n03voEZ1X6,)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.117647</td>\n      <td>265</td>\n      <td>538</td>\n      <td>(Half the 18 major Southern gubernatorial candidates support restrictions on classroom teaching about race, inequali\u2026 https://t.co/FJQntdklSW,)</td>\n      <td>(Half the 18 major Southern gubernatorial candidates support restrictions on classroom teaching about race, inequali\u2026 https://t.co/70Cq98QLtY,)</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "    distCol  id_A  id_B  \\\n0  0.095238   366   550   \n1  0.142857    99   209   \n2  0.200000   464   796   \n3  0.142857   639   826   \n4  0.117647   265   538   \n\n                                                                                                                                            text_A  \\\n0  (If we really want equal opportunities for kids from all races, ethnicities, and family income levels, we must let e\u2026 https://t.co/RTagK30nVp,)   \n1                       (LGBTQ students protected from discrimination, proposed rules say #TitleIX #LGBTQIA #EdChat #k12 https://t.co/wQUPrI2vio,)   \n2       (@_lesliethomas @Miss_Snuffy @BlackEquityOrg @DavidLammy @TrevorPTweets @CliveMyrieBBC @skygillian @darshnasoni\u2026 https://t.co/WDdUgBVsRP,)   \n3                                       (New NYC high school admissions rules could slow pandemic-era gains in diversity https://t.co/s9VxwApcGe,)   \n4  (Half the 18 major Southern gubernatorial candidates support restrictions on classroom teaching about race, inequali\u2026 https://t.co/FJQntdklSW,)   \n\n                                                                                                                                            text_B  \n0  (If we really want equal opportunities for kids from all races, ethnicities, and family income levels, we must let e\u2026 https://t.co/3rko3zc0ii,)  \n1                       (LGBTQ students protected from discrimination, proposed rules say #TitleIX #LGBTQIA #EdChat #k12 https://t.co/RYkg6CVIg2,)  \n2       (@_lesliethomas @Miss_Snuffy @BlackEquityOrg @DavidLammy @TrevorPTweets @CliveMyrieBBC @skygillian @darshnasoni\u2026 https://t.co/1vhqq8A2RD,)  \n3                                       (New NYC high school admissions rules could slow pandemic-era gains in diversity https://t.co/n03voEZ1X6,)  \n4  (Half the 18 major Southern gubernatorial candidates support restrictions on classroom teaching about race, inequali\u2026 https://t.co/70Cq98QLtY,)  "}, "execution_count": 57, "metadata": {}, "output_type": "execute_result"}], "source": "df_dups_txt_30 = df_dups_text_30\n# df_dups_text_30.cache()\ndf_dups_text_30.limit(5).toPandas()"}, {"cell_type": "code", "execution_count": null, "id": "d9c57201-c2b0-41b5-ac2c-ed7cb7bc6065", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 245:==================================================>  (182 + 4) / 190]\r"}, {"name": "stdout", "output_type": "stream", "text": "Total records:  1042\nDuplicate titles based on { 0.5 } jaccard distance:  53\nUnique titles based on { 0.5 } jaccard distance:  0.5 :  989\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "records = df_hashed_text.count()\ndups_30 = df_dups_text_30.select('id_A').distinct().count()\nuniques = records - dups_30\nprint ('Total records: ', records)\nprint ('Duplicate titles based on {', jaccard_distance, '} jaccard distance: ', dups_30)\nprint ('Unique titles based on {', jaccard_distance, '} jaccard distance: ', jaccard_distance, ': ', uniques)"}, {"cell_type": "code", "execution_count": null, "id": "8a2692e8-a6d6-4c15-b656-49bf53a9b8a8", "metadata": {}, "outputs": [{"data": {"image/png": "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\n", "text/plain": "<Figure size 640x480 with 1 Axes>"}, "metadata": {}, "output_type": "display_data"}], "source": "dups_df = pd.DataFrame.from_dict({'near_dups': [dups_30], 'unique': [uniques]})\nax=dups_df.plot(kind = 'bar',y=['near_dups', 'unique'], fontsize=10, color=['C0', 'C1'], align='center', width=0.8, xlabel=\"Duplicates vs. Unique\")\nax.set_title('Nonprofit duplication analysis (Jaccard Distance 0.5) for Text', fontsize=15)\nfor p in ax.patches:\n       ax.annotate(format(p.get_height(), '.1f'), \n                   (p.get_x() + p.get_width() / 2., p.get_height()/2), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points') \n"}, {"cell_type": "markdown", "id": "2b4f9e2d-a720-421c-a4f4-d7da29ff029b", "metadata": {}, "source": "##### Similarity Analysis on news outlets"}, {"cell_type": "code", "execution_count": null, "id": "ab42f737-6a50-4cfa-a537-17dae49108ac", "metadata": {}, "outputs": [{"data": {"text/html": "<table border='1'>\n<tr><th>text</th></tr>\n<tr><td>@MarshaBlackburn ...</td></tr>\n<tr><td>Lawsuit alleges r...</td></tr>\n<tr><td>Supreme Court tak...</td></tr>\n<tr><td>@WNYT High probab...</td></tr>\n<tr><td>US Supreme Court ...</td></tr>\n</table>\n", "text/plain": "+--------------------+\n|                text|\n+--------------------+\n|@MarshaBlackburn ...|\n|Lawsuit alleges r...|\n|Supreme Court tak...|\n|@WNYT High probab...|\n|US Supreme Court ...|\n+--------------------+"}, "execution_count": 60, "metadata": {}, "output_type": "execute_result"}], "source": "news = news_outlets.select([\"text\"])\nnews.limit(5)"}, {"cell_type": "code", "execution_count": null, "id": "8ffc917f-a588-4774-af58-68ee8980c9e6", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "text = news.rdd.map(lambda x : x['text']).filter(lambda x: x is not None)\nStopWords = stopwords.words(\"english\")\ntokens = text\\\n    .map( lambda document: document.strip().lower())\\\n    .map( lambda document: re.split(\" \", document))\\\n    .map( lambda word: [x for x in word if len(x) > 1] )\\\n    .zipWithIndex()"}, {"cell_type": "code", "execution_count": null, "id": "e97b87e9-b0e0-4010-ae31-dcd98613b984", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "row = Row('text')\ntext_df=text.map(row).zipWithIndex().toDF(['text','id'])"}, {"cell_type": "code", "execution_count": null, "id": "f8cded2d-a178-4ba0-a726-e2c102539e73", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>list_of_words</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[@marshablackburn, why???, did, you, not, see, the, disgraceful, mob, that, verbally, attacked, and, threatened, the, williamson, co\u2026, https://t.co/qmjph8jxjb]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[lawsuit, alleges, racism, in, burlington, area, school, district, https://t.co/ub8trjptjy, via, @youtube, \\n\\nfrom, channel, news, milwaukee,, wisconsin]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[supreme, court, takes, up, race-conscious, college, admissions, https://t.co/prbyg9emvv]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[@wnyt, high, probability, it, gets, struck, down., what\u2019s, happening, to, asian, americans, in, the, college, admission, process, should, be, crime]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[us, supreme, court, to, weigh, end, to, race-based, college, admissions\\nl:, https://t.co/2ywl3jbytv\\nc:, https://t.co/okpoi5x9e6]</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                                                                                                                                     list_of_words  \\\n0  [@marshablackburn, why???, did, you, not, see, the, disgraceful, mob, that, verbally, attacked, and, threatened, the, williamson, co\u2026, https://t.co/qmjph8jxjb]   \n1       [lawsuit, alleges, racism, in, burlington, area, school, district, https://t.co/ub8trjptjy, via, @youtube, \\n\\nfrom, channel, news, milwaukee,, wisconsin]   \n2                                                                        [supreme, court, takes, up, race-conscious, college, admissions, https://t.co/prbyg9emvv]   \n3            [@wnyt, high, probability, it, gets, struck, down., what\u2019s, happening, to, asian, americans, in, the, college, admission, process, should, be, crime]   \n4                              [us, supreme, court, to, weigh, end, to, race-based, college, admissions\\nl:, https://t.co/2ywl3jbytv\\nc:, https://t.co/okpoi5x9e6]   \n\n   id  \n0   0  \n1   1  \n2   2  \n3   3  \n4   4  "}, "execution_count": 63, "metadata": {}, "output_type": "execute_result"}], "source": "df_tokens = spark.createDataFrame(tokens, [\"list_of_words\",'id'])\n\n#Drop records with no tokens\ndf_tokens = df_tokens.where(col('list_of_words').getItem(0).isNotNull())\ndf_tokens.limit(5).toPandas()"}, {"cell_type": "code", "execution_count": null, "id": "484bd878-e03f-4fd9-afec-c4fdd80b57cc", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "vectorize = CountVectorizer(inputCol=\"list_of_words\", outputCol=\"features\", minDF=1.0)\ndf_vectorize = vectorize.fit(df_tokens).transform(df_tokens)"}, {"cell_type": "code", "execution_count": null, "id": "e90c8f83-b060-4445-a582-0f23fb3b31cd", "metadata": {}, "outputs": [], "source": "mh = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", numHashTables=5)\nmodel = mh.fit(df_vectorize)\ndf_hashed = mh.fit(df_vectorize).transform(df_vectorize)"}, {"cell_type": "code", "execution_count": null, "id": "65d8d8f2-b457-48af-95e6-87818e444ba2", "metadata": {}, "outputs": [], "source": "df_hashed_text = text_df.join(df_hashed, \"id\", how = 'left')"}, {"cell_type": "code", "execution_count": null, "id": "23341507-714e-439b-b4df-1d322edff4f4", "metadata": {}, "outputs": [], "source": "jaccard_distance = 0.5\n\ndf_dups_text_30 = model.approxSimilarityJoin(df_hashed_text, df_hashed_text, jaccard_distance).filter(\"datasetA.id < datasetB.id\").select(\n            col(\"distCol\"),\n            col(\"datasetA.id\").alias(\"id_A\"),\n            col(\"datasetB.id\").alias(\"id_B\"),\n            col('datasetA.text').alias('text_A'),\n            col('datasetB.text').alias('text_B')\n            )"}, {"cell_type": "code", "execution_count": null, "id": "9746f36e-2133-4430-8078-e335d8e75980", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "22/12/08 03:43:40 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1053.1 KiB\n                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distCol</th>\n      <th>id_A</th>\n      <th>id_B</th>\n      <th>text_A</th>\n      <th>text_B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.166667</td>\n      <td>572</td>\n      <td>10170</td>\n      <td>(Talk of race, sex in schools divides Americans: AP-NORC poll https://t.co/znMJaQpNNF,)</td>\n      <td>(Talk of race, sex in schools divides Americans: AP-NORC poll https://t.co/XRTDY0Jn3d,)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.375000</td>\n      <td>1444</td>\n      <td>13635</td>\n      <td>(Talk of race, sex in schools divides Americans: AP-NORC poll || Via AP https://t.co/tppGR0mw21,)</td>\n      <td>(UPDATE: Talk of race, sex in schools divides Americans: AP-NORC poll https://t.co/M4GoEAbNLu,)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.222222</td>\n      <td>1082</td>\n      <td>5053</td>\n      <td>(Supreme Court takes up race-conscious college admissions https://t.co/Dno4c2im50,)</td>\n      <td>(Supreme Court takes up race-conscious college admissions https://t.co/OHbPreR3Q8,)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.222222</td>\n      <td>2796</td>\n      <td>3551</td>\n      <td>(Supreme Court takes up race-conscious college admissions https://t.co/JFwkuNbtQh,)</td>\n      <td>(Supreme Court Takes Up Race-Conscious College Admissions https://t.co/06p1BKuEbR,)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.222222</td>\n      <td>984</td>\n      <td>6122</td>\n      <td>(Supreme Court takes up race-conscious college admissions https://t.co/lStEQmdEYl,)</td>\n      <td>(Supreme Court Takes Up Race-Conscious College Admissions https://t.co/swJy7QidlX,)</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "    distCol  id_A   id_B  \\\n0  0.166667   572  10170   \n1  0.375000  1444  13635   \n2  0.222222  1082   5053   \n3  0.222222  2796   3551   \n4  0.222222   984   6122   \n\n                                                                                              text_A  \\\n0            (Talk of race, sex in schools divides Americans: AP-NORC poll https://t.co/znMJaQpNNF,)   \n1  (Talk of race, sex in schools divides Americans: AP-NORC poll || Via AP https://t.co/tppGR0mw21,)   \n2                (Supreme Court takes up race-conscious college admissions https://t.co/Dno4c2im50,)   \n3                (Supreme Court takes up race-conscious college admissions https://t.co/JFwkuNbtQh,)   \n4                (Supreme Court takes up race-conscious college admissions https://t.co/lStEQmdEYl,)   \n\n                                                                                            text_B  \n0          (Talk of race, sex in schools divides Americans: AP-NORC poll https://t.co/XRTDY0Jn3d,)  \n1  (UPDATE: Talk of race, sex in schools divides Americans: AP-NORC poll https://t.co/M4GoEAbNLu,)  \n2              (Supreme Court takes up race-conscious college admissions https://t.co/OHbPreR3Q8,)  \n3              (Supreme Court Takes Up Race-Conscious College Admissions https://t.co/06p1BKuEbR,)  \n4              (Supreme Court Takes Up Race-Conscious College Admissions https://t.co/swJy7QidlX,)  "}, "execution_count": 68, "metadata": {}, "output_type": "execute_result"}], "source": "df_dups_txt_30 = df_dups_text_30\n# df_dups_text_30.cache()\ndf_dups_text_30.limit(5).toPandas()"}, {"cell_type": "code", "execution_count": null, "id": "1754a9a1-7c88-480d-b5c8-141607f6d8f7", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "22/12/08 03:46:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1053.1 KiB\n[Stage 307:====================================================>  (23 + 1) / 24]\r"}, {"name": "stdout", "output_type": "stream", "text": "Total records:  16359\nDuplicate titles based on { 0.5 } jaccard distance:  4392\nUnique titles based on { 0.5 } jaccard distance:  0.5 :  11967\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "records = df_hashed_text.count()\ndups_30 = df_dups_text_30.select('id_A').distinct().count()\nuniques = records - dups_30\nprint ('Total records: ', records)\nprint ('Duplicate titles based on {', jaccard_distance, '} jaccard distance: ', dups_30)\nprint ('Unique titles based on {', jaccard_distance, '} jaccard distance: ', jaccard_distance, ': ', uniques)"}, {"cell_type": "code", "execution_count": null, "id": "a4624f8d-77a1-4cf9-8a44-520c61b1b554", "metadata": {}, "outputs": [{"data": {"image/png": "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\n", "text/plain": "<Figure size 640x480 with 1 Axes>"}, "metadata": {}, "output_type": "display_data"}], "source": "dups_df = pd.DataFrame.from_dict({'near_dups': [dups_30], 'unique': [uniques]})\nax=dups_df.plot(kind = 'bar',y=['near_dups', 'unique'], fontsize=10, color=['C0', 'C1'], align='center', width=0.8, xlabel=\"Duplicates vs. Unique\")\nax.set_title('News Outlets duplication analysis', fontsize=15)\nfor p in ax.patches:\n       ax.annotate(format(p.get_height(), '.1f'), \n                   (p.get_x() + p.get_width() / 2., p.get_height()/2), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points') "}, {"cell_type": "markdown", "id": "fd27d10e-fb81-45a8-824b-1fdd462ebec8", "metadata": {}, "source": "##### Similarity Analysis on social media influencer"}, {"cell_type": "code", "execution_count": null, "id": "07b7564a-cc5e-4a4b-9a7e-4c36275779e3", "metadata": {}, "outputs": [{"data": {"text/html": "<table border='1'>\n<tr><th>text</th></tr>\n<tr><td>RT @uche_blacksto...</td></tr>\n<tr><td>RT @LawBeatInd: C...</td></tr>\n<tr><td>RT @Littlesubgirl...</td></tr>\n<tr><td>RT @yaf: &quot;Liberal...</td></tr>\n<tr><td>For back-to-schoo...</td></tr>\n</table>\n", "text/plain": "+--------------------+\n|                text|\n+--------------------+\n|RT @uche_blacksto...|\n|RT @LawBeatInd: C...|\n|RT @Littlesubgirl...|\n|RT @yaf: \"Liberal...|\n|For back-to-schoo...|\n+--------------------+"}, "execution_count": 71, "metadata": {}, "output_type": "execute_result"}], "source": "inf = social_media_influencer.select([\"text\"])\ninf.limit(5)"}, {"cell_type": "code", "execution_count": null, "id": "e0551851-1426-4cf5-9660-e4cb85927edc", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "text = inf.rdd.map(lambda x : x['text']).filter(lambda x: x is not None)\nStopWords = stopwords.words(\"english\")\ntokens = text\\\n    .map( lambda document: document.strip().lower())\\\n    .map( lambda document: re.split(\" \", document))\\\n    .map( lambda word: [x for x in word if len(x) > 1] )\\\n    .zipWithIndex()"}, {"cell_type": "code", "execution_count": null, "id": "ca4d0e1f-9db0-44ba-8a1c-906ac743f5e1", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "row = Row('text')\ntext_df=text.map(row).zipWithIndex().toDF(['text','id'])"}, {"cell_type": "code", "execution_count": null, "id": "c40996dd-9ad1-4429-a437-cbff6f9a395e", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>list_of_words</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[rt, @uche_blackstock:, have, to, constantly, brace, myself, for, anti-blackness, when, open, this, app., \\n\\ncase, in, point.\\n\\nthis, physician, is, suggest\u2026]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[rt, @lawbeatind:, counsel, (referring, report)girls, from, sc/st, and, muslim, face, the, most, discrimination., non-recognition, of, cultural, and, social\u2026]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[rt, @littlesubgirlm:, cute, asian, skips, school, to, rim, &amp;amp;, suck, cock, https://t.co/dxgpgm1kgj\\n\\n@littlesubgirlm, https://t.co/utbxxonjim]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[rt, @yaf:, \"liberals, want, to, criminalize, dissent:, on, election, integrity,, covid-19,, climate,, critical, race, theory, in, schools, if, you, dare, spe\u2026]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[for, back-to-school,, @massdph's, vaccine, equity, initiative, is, joining, with, communities, to, host, over, 450, covid-19, vacc\u2026, https://t.co/dmjzysenq5]</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                                                                                                                                      list_of_words  \\\n0  [rt, @uche_blackstock:, have, to, constantly, brace, myself, for, anti-blackness, when, open, this, app., \\n\\ncase, in, point.\\n\\nthis, physician, is, suggest\u2026]   \n1    [rt, @lawbeatind:, counsel, (referring, report)girls, from, sc/st, and, muslim, face, the, most, discrimination., non-recognition, of, cultural, and, social\u2026]   \n2               [rt, @littlesubgirlm:, cute, asian, skips, school, to, rim, &amp;, suck, cock, https://t.co/dxgpgm1kgj\\n\\n@littlesubgirlm, https://t.co/utbxxonjim]   \n3  [rt, @yaf:, \"liberals, want, to, criminalize, dissent:, on, election, integrity,, covid-19,, climate,, critical, race, theory, in, schools, if, you, dare, spe\u2026]   \n4    [for, back-to-school,, @massdph's, vaccine, equity, initiative, is, joining, with, communities, to, host, over, 450, covid-19, vacc\u2026, https://t.co/dmjzysenq5]   \n\n   id  \n0   0  \n1   1  \n2   2  \n3   3  \n4   4  "}, "execution_count": 74, "metadata": {}, "output_type": "execute_result"}], "source": "df_tokens = spark.createDataFrame(tokens, [\"list_of_words\",'id'])\n\n#Drop records with no tokens\ndf_tokens = df_tokens.where(col('list_of_words').getItem(0).isNotNull())\ndf_tokens.limit(5).toPandas()"}, {"cell_type": "code", "execution_count": null, "id": "56e64586-9c55-4109-9e2a-ef6faeaddc4b", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "vectorize = CountVectorizer(inputCol=\"list_of_words\", outputCol=\"features\", minDF=1.0)\ndf_vectorize = vectorize.fit(df_tokens).transform(df_tokens)"}, {"cell_type": "code", "execution_count": null, "id": "06bdaf12-b728-4d6d-80ca-cdabc8522382", "metadata": {}, "outputs": [], "source": "mh = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", numHashTables=5)\nmodel = mh.fit(df_vectorize)\ndf_hashed = mh.fit(df_vectorize).transform(df_vectorize)"}, {"cell_type": "code", "execution_count": null, "id": "42305078-d60d-4455-acce-7a34a65f145e", "metadata": {}, "outputs": [], "source": "df_hashed_text = text_df.join(df_hashed, \"id\", how = 'left')"}, {"cell_type": "code", "execution_count": null, "id": "46427750-c4c3-4718-a491-1c7d618449d9", "metadata": {}, "outputs": [], "source": "jaccard_distance = 0.5\n\ndf_dups_text_30 = model.approxSimilarityJoin(df_hashed_text, df_hashed_text, jaccard_distance).filter(\"datasetA.id < datasetB.id\").select(\n            col(\"distCol\"),\n            col(\"datasetA.id\").alias(\"id_A\"),\n            col(\"datasetB.id\").alias(\"id_B\"),\n            col('datasetA.text').alias('text_A'),\n            col('datasetB.text').alias('text_B'),\n            )"}, {"cell_type": "code", "execution_count": null, "id": "8d48a818-fd54-4697-bf3e-79a855851784", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "22/12/08 03:49:44 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1328.2 KiB\n22/12/08 03:50:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1372.6 KiB\n22/12/08 03:50:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1373.5 KiB\n22/12/08 03:50:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1473.2 KiB\n22/12/08 04:13:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1384.6 KiB\n22/12/08 04:13:37 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 352.0 (TID 22186) (hub-msca-bdp-dphub-students-backup-zhiliny-w-1.c.msca-bdp-students.internal executor 43): FetchFailed(BlockManagerId(50, hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal, 7337, None), shuffleId=85, mapIndex=2, mapId=22168, reduceId=0, message=\norg.apache.spark.shuffle.FetchFailedException: Failure while fetching StreamChunkId[streamId=1268551880000,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=50)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage12.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage12.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.network.client.ChunkFetchFailureException: Failure while fetching StreamChunkId[streamId=1268551880000,chunkIndex=0]: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=50)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getContinuousBlocksData(ExternalShuffleBlockResolver.java:188)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:489)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler$ShuffleManagedBufferIterator.next(ExternalBlockHandler.java:445)\n\tat org.apache.spark.network.server.OneForOneStreamManager.getChunk(OneForOneStreamManager.java:87)\n\tat org.apache.spark.network.server.ChunkFetchRequestHandler.processFetchRequest(ChunkFetchRequestHandler.java:103)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:107)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:182)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 04:13:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1328.2 KiB\n22/12/08 04:14:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1373.5 KiB\n22/12/08 04:14:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1372.6 KiB\n22/12/08 04:14:08 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 17.0 in stage 350.0 (TID 22229) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 53): FetchFailed(BlockManagerId(49, hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal, 7337, None), shuffleId=82, mapIndex=173, mapId=21577, reduceId=2, message=\norg.apache.spark.shuffle.FetchFailedException: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=49)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.lambda$getLocalDirs$3(ExternalShuffleBlockResolver.java:386)\n\tat java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)\n\tat java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)\n\tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)\n\tat java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n\tat java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getLocalDirs(ExternalShuffleBlockResolver.java:390)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler.handleMessage(ExternalBlockHandler.java:256)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler.receive(ExternalBlockHandler.java:137)\n\tat org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:161)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.RuntimeException: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=49)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.lambda$getLocalDirs$3(ExternalShuffleBlockResolver.java:386)\n\tat java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)\n\tat java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)\n\tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)\n\tat java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n\tat java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getLocalDirs(ExternalShuffleBlockResolver.java:390)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler.handleMessage(ExternalBlockHandler.java:256)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler.receive(ExternalBlockHandler.java:137)\n\tat org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:161)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:208)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 04:14:08 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 18.0 in stage 350.0 (TID 22230) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 54): FetchFailed(BlockManagerId(49, hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal, 7337, None), shuffleId=82, mapIndex=177, mapId=21581, reduceId=0, message=\norg.apache.spark.shuffle.FetchFailedException: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=49)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.lambda$getLocalDirs$3(ExternalShuffleBlockResolver.java:386)\n\tat java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)\n\tat java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)\n\tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)\n\tat java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n\tat java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getLocalDirs(ExternalShuffleBlockResolver.java:390)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler.handleMessage(ExternalBlockHandler.java:256)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler.receive(ExternalBlockHandler.java:137)\n\tat org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:161)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage8.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.RuntimeException: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=49)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.lambda$getLocalDirs$3(ExternalShuffleBlockResolver.java:386)\n\tat java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)\n\tat java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)\n\tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)\n\tat java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n\tat java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getLocalDirs(ExternalShuffleBlockResolver.java:390)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler.handleMessage(ExternalBlockHandler.java:256)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler.receive(ExternalBlockHandler.java:137)\n\tat org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:161)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:208)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 04:14:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1328.2 KiB\n22/12/08 04:14:08 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 13.0 in stage 349.0 (TID 22253) (hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal executor 54): FetchFailed(BlockManagerId(49, hub-msca-bdp-dphub-students-backup-zhiliny-sw-ztfh.c.msca-bdp-students.internal, 7337, None), shuffleId=82, mapIndex=173, mapId=21577, reduceId=2, message=\norg.apache.spark.shuffle.FetchFailedException: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=49)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.lambda$getLocalDirs$3(ExternalShuffleBlockResolver.java:386)\n\tat java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)\n\tat java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)\n\tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)\n\tat java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n\tat java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getLocalDirs(ExternalShuffleBlockResolver.java:390)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler.handleMessage(ExternalBlockHandler.java:256)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler.receive(ExternalBlockHandler.java:137)\n\tat org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:161)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:777)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:224)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.RuntimeException: java.lang.RuntimeException: Executor is not registered (appId=application_1670420302918_0013, execId=49)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.lambda$getLocalDirs$3(ExternalShuffleBlockResolver.java:386)\n\tat java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)\n\tat java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)\n\tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)\n\tat java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n\tat java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)\n\tat org.apache.spark.network.shuffle.ExternalShuffleBlockResolver.getLocalDirs(ExternalShuffleBlockResolver.java:390)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler.handleMessage(ExternalBlockHandler.java:256)\n\tat org.apache.spark.network.shuffle.ExternalBlockHandler.receive(ExternalBlockHandler.java:137)\n\tat org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:161)\n\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:109)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat org.sparkproject.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat org.sparkproject.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat org.sparkproject.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat org.sparkproject.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat org.sparkproject.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat org.sparkproject.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat org.sparkproject.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat org.sparkproject.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:208)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t... 1 more\n\n)\n22/12/08 04:14:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1373.5 KiB\n22/12/08 04:14:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1372.6 KiB\n22/12/08 04:14:13 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1473.2 KiB\n22/12/08 04:14:44 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1384.6 KiB\n                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distCol</th>\n      <th>id_A</th>\n      <th>id_B</th>\n      <th>text_A</th>\n      <th>text_B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>228</td>\n      <td>7901</td>\n      <td>(RT @joingles: Trump says we will \u201cget Critical Race Theory out of our classrooms.\u201d Fact check - We haven\u2019t been able to find one k-12 schoo\u2026,)</td>\n      <td>(RT @joingles: Trump says we will \u201cget Critical Race Theory out of our classrooms.\u201d Fact check - We haven\u2019t been able to find one k-12 schoo\u2026,)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>262</td>\n      <td>38058</td>\n      <td>(RT @santiagomayer_: The news is out: \\n\\nAs state legislatures try to restrict access to contraception, @VotersTomorrow is going to college c\u2026,)</td>\n      <td>(RT @santiagomayer_: The news is out: \\n\\nAs state legislatures try to restrict access to contraception, @VotersTomorrow is going to college c\u2026,)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>149</td>\n      <td>4734</td>\n      <td>(RT @Ccampbellbased: BLM activist Demands Reparations &amp;amp; George Floyd Bill For Schools at Frisco, TX City Council https://t.co/ocgAR08ElE,)</td>\n      <td>(RT @Ccampbellbased: BLM activist Demands Reparations &amp;amp; George Floyd Bill For Schools at Frisco, TX City Council https://t.co/ocgAR08ElE,)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>110</td>\n      <td>1793</td>\n      <td>(RT @MariahGraceArtt: It\u2019s college graduation season and I want to make it very clear that it is okay if you dropped out,)</td>\n      <td>(RT @MariahGraceArtt: It\u2019s college graduation season and I want to make it very clear that it is okay if you dropped out,)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>190</td>\n      <td>23449</td>\n      <td>(RT @ACLUFL: BREAKING: We are challenging a Florida law that bans educators and students from discussing race and gender in college classroo\u2026,)</td>\n      <td>(RT @ACLUFL: BREAKING: We are challenging a Florida law that bans educators and students from discussing race and gender in college classroo\u2026,)</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   distCol  id_A   id_B  \\\n0      0.0   228   7901   \n1      0.0   262  38058   \n2      0.0   149   4734   \n3      0.0   110   1793   \n4      0.0   190  23449   \n\n                                                                                                                                              text_A  \\\n0    (RT @joingles: Trump says we will \u201cget Critical Race Theory out of our classrooms.\u201d Fact check - We haven\u2019t been able to find one k-12 schoo\u2026,)   \n1  (RT @santiagomayer_: The news is out: \\n\\nAs state legislatures try to restrict access to contraception, @VotersTomorrow is going to college c\u2026,)   \n2     (RT @Ccampbellbased: BLM activist Demands Reparations &amp; George Floyd Bill For Schools at Frisco, TX City Council https://t.co/ocgAR08ElE,)   \n3                         (RT @MariahGraceArtt: It\u2019s college graduation season and I want to make it very clear that it is okay if you dropped out,)   \n4    (RT @ACLUFL: BREAKING: We are challenging a Florida law that bans educators and students from discussing race and gender in college classroo\u2026,)   \n\n                                                                                                                                              text_B  \n0    (RT @joingles: Trump says we will \u201cget Critical Race Theory out of our classrooms.\u201d Fact check - We haven\u2019t been able to find one k-12 schoo\u2026,)  \n1  (RT @santiagomayer_: The news is out: \\n\\nAs state legislatures try to restrict access to contraception, @VotersTomorrow is going to college c\u2026,)  \n2     (RT @Ccampbellbased: BLM activist Demands Reparations &amp; George Floyd Bill For Schools at Frisco, TX City Council https://t.co/ocgAR08ElE,)  \n3                         (RT @MariahGraceArtt: It\u2019s college graduation season and I want to make it very clear that it is okay if you dropped out,)  \n4    (RT @ACLUFL: BREAKING: We are challenging a Florida law that bans educators and students from discussing race and gender in college classroo\u2026,)  "}, "execution_count": 79, "metadata": {}, "output_type": "execute_result"}], "source": "df_dups_txt_30 = df_dups_text_30\n# df_dups_text_30.cache()\ndf_dups_text_30.limit(5).toPandas()"}, {"cell_type": "code", "execution_count": null, "id": "bf959d1d-a7a3-4c74-9119-82a23fd5a0c3", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "22/12/08 04:15:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1328.2 KiB\n22/12/08 04:17:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1372.6 KiB\n22/12/08 04:17:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1373.5 KiB\n22/12/08 04:17:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1473.2 KiB\n22/12/08 04:36:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1383.9 KiB\n22/12/08 04:37:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1366.7 KiB\n"}, {"name": "stdout", "output_type": "stream", "text": "Total records:  43678\nDuplicate titles based on { 0.5 } jaccard distance:  22244\nUnique titles based on { 0.5 } jaccard distance:  0.5 :  21434\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "records = df_hashed_text.count()\ndups_30 = df_dups_text_30.select('id_A').distinct().count()\nuniques = records - dups_30\nprint ('Total records: ', records)\nprint ('Duplicate titles based on {', jaccard_distance, '} jaccard distance: ', dups_30)\nprint ('Unique titles based on {', jaccard_distance, '} jaccard distance: ', jaccard_distance, ': ', uniques)"}, {"cell_type": "code", "execution_count": null, "id": "ca8a6967-7e47-42de-9234-a5a15b76504f", "metadata": {}, "outputs": [{"data": {"image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHECAYAAAAwOIA0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWMElEQVR4nO3dd1gU18IG8Hdpy9KW3hRFjWDBigVsYAMLKpiIikFJjMZrC1FiYm5yJYmfxm5MMc2IxpbEdo2FQKISvViJRI1dERuICi6CSD3fH96d68rSFEQm7+959tGdOTNzZmbLy5kzZxVCCAEiIiIiGTKo7QoQERER1RQGHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQadGhYfH4/g4GA4OzvDxMQEdnZ2aNGiBUaNGoVvvvkGBQUFz7Q+/v7+UCgUuHz58lOt5/Lly1AoFPD396/0MhEREVAoFFAoFHj99dfLLFdQUAAbGxup7N69e5+qrpWt1+PbcXd3h0KheCbbjomJqZb1Xbx4ESEhIbC3t4eBgYG0X09yvujJRUdHV+t5raqYmBgoFApER0c/V/UqS1n1pbLVxjHbu3cvFAoFIiIintk2qwODTg2aNWsWAgIC8O9//xsODg4YNGgQevfuDWNjY6xfvx7jx49HZmZmbVezVvz0009lhrzt27fj7t27z7ZCMlBSUoKXXnoJW7duRdOmTfHyyy9jzJgxcHZ2ru2q0d9cWX9MED0LRrVdAbk6evQoPvzwQ5iYmGDLli0YMGCAzvzr16/jm2++gVKpfKb1Wr16Ne7fv4969eo90+0+ql27djh27Bh27tyJ4ODgUvPXrFkDQ0NDeHl54c8//3z2Ffyv3377DYWFhbW2/aq6fPkykpOT0b17d/z++++l5hFNnjwZI0aMgIuLS21XRUdISAh8fHxgb29f21WhcnTq1AmnT5+GWq2u7apUCYNODdmyZQsAIDQ0tFTIAYB69erVSjNtgwYNnvk2HxcWFoY///wTa9euLRV07t69i507d6J3795QKBS1GnSaNGlSa9t+EteuXQMANG7cuJZrQs8re3v75zJMqNXqOvfl+XdkZmaGZs2a1XY1qoyXrmrIrVu3AAAODg5VXvbUqVMYNWoUXFxcYGJignr16mH06NE4e/Zsucu88soraNiwIZRKJZycnNCjRw988sknOuXK6qOzb98+TJ48Ga1bt4aNjQ1UKhWaNWuGd955p9ovI9WvXx9+fn7Yvn07NBqNzrwff/wR+fn5ePnll8tdR05ODj788EO0atUKZmZmsLKygp+fH7Zu3VrmMps2bUKnTp2gUqng5OSE0aNH48aNG2WWL6uPzo4dO/Dqq6+iefPmsLKygrm5Odq0aYM5c+YgPz+//J2vpEfP09atW+Hj4wNzc3PY2tpi5MiRUqjRUigU8PPzAwCsWrVK6t9UUZ+civpslNdP6cSJExg1ahTq1asHpVIJV1dXvPLKK3pbjx7dzokTJzB48GDY2NjA3Nwcfn5+SExMLLOOBw4cQGhoKFxdXaFUKlGvXj0EBgZizZo1pcreunULUVFR8PT0hKmpKWxsbNC/f/9SLVyAbn+D9PR0vPbaa6hfvz6MjIywdOnSMuvzqISEBPj7+8PCwgJ2dnYICQnBmTNnyiyvUCjg7u6ud15ZfS4efS2sWbMG3t7eMDMzg6OjI8aMGYPr169Xqq5A+ee7sLAQX3zxBbp27Qpra2uYmZnBw8MD48aNw8mTJ6VyDx48wIoVKzBkyBA0btwYKpUK1tbW6NGjBzZs2KB3n1etWgUA6Nmzp/TafPRzqLz+Jvfv38dHH30ELy8vqFQqqNXqMrcF6L5mv/32W7Ru3RoqlQrOzs54/fXXq/x5VtX3+6P7cuXKFYSFhcHBwQEqlQodOnTAzz//XGoZIQTWr1+PESNGwMPDA+bm5rC0tESnTp3wxRdfoKSkpFJ1HThwIBQKBeLj4/XOz83NhZWVFdRqNXJzc6Xphw4dQkhIiPT94ezsjE6dOmHmzJnIycmRypXVR0cIgQ0bNqBHjx5wdnaGqakp3Nzc0KdPH3z++eeVqnuNElQjPvjgAwFANGjQQGRkZFR6uV9//VWoVCoBQLRv316MGDFCtG3bVgAQFhYW4vfffy+1zI8//iiUSqUAIFq2bClGjBghAgIChKurq3j8FPv5+QkAIiUlRWd6586dhVKpFN7e3mLo0KFi4MCBwsXFRVrnvXv3dMqnpKQIAMLPz6/S+zZmzBgBQKxfv158++23AoBYsWKFTpkePXoIMzMzce/ePREYGCgAiD179uiUSU9PFy1atBAARL169cTgwYNFnz59hLm5uQAg5s6dW2rbn376qQAgDA0NRa9evURoaKhwcXERbm5uIigoSO92GjZsWOr4CSGEk5OTsLCwEJ07dxbDhg0TgYGBwsbGRgAQvXr1EkVFRVU+JitXrtSZrj1Pb731ljAwMBCdOnUSQ4cOFW5ubgKAaNq0qbh//77OerTHq0mTJmLMmDFizJgx0rEo63zNmjVL7/YrOgYbN24UJiYmAoDw9vYWL730kmjXrp0AIOzs7MTJkyf1bmfSpEnCzMxMeHh4iBdffFG0adNGABCmpqbixIkTpbazZMkSoVAoBADRsWNHMWLECNGrVy9hb28vGjZsqFP29OnTol69etIxCAkJET169BAmJibCwMBArF27Vqf8nj17BAAxYMAAUb9+feHs7CxeeuklERQUJL766iu9x+NRW7duFYaGhgKA6NKlixgxYoRo3LixsLKyEqNGjdJ7XAGUqrfWypUrBQAxa9Ysnena18KkSZOEQqEQPXr0ECNGjBDu7u4CgKhfv764evVqpdZV1vnOyckR3bt3lz5n+vfvL0JDQ0XHjh2FkZGRznpOnz4tAAgnJyfh5+cnhg8fLvz8/ISxsbHebY4ZM0Y0adJEABCBgYHSa3PMmDHi1q1b5dY3OztbeHt7CwDCwcFBvPTSS6J///7S590bb7xR6jhqX7NvvfWWMDExEV27dhXBwcHC0dFRABDdu3cXJSUles+BPlV9v2v3ZcyYMcLR0VE0aNBABAcHC19fXwFAGBgYiF9++UVnmby8PAFA2NjYiK5du4rhw4eL3r17CzMzM2ldj9N3zLZt2yYAiGHDhundF+3n7oQJE6Rp27dvFwYGBsLQ0FB6bQUGBopGjRqV+q7Qvmcer8/bb78tAAhLS0vRv39/MXLkSOHv76/3fVobGHRqyIULF4SpqakAIKysrMTo0aPFN998I06ePFnmmywnJ0c4OTkJAGL58uU68xYvXix9qD148ECafu7cOWFqaiqMjY3FDz/8oLNMcXGx+Pnnn3WmlRV0duzYITIzM3WmPXjwQIwfP14AEB988IHOvKcNOnfv3hWmpqaiZ8+e0vzU1FShUCjEyJEjhRCizKDTv39/AUDMmDFDFBQUSNMvXrwomjRpIgwNDcWff/6pU1elUimUSqXOunJzc0Xfvn0FgCoFnS1btoicnBydadnZ2VJgWrVqVZWPSVlBx9zcXPz22286de7SpYvekFjWh5AQ1Rt0Ll26JMzMzIRarRYJCQk681atWiWFEn3bASDmzZunMy8yMlIAEOHh4TrTExIShEKhEFZWVqXOTX5+voiNjZWeFxUVCS8vLwFAfPLJJzrvsT/++EPY2dkJc3NzcfPmTWm69ngBECEhISIvL0/vMdAnOztb2NvbCwBi3bp10vTCwkLpnFZ30DEyMhI7duyQphcUFEiBKiQkpFLrKut8jx07VgAQPXv2FLdv39aZd+3aNXH06FHp+e3bt8Uvv/wiiouLdcpdunRJuLu7CwMDg1KfL9pj8vh5rKi+kydPFgBEnz59dP7YOn36tBRcHj0mQvzvNevi4iKOHTsmTb9165Z44YUXBACd91RFqvp+1+4LADFlyhRRWFgozVu6dKkUth5VWFgoNm3aJPLz83WmZ2RkiA4dOggApd5r+o5ZUVGRcHNzEyYmJnr/wO7cubMAIJKSkqRpfn5+QqFQ6JxjrUOHDons7Gzpub7PmLy8PKFUKoW7u7u4c+dOqf16vN61gUGnBv3yyy9Sq8qjD0dHR/HWW2+JrKwsnfLfffed3jeBlvYvm/Xr10vT/vGPfwgAYvLkyZWqU1lBpyz3798XRkZGon379jrTnzboCCHESy+9JAwMDMS1a9eEEELMmTNH54NLX9A5duyY9Be0vsC4detW6QNG6/333xcAxLhx40qVP3PmjNRiUNmgU5bz588LAGLo0KGVXqaioPPee++VWmbTpk16A82zCjpvvPGGAFBmq0dwcHCpD1Ptdrp161aq/O3bt/UGAG2gXbhwod7tPGrLli0CgBSSH6f9glm0aJE0TXu8lEql9BqsrBUrVggAom/fvqXmZWZmCgsLi2oPOmFhYaWWuX37tjA3N9d5H5W3Ln3n+8aNG8LQ0FCoVKpSLUNV9c033wgAYtmyZTrTnyTo5OTkCJVKJQwMDMS5c+dKLbNs2TKplehR2tfst99+W2qZRYsW6T0uT6Ks97t2Xxo3bqzzh5gQD7/4bWxshLGxcalQU5b4+HgBQEybNk3vdh7fF+3VhMffNydOnBAARLt27XSmN2/eXFhbW1eqLvo+Y27evCkAiCFDhlRqHbWBnZFrUEBAAC5duoRt27YhPj4ehw4dwsmTJ5GRkYEFCxZgy5YtSExMlPrx7Nu3DwAwatQovet7+eWXkZSUhH379mHEiBEAgF9//RUAyh2XprKuX7+On3/+GWfOnEF2drZ0XdjExATnz59/6vU/7uWXX8bGjRuxbt06vPXWW1i7di0cHR0REBBQ5jLaa89DhgzR23ekW7duAIAjR45I0/bv3w/gYcfwx3l6eqJdu3b4448/qlT38+fPY+fOnbhw4QJyc3NRUlICIYQ0r7roOxYeHh4AgLS0tGrbTlU8eg706datG7Zu3YojR46gffv2OvP07Y+dnR3s7Ox09qe4uFi6FXn8+PGVrpO+u/i0dQJ0Xxda7du3r/JdiOW9pmxsbBAQEIDNmzdXaZ0V0b7nH2VnZ4e+ffti69atSExMxLBhw6q83j179qC4uBgDBgxA/fr1K73c/v37sXfvXly/fh0PHjyAEEI6h9XxHkhKSkJeXh58fHzQtGnTUvPDw8MxdepU/Oc//4EQotTnQXW+d57k/e7v7w9jY2OdaUZGRmjcuDGSkpJw586dUne/JScnIy4uDqmpqbh//z6EELh3716523nca6+9ho8++gjffvstpk+fLk3/5ptvAJR+P3l7e2PNmjUYO3Ys3nzzTXh5eVVqO1qOjo6oX78+duzYgQULFmDUqFFwdXWt0jpqGoNODVMqlRg2bJj0AXTr1i3ExMQgOjoaFy5cwLvvviu9ALUdY8vqrKid/mgH2qtXrwJ4+jttFi9ejJkzZz7TAQwHDBgAOzs7rF27Fn369MFff/2FKVOmwMio7JeltvPi22+/jbfffrvMcrdv35b+rz1eZd1x1qBBg0oHHSEEoqKisGTJEumD7nHaD6bqoO+Lx8LCAgCqreNzVWnPQUXj8zx6DrTK+iK1sLDAnTt3dJbNy8uDo6MjLC0tK12n4cOHY/jw4VWq05PciViZ11R1a9iwod7p+j4XqkL7GVLZuww1Gg2GDh2K3bt3l1mmOt4DFX0eWltbQ61WQ6PRIDs7u9RdW9Xx3nma93t5r/XH61BQUICIiAisX7++zLpU9pi6uroiKCgIW7duxb59+9C9e3fk5+djzZo1MDMzQ1hYmE75OXPm4MSJE/juu+/w3Xffwd7eHl26dEFwcDDCwsIqNQTKqlWrMGLECMyYMQMzZsxAo0aN0KNHD4SFhZX7h+uzwqDzjDk4OOCtt96CSqXClClTsGPHjlJlKhqN9/H52jsYntTBgwcxffp0qNVqfP311/D394ezs7P0And1da2R1gNjY2MMGzYMX375Jd59910AqPBuq+LiYgBA9+7dyw13j95Cq/2Aqo5Rjn/44QcsXrwY9evXx9KlS+Hr6wsHBwcYGxujoKAASqWyzA/EJ1HTIzNXRN/dHsXFxVAoFBg9enS5y7Zs2bLUtKruT2XLa18X/fv3h6OjY5nl9N0aa2pqWqU6AdX7mtKq7J01ZdXlaVV2X95++23s3r0bPXr0wIcffggvLy9YW1vD0NAQcXFxCAwMfObvAX1lavv9XpXtL168GOvXr4eXlxcWLFiA9u3bw8bGBsbGxjh37hw8PT2rdEwnTJiArVu34ttvv0X37t2xadMmZGZm4pVXXoGVlZVOWTc3Nxw9ehS7d+/G9u3bkZCQgJ9//hnbtm3D/PnzkZiYCBsbm3K316tXL1y4cAHbt29HbGwsEhISsGrVKqxatQqhoaH44YcfKl33msCgU0u0t/0++hemtrkvJSVF7zKpqakAoNPc6ebmhvPnz+PixYtVbnLU0o75M3v2bIwZM0ZnXl5eHtLT059ovZXx8ssv48svv0RsbCyaNm2KTp06lVte+1fSSy+9hKlTp1ZqG66urjh37hxSU1P1NoFfuXKl0vXVHqvly5cjKChIZ96lS5cqvZ7nhYmJCQDo3EKqVVxcrPfc169fHxcvXsSyZctKfWhWF3t7e6hUKty8eRP37t2rsFVH+7qYMGECBg8eXCN1epT2vap9Tz6urNeUsbGx3mMN/K9lpSypqalo3bp1mdt60ssFbm5uAIALFy5UqvyWLVtgaGiIbdu2lWpFqc73QEWfhxqNBhqNRroVuyY8q/e7djvasPO02wkICEDjxo3x008/4ZNPPpGuGowbN05veSMjIwQEBEitL1euXMErr7yC3bt34+OPP8a8efMq3KaVlRXCwsKkFqODBw9i2LBh+PHHHxEREYH+/ftXeT+qC8fRqSEVpe+LFy8C0P1w6t69OwBg7dq1epfRTteWA4A+ffoAAL7++usnrmtWVhaA/33gPeqnn36q1r/OHte1a1e0bdsWdnZ2GDt2bIXltftb3ng5j9P2z/jpp59KzTt37hySk5Mrva7yjtWPP/5Y6fU8L7Sh+dy5c6Xm7d69W+/I0E9yDqrK0NBQ+mNA+yFdnmdRp0eV95q6e/cu4uLi9C7n4uKCO3fu6P3pl7KW0dL3V3FmZibi4uKgUCjg6+tbmaqX4u/vD0NDQ+zcubNSY/JkZWXB0tJS7wB/Zb0HtIG6qKio0vXy9vaGSqXC4cOH9fZP0Y6j1K1btxpr+XxW7/fq3o5CocC4ceOQl5eHDz74AAkJCWjZsmWlXyMNGjSQugacOHGiytsHAB8fH4SHhz/VOqoLg04Nef/99zFjxgy9f42cP39e6iQ2dOhQaXpoaCicnJywb9++UsFl2bJlOHLkCOrXr4+QkBBpemRkJExNTfHll19i06ZNOsuUlJRg586dFdZV20FvxYoVOl9sp06dKrcfTHU5duwYbt++Xalt+fj4oHfv3tizZw/efPPNUn8dl5SUIC4uTuosCgCvvPIKTExMsHr1aqnDN/CwteqNN96o0iUD7bH6+uuvdQLgvn37sGDBgkqv53mhHWRwzZo1OgP9Xbp0CVOmTNG7zPTp06FSqfDmm2/qHfwsMzMTX3zxBfLy8p6qbm+//TYUCgU++ugjnfMGPBzc7pdffpGev/TSS2jWrBliYmIwb968UgGtoKAAmzdvrrYP3GHDhsHW1hZxcXE6X0TFxcWYPn16ma022uP90UcfSdOEEJg7d265gyYCD7/wHt3noqIivPnmm8jNzcXgwYOr1JH4Ua6urhg9ejTy8vIQERFRKoTduHFDpw+bh4cH7t69Wyp4LVmyBHv27ClzGwDKHfT0cebm5nj11VdRUlKCSZMm6Qxwd+7cOcyePRsAynydVodn9X7XbufLL7/Umb5x40asXr36idb56quvwsTEBEuXLoUQoszWnCVLluDmzZulpsfGxgKouL/ZlStXEBMTg/v37+tMz8/Pl14PtT4i/7O8xevvRHsLrkKhEM2aNRMhISEiNDRU+Pj4CAMDAwE8HGjt7t27Oss9OmCgt7e3GDlypDQQm7m5ud4BA9etWycN1uXl5SUN+FTZAQNv374tnJ2dBQDRqFEjERoaKvr06SOMjY3FsGHD9N5iXB23l1ekvAEDW7duLQAIW1tb0atXLzF8+HDRrVs34eDgIACIJUuW6CyzZMkSATwcMLB3795i+PDhwtXVVdSvX79KAwaePXtWGpiwRYsWYsSIEaJ79+5CoVCIqKiocm8fLu+YlHV7ub5hAMo69k9ye7kQQowePVoAEGq1WgwaNEj06tVLmJmZlXnuhXh4i7v2derp6SmCg4PFkCFDRNu2baWBBB8dPuFJByZcsGCBNCxDp06dxMiRI0Xv3r3LHDCwQYMGAv8dQyUwMFAMGzZM+Pj4CGtrawFAbNmypVLHqzI2btwovZe7du0qRo4cKZo0aVLugIEnT56Ujlvbtm3Fiy++KDw8PIRKpRITJ04s9/Zy7YCBfn5+YuTIkdKAbq6uriI1NVVnmaqOo5OdnS0NaGdpaSkGDBggQkNDRadOnUoNGLhmzRrpnHTv3l2MHDlStGjRQhgYGIg333xT7zE9evSoUCgUQqlUiiFDhoixY8eKsWPHSmP2VGbAQEdHRzFs2DAxYMAAaYyyqVOnljov5Q0LUdVz/iTv97L2RUvfezshIUEafFL7ua8dP0e7ncffuxVtRwghQkNDpSEUHh/jRkutVgsDAwPRrl07ERoaKoYNGyY8PT0FAGFvby8uXLggldV3/LRDfpiZmYkePXqIsLAwMWTIEOmzuFOnTpW+lb6msEWnhrz33ntYvXo1wsLCYGRkhISEBGzevBkXLlyAn58fPv/8cyQmJpZq/u3duzeOHDkiDfO/ceNGpKenS7eWP3rZSmvkyJE4cuQIwsLCcOfOHWzatAnJyclo2rQpli1bVmFd7ezspOULCgqwbds2XL9+HR9++GG5dwHUFicnJxw8eBCLFy9G06ZNceTIEWzduhXXrl1Du3bt8Pnnn5fq1BwZGYkff/wRbdu2xf79+/Hbb7/B398fBw8ehJ2dXaW37eHhgSNHjmDQoEG4ffs2tm3bhpycHHz11Vd1skUHeHhp6J133oGVlRV++eUXpKam4t133y333A8dOhR//vknXn/9dRQWFmLXrl3Yu3cv8vPzMWrUKGzfvr1afrsoKioKe/fuxZAhQ5CSkoKNGzfizJkz8Pb2xpw5c3TKNmvWDMnJyYiOjoajoyP279+PHTt24NatW+jRowdWrlwpXeKqDi+++CLi4+PRvXt3HDt2DLt27UKLFi1w4MABvPDCC3qXadmyJXbv3g1/f3+cO3cO8fHxaNKkCQ4cOICOHTtWeCxWrlwJjUaDLVu2IDs7G+Hh4Th06NBT/8VsaWmJPXv2YMmSJfD09ERCQgK2b9+Ou3fv4tVXX9W5bX3UqFHYsWMHfHx8kJycjF27dsHV1RW7d+8us3+U9hbmli1bIi4uDitWrMCKFSsqvJPI0tISCQkJ+OCDD2Bvb49t27Zh37596NChA9atW1fqJ26q27N6v/fo0QP79+9Hr169cOnSJWzfvh0mJibYtGkTJk2a9MTr7d27N4CHr1VbW1u9ZT799FOMGDEC9+/fx65duxAbGwtDQ0NERUXh+PHjFd6N16RJEyxcuBD+/v64cuUKNm/ejP/85z9wd3fHsmXLsHfvXunSZW1RCFGDHTCIiOip+Pv7IyEhASkpKWXeak2kT0BAAOLj47Fnz54Kf/dOztiiQ0REJDOHDx/Gr7/+ipYtW/6tQw7A28uJiIhk45133sGVK1ewY8cOCCFKXeL9O2LQISIikokNGzbg6tWrcHd3x/z585/JuFLPO/bRISIiItliHx0iIiKSLQYdIiIikq2/dR+dkpIS3LhxA5aWlrX+44lERERUOUII3Lt3D66urjAwKL/N5m8ddG7cuKH3t0WIiIjo+Xf16tUKf/7kbx10tL94e/Xq1Rr7FWYiIiKqXtnZ2XBzc6vUL9f/rYOO9nKVlZUVgw4REVEdU5luJ+yMTERERLLFoENERESyxaBDREREsvW37qNDRER1W3FxMQoLC2u7GlTNjI2NYWhoWC3rYtAhIqI6RwiB9PR03L17t7arQjXE2toazs7OTz3OHYMOERHVOdqQ4+joCDMzMw76KiNCCNy/fx8ZGRkAABcXl6daH4MOERHVKcXFxVLIsbOzq+3qUA1QqVQAgIyMDDg6Oj7VZSx2RiYiojpF2yfHzMyslmtCNUl7fp+2DxaDDhER1Um8XCVv1XV+GXSIiIhIthh0iIiISMfly5ehUCiQnJxc21V5auyMTEREsuD+zo5nur3LHw98ptujJ8MWHSIiIhkrKCio7SrUKgYdIiKiZ8Tf3x9Tp07FjBkzYGtrC2dnZ0RHR0vzNRoNxo8fD0dHR1hZWaFXr174888/pfkXL17EkCFD4OTkBAsLC3Ts2BG//vqrzjbc3d0xe/ZsREREQK1WY9y4cRXW6/Dhw2jXrh1MTU3RoUMHHDt2TGd+TEwMrK2tdaZt3bpVp8NwdHQ02rZti6+++gpubm4wMzPDsGHDdAZ13Lt3Lzp16gRzc3NYW1uja9euSE1NrcSRe3IMOkRERM/QqlWrYG5ujkOHDmH+/Pn48MMPER8fDyEEBg4ciPT0dOzcuRNJSUlo3749evfujczMTABATk4OBgwYgF9//RXHjh1DYGAgBg0ahCtXruhsY8GCBfDy8kJSUhLef//9cuuTm5uLoKAgeHp6IikpCdHR0YiKinqifbtw4QJ+/PFH/Pzzz4iNjUVycjImTZoEACgqKkJwcDD8/Pxw/PhxHDhwAOPHj6/xu+fYR4dqzbO+nk5/P+xDQc+j1q1bY9asWQCApk2b4rPPPsNvv/0GQ0NDnDhxAhkZGVAqlQCAhQsXYuvWrdi4cSPGjx+PNm3aoE2bNtK6Zs+ejS1btmDbtm2YPHmyNL1Xr16VDitr165FcXExvvvuO5iZmaFly5a4du0a/vGPf1R53x48eIBVq1ahfv36AIBPP/0UAwcOxKJFi2BiYgKNRoOgoCA0adIEANC8efMqb6Oq2KJDRET0DLVu3VrnuYuLCzIyMpCUlIScnBzY2dnBwsJCeqSkpODixYsAHra+zJgxAy1atIC1tTUsLCxw5syZUi06HTp0qHR9Tp8+jTZt2ugMwOjr6/tE+9agQQMp5GjXU1JSgrNnz8LW1hYRERFSK9Qnn3yCtLS0J9pOVbBFh4iI6BkyNjbWea5QKFBSUoKSkhK4uLhg7969pZbR9o9566238Msvv2DhwoV44YUXoFKp8NJLL5XqcGxubl7p+gghKixjYGBQqlxlRizWXpbS/rty5UpMnToVsbGx+OGHH/Dee+8hPj4ePj4+la5vVTHoEBERPQfat2+P9PR0GBkZwd3dXW+Zffv2ISIiAiEhIQAe9tm5fPnyU223RYsW+P7775GXlyf9xtTBgwd1yjg4OODevXvIzc2VQpS+MXauXLmCGzduwNXVFQBw4MABGBgYwMPDQyrTrl07tGvXDjNnzoSvry/WrVtXo0GHl66IiIieA3369IGvry+Cg4Pxyy+/4PLly0hMTMR7772Ho0ePAgBeeOEFbN68GcnJyfjzzz8RFhaGkpKSp9puWFgYDAwMMHbsWJw6dQo7d+7EwoULdcp07twZZmZmePfdd3HhwgWsW7cOMTExpdZlamqKMWPG4M8//8S+ffswdepUhIaGwtnZGSkpKZg5cyYOHDiA1NRUxMXF4dy5czXeT4dBh4iI6DmgUCiwc+dO9OjRA6+++io8PDwwYsQIXL58GU5OTgCAJUuWwMbGBl26dMGgQYMQGBiI9u3bP9V2LSws8PPPP+PUqVNo164d/vnPf2LevHk6ZWxtbbFmzRrs3LkTrVq1wvr163Vui9d64YUXMHToUAwYMAABAQHw8vLCF198AeDhj3SeOXMGL774Ijw8PDB+/HhMnjwZr7/++lPVvyIKUZmLczKVnZ0NtVoNjUYDKyur2q7O3w7vuqKaxruu5OnBgwdISUlBo0aNYGpqWtvVof+Kjo7G1q1bq+1nI8o7z1X5/maLDhEREckWgw4REZGMzZkzR+d29Ucf/fv3r+3q1TjedUVERCRjEyZMQGhoqN552rusqkN0dLTefju1jUGHiIhIxmxtbWFra1vb1ag1vHRFREREssWgQ0RERLLFS1dEJF/R6tquAdUECzeg6yIgIw8wqtlfvq6Qa7va3T5ViC06REREJFsMOkRERCRbDDpERER1wN69e6FQKHD37t3arkqdwj46REQkD1/7P9vtjd/7TDfXpUsXpKWlQa1m37OqYNAhIiKqA0xMTODs7Fzb1ahzeOmKiIjoGXB3d8fSpUt1prVt21YaTVihUODbb79FSEgIzMzM0LRpU2zbtk0qq+/SVUxMDBo0aAAzMzOEhIRg0aJFsLa2luZHREQgODhYZ5uRkZHw9/eXngshMH/+fDRu3BgqlQpt2rTBxo0bq2mvax+DDhER0XPigw8+QGhoKI4fP44BAwZg1KhRyMzM1Fv20KFDePXVVzFx4kQkJyejZ8+emD17dpW3+d5772HlypVYvnw5/vrrL7z55pt4+eWXkZCQ8LS781zgpSsiIqLnREREBEaOHAng4Y9xfvrppzh8+DD69etXquwnn3yCwMBAvPPOOwAADw8PJCYmIjY2ttLby83NxeLFi7F79274+voCABo3boz9+/fjq6++gp+fXzXsVe1i0CEiInpOtG7dWvq/ubk5LC0tkZGRobfs6dOnERISojPN19e3SkHn1KlTePDgAfr27aszvaCgAO3ayWMwRAYdIiKiZ8DAwABCCJ1phYWFOs+NjY11nisUCpSUlOhd3+PrepJtate9Y8cO1KtXT6ecUqmscP11AYMOERHRM+Dg4IC0tDTpeXZ2NlJSUp54fS1atMDBgwd1pj3+3MHBASdPntSZlpycLAWqFi1aQKlU4sqVK7K4TKUPgw4REdEz0KtXL8TExGDQoEGwsbHB+++/D0NDwyde39SpU9GlSxfMnz8fwcHBiIuLK3XZqlevXliwYAFWr14NX19frFmzBidPnpQuS1laWiIqKgpvvvkmSkpK0K1bN2RnZyMxMREWFhYYM2bMU+3z84B3XRERET0DM2fORI8ePRAUFIQBAwYgODgYTZo0eeL1+fj44Ntvv8Wnn36Ktm3bIi4uDu+9955OmcDAQLz//vuYMWMGOnbsiHv37mH06NE6ZT766CP861//wty5c9G8eXMEBgbi559/RqNGjZ64bs8ThajMRT6Zys7OhlqthkajgZWVVW1X52/H/Z0dtV0FkrnLpmG1XQWqAQ8s3JDSdREa1XOAKX+9XEdMTAwiIyNl8TMRDx48QEpKCho1agRTU1OdeVX5/maLDhEREckWgw4RERHJFoMOERGRTERERMjislV1qlLQmTt3Ljp27AhLS0s4OjoiODgYZ8+e1SkjhEB0dDRcXV2hUqng7++Pv/76S6dMfn4+pkyZAnt7e5ibm2Pw4MG4du2aTpmsrCyEh4dDrVZDrVYjPDy81Mm7cuUKBg0aBHNzc9jb22Pq1KkoKCioyi4RERGRjFUp6CQkJGDSpEk4ePAg4uPjUVRUhICAAOTm5kpl5s+fj8WLF+Ozzz7DkSNH4OzsjL59++LevXtSmcjISGzZsgUbNmzA/v37kZOTg6CgIBQXF0tlwsLCkJycjNjYWMTGxiI5ORnh4eHS/OLiYgwcOBC5ubnYv38/NmzYgE2bNmH69OlPczyIiIhIRp7qrqtbt27B0dERCQkJ6NGjB4QQcHV1RWRkJN5++20AD1tvnJycMG/ePLz++uvQaDRwcHDA999/j+HDhwMAbty4ATc3N+zcuROBgYE4ffq0NBBS586dATwcBMnX1xdnzpyBp6cndu3ahaCgIFy9ehWurq4AgA0bNiAiIgIZGRmVuouKd13VLt51RTWNd13J0wPzekjpthgNXR1hZsy7ruTq/v37SE1Nfeq7rp5qwECNRgMAsLW1BQCkpKQgPT0dAQEBUhmlUgk/Pz8kJibi9ddfR1JSEgoLC3XKuLq6wsvLC4mJiQgMDMSBAwegVqulkAM8HC9ArVYjMTERnp6eOHDgALy8vKSQAzwcLyA/Px9JSUno2bNnqfrm5+cjPz9fep6dnf00u09ERLXA5P5NGORl4kaWFRzUpjAxABS1lXcePKilDcuXEAIFBQW4desWDAwMYGJi8lTre+KgI4TAtGnT0K1bN3h5eQEA0tPTAQBOTk46ZZ2cnJCamiqVMTExgY2NTaky2uXT09Ph6OhYapuOjo46ZR7fjo2NDUxMTKQyj5s7dy4++OCDqu4qERE9RwxEERodfh9pzV7FDYe2gEEtDvKf++Q/4UDlMzMzQ4MGDWBg8HT3TT3xq2Py5Mk4fvw49u/fX2qe4rFoLYQoNe1xj5fRV/5Jyjxq5syZmDZtmvQ8Ozsbbm5u5daLiIiePyYPbqNB8gIUmVih2Niy9pp0Jh+tne3KnKGhIYyMjCrMDpXxREFnypQp2LZtG37//XfUr19fmu7s7AzgYWuLi4uLND0jI0NqfXF2dkZBQQGysrJ0WnUyMjLQpUsXqczNmzdLbffWrVs66zl06JDO/KysLBQWFpZq6dFSKpWy+TVWIqK/OwUEjAs0MC7Q1F4lHus7Qs+fKrUHCSEwefJkbN68Gbt37y71OxiNGjWCs7Mz4uPjpWkFBQVISEiQQoy3tzeMjY11yqSlpeHkyZNSGV9fX2g0Ghw+fFgqc+jQIWg0Gp0yJ0+e1Pkl2Li4OCiVSnh7e1dlt4iIiEimqtSiM2nSJKxbtw7//ve/YWlpKfWFUavVUKlUUCgUiIyMxJw5c9C0aVM0bdoUc+bMgZmZGcLCwqSyY8eOxfTp02FnZwdbW1tERUWhVatW6NOnDwCgefPm6NevH8aNG4evvvoKADB+/HgEBQXB09MTABAQEIAWLVogPDwcCxYsQGZmJqKiojBu3DjeQUVEREQAqhh0li9fDgDw9/fXmb5y5UpEREQAAGbMmIG8vDxMnDgRWVlZ6Ny5M+Li4mBpaSmVX7JkCYyMjBAaGoq8vDz07t0bMTExOj9Xv3btWkydOlW6O2vw4MH47LPPpPmGhobYsWMHJk6ciK5du0KlUiEsLAwLFy6s0gEgIiIi+eKvl3McnVrDcXSopnEcHapx0bXYP+hvjL9eTkRERAQGHSIiIpIxBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpItBh0iIiKSLQYdIiIiki0GHSIiIpKtKged33//HYMGDYKrqysUCgW2bt2qMz8iIgIKhULn4ePjo1MmPz8fU6ZMgb29PczNzTF48GBcu3ZNp0xWVhbCw8OhVquhVqsRHh6Ou3fv6pS5cuUKBg0aBHNzc9jb22Pq1KkoKCio6i4RERGRTFU56OTm5qJNmzb47LPPyizTr18/pKWlSY+dO3fqzI+MjMSWLVuwYcMG7N+/Hzk5OQgKCkJxcbFUJiwsDMnJyYiNjUVsbCySk5MRHh4uzS8uLsbAgQORm5uL/fv3Y8OGDdi0aROmT59e1V0iIiIimTKq6gL9+/dH//79yy2jVCrh7Oysd55Go8GKFSvw/fffo0+fPgCANWvWwM3NDb/++isCAwNx+vRpxMbG4uDBg+jcuTMA4JtvvoGvry/Onj0LT09PxMXF4dSpU7h69SpcXV0BAIsWLUJERAT+7//+D1ZWVlXdNSIiIpKZGumjs3fvXjg6OsLDwwPjxo1DRkaGNC8pKQmFhYUICAiQprm6usLLywuJiYkAgAMHDkCtVkshBwB8fHygVqt1ynh5eUkhBwACAwORn5+PpKQkvfXKz89Hdna2zoOIiIjkq9qDTv/+/bF27Vrs3r0bixYtwpEjR9CrVy/k5+cDANLT02FiYgIbGxud5ZycnJCeni6VcXR0LLVuR0dHnTJOTk46821sbGBiYiKVedzcuXOlPj9qtRpubm5Pvb9ERET0/KrypauKDB8+XPq/l5cXOnTogIYNG2LHjh0YOnRomcsJIaBQKKTnj/7/aco8aubMmZg2bZr0PDs7m2GHiIhIxmr89nIXFxc0bNgQ58+fBwA4OzujoKAAWVlZOuUyMjKkFhpnZ2fcvHmz1Lpu3bqlU+bxlpusrCwUFhaWaunRUiqVsLKy0nkQERGRfNV40Llz5w6uXr0KFxcXAIC3tzeMjY0RHx8vlUlLS8PJkyfRpUsXAICvry80Gg0OHz4slTl06BA0Go1OmZMnTyItLU0qExcXB6VSCW9v75reLSIiIqoDqnzpKicnBxcuXJCep6SkIDk5Gba2trC1tUV0dDRefPFFuLi44PLly3j33Xdhb2+PkJAQAIBarcbYsWMxffp02NnZwdbWFlFRUWjVqpV0F1bz5s3Rr18/jBs3Dl999RUAYPz48QgKCoKnpycAICAgAC1atEB4eDgWLFiAzMxMREVFYdy4cWypISIiIgBPEHSOHj2Knj17Ss+1fV7GjBmD5cuX48SJE1i9ejXu3r0LFxcX9OzZEz/88AMsLS2lZZYsWQIjIyOEhoYiLy8PvXv3RkxMDAwNDaUya9euxdSpU6W7swYPHqwzdo+hoSF27NiBiRMnomvXrlCpVAgLC8PChQurfhSIiIhIlhRCCFHblagt2dnZUKvV0Gg0bAWqBe7v7KjtKpDMXTYNq+0qkNxFa2q7Bn9LVfn+5m9dERERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbBnVdgWI6jLNgR9x/9wBFGZeg8LIBMp6zWHjFwFju/oAAFFchLv7vkfexaMo0qTDQGkO04ZtYO0XASNLOwBAcd49aPavRd7lYyjOvg0DlRXMPHxg3f1lGCjNS21TFBUi7ftpKMxIgUvEMpg4NS5VpjgvG2nfTUFxzh24vbEBBqYWZe6DKCpE1p4VyD39O0RRPkwbtoFt34kwsrKvpqNERFR72KJD9BQeXD0Jy/YD4fzyQjgN/wgoKcbNH99HScEDAIAoykdB+kWou4yAy5hP4BD8Lgozb+DW5o+kdRTn3EFxTiZser4Kl1c/g93ASORdSsKdnZ/o3WbW3u9gaGFbbr3u7FoGY0f3Su1D5m9f4/65A7AfPAPOo+ajpOABMjZ9AFFSXLmDQET0HGPQIXoKTqEfwqJVH5g4NISJY2PYDYhEcfYtFNy8AAAwUJrDacRsmDfvDmO7+lDWawbbvq+jIP0CirIzAAAmDu5wCHkXZi90hrGNC1QN28C6x2jcv3i4VNjIu3gUeSnHYNNzbJl1undsJ0oe5MCq09AK61+Sn4uc4/Gw6TUWKve2MHFqAvug6Si8lYoHl5Of/MAQET0nGHSIqlFJfi4AlHupqCT/PgAFDJTllcmFgYkZFAaG0rTi3Czcif0U9kHTYWCs1Ltcwe0r0PxnPeyDpkGhUFRY3/z0C0BJEUwbtZemGVnawdi+AfKvn6lweSKi5x2DDlE1EUIga/e3UNZvARMHd/1ligpwNyEG5i38YKA001umOC8bmsQNsGjbX2fdt3cshUW7/lC6NC1j3YW4vW0+rHu+CiMrx0rVuSQ3CzA0guFjwczQ3AbFuVmVWgcR0fOMQYeommTGf4mCjMuwHzRD73xRXIRb2+YDQsA2YKLeMiX595Hx0wcwtmsA664jpen3kn6GKLgPtc+wMreflRADYzs3WLTs+XQ7AgBCABU3CBERPfd41xVRNciM/xJ5Fw7BKexjvXcrieIi3Pr3xyi6mw6nkXP0tuaU5N9Hxo//goGJKRyH/hMKw/+9PR9cOY78G2dxZWGIzjJpqyJh3tIf9gOn4cGV4yi8lYrU+YN1ylxdFga173BYdx9VapsG5jZAcRGKH+TotOoU378LZb3mVT4ORETPGwYdoqcghEDWr1/i/rkDcBo5F8bWzqXLaENO1g04jZwLQ5VVqTIl+fdx88f3oTA0hsOL70NhZKIz37bPeJR0f1l6XpyTiYwf/wX7IW9D6eIJAHAIfheiKF8qU5B2Hnd2fQLnUfNgZO2it/5K5xcAAyM8SDkG8+bdAQBFOZkovH0FSv9Xqn5AqNrN3ZePzWcKceZ2CVRGCnRxM8S8Pkp42v+v/9bm04X4KqkASTdKcCdP4Njr5mjrbKh3fUIIDFh3H7EXirFluArBzYyleYPX30dyejEycgVsVAr0aWyEeX2UcLUs3fh/534J2nyZi+v3BLLetoS1adlNgPlFAlFxD7D+ZBHyigR6NzLCFwNNUd+KFxWo5vFVRvQUMuOXI+evvbAf9BYMTMxQnJOF4pwslBQ+DByipBi3ts5FQfoF2A+KAkpKpDKiuBDAf0POD+9DFObDrv8bEPl5/yvz37uujKwcYeLgLj2MbesBAIytXaQWJGMbF50yRtZOD6fbucHQ3BoAUHTvNq5/MwH5N84CeHhXmEXrvsjaswJ5l5NRcPMi7mxfCGOHhjB1b/usDiOVIyG1CJM6muDgWHPEh5uhqAQIWHMfuQVCKpNbINDVzQgf99HfSf1RSw8WQFHGdcme7ob4cZgKZydbYFOoChczS/DSj3l6y47d9gCtnfSHqcdFxj7AljNF2PCSCvtfMUdOgUDQuvsoLhEVL0z0lNiiQ/QUco7tBADcXD9TZ7rdgEhYtOqD4nu3kXfhEAAgbeVUnTJOI+fAtEFrFNy8gIK0h8HjxtfjdMrUm7ACRmqn6qtwSTGKMq/ptPzY9h6HLAND3P73PIiiApg2bA3HF9/UueOLak/sy7qDRq4cYgrHhTlISitGj4YPP8LD2zxsAbx8t6Tcdf2ZXozFBwtwZJw5XBbllJr/pu//glJDawO8000geEMeCosFjA3/F46WHynA3QcC//JTYteFonK3qXkgsOJYIb4PUaFP44f1XTNUBbclOfj1UjECX+DXENUsvsKInkLDt7eXO99I7VRhGdMGrSssU13r1becwsgEtn0nwLbvhCrVgWqH5r8Z1VZVtd7i9wsFRm7Kw2f9TeFsUXFjfmaewNoThejiZqgTck7dKsaHv+fj0GvmuJRVfrACgKS0YhSWAAFN/vd142ppAC9HAyReLWLQoRrHVxgRUR0hhMC0Xx6gWwNDeDlWrcXtzdgH6OJmiCGP9MnR5+34B/jsSAHuFwI+9Q2xfaRKmpdf9DAsLeirRAO1QaWCTnqOgIkhYPNYMHMyVyA9h5euqOaxjw4RUR0xeecDHL9ZjPUvqiou/IhtZwux+3IxlvYzrbDsW11NcOx1c8S9bAZDBTB66wMI8TCQzPwtH83tDfBya5MK1lIxAaASY1oSPTW26BAR1QFTduZh27ki/B5hXuW7lXanFONiZgmsP76nM/3FH/PQvUEB9kb8rx+QvZkB7M0ADzuguYMB3Jbk4OC1Yvi6GWF3ShFOZJRg44fZAB6GFQCwn38P/+xugg96lg5SzhYKFBQDWXlCp1UnI1egS30mHap5DDpERM8xIQSm7Hp419LeMWZoZFP1hvh3upngtfa6l6xaLc/FkkAlBnmUfSnrvw05yP/vT65tCjVDXtH/LjcduV6MV7c9wL5XzNDEVn+9vF0MYWwAxF8qQmjLh9tKu1eCkxklmN+HX0FU8/gqIyJ6jk3a+QDrThTi3yPMYKlUID3nYb8YtVIBlfHDFpHMPIErmhLcuPdw3tnbD/91tlDA2cLgv4/S626gNpCC0+HrxTh8vRjdGhjCxlSBS1kl+NfefDSxUcC3/sP+QI+Hmdv3H4ae5g6G0jg617NL0Hv1fawOUaFTPUOoTRUY284Y0+MewE6lgK1Kgaj4B2jlaIA+jXlnH9U8Bh0ioufY8qMPx1vyX3VfZ/rKIaaIaPuwr8y2s4V45d8PpHkjNj0c+2aWnwmi/SvulwMAKqOHAw/O2puP3AIBF0sF+jUxwoYXVVAaVf4SU2EJcPZOCe4X/q/lZ0k/UxgZPEDoxjzkFQr0bmyEmJEqGBrw0hXVPIXQ9jL7G8rOzoZarYZGo4GVVenRaqlmub+zo7arQDJ32TSstqtAchetqe0a/C1V5fubd10RERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWxVOej8/vvvGDRoEFxdXaFQKLB161ad+UIIREdHw9XVFSqVCv7+/vjrr790yuTn52PKlCmwt7eHubk5Bg8ejGvXrumUycrKQnh4ONRqNdRqNcLDw3H37l2dMleuXMGgQYNgbm4Oe3t7TJ06FQUFBVXdJSIiIpKpKged3NxctGnTBp999pne+fPnz8fixYvx2Wef4ciRI3B2dkbfvn1x7949qUxkZCS2bNmCDRs2YP/+/cjJyUFQUBCKi4ulMmFhYUhOTkZsbCxiY2ORnJyM8PBwaX5xcTEGDhyI3Nxc7N+/Hxs2bMCmTZswffr0qu4SERERyZRCCCGeeGGFAlu2bEFwcDCAh605rq6uiIyMxNtvvw3gYeuNk5MT5s2bh9dffx0ajQYODg74/vvvMXz4cADAjRs34Obmhp07dyIwMBCnT59GixYtcPDgQXTu3BkAcPDgQfj6+uLMmTPw9PTErl27EBQUhKtXr8LV1RUAsGHDBkRERCAjIwNWVlYV1j87OxtqtRoajaZS5al6ub+zo7arQDJ32TSstqtAchetqe0a/C1V5fu7WvvopKSkID09HQEBAdI0pVIJPz8/JCYmAgCSkpJQWFioU8bV1RVeXl5SmQMHDkCtVkshBwB8fHygVqt1ynh5eUkhBwACAwORn5+PpKSk6twtIiIiqqOMqnNl6enpAAAnJyed6U5OTkhNTZXKmJiYwMbGplQZ7fLp6elwdHQstX5HR0edMo9vx8bGBiYmJlKZx+Xn5yM/P196np2dXZXdIyIiojqmRu66UigUOs+FEKWmPe7xMvrKP0mZR82dO1fq3KxWq+Hm5lZunYiIiKhuq9ag4+zsDAClWlQyMjKk1hdnZ2cUFBQgKyur3DI3b94stf5bt27plHl8O1lZWSgsLCzV0qM1c+ZMaDQa6XH16tUn2EsiIiKqK6o16DRq1AjOzs6Ij4+XphUUFCAhIQFdunQBAHh7e8PY2FinTFpaGk6ePCmV8fX1hUajweHDh6Uyhw4dgkaj0Slz8uRJpKWlSWXi4uKgVCrh7e2tt35KpRJWVlY6DyIiIpKvKvfRycnJwYULF6TnKSkpSE5Ohq2tLRo0aIDIyEjMmTMHTZs2RdOmTTFnzhyYmZkhLOzh3Q9qtRpjx47F9OnTYWdnB1tbW0RFRaFVq1bo06cPAKB58+bo168fxo0bh6+++goAMH78eAQFBcHT0xMAEBAQgBYtWiA8PBwLFixAZmYmoqKiMG7cOAYYIiIiAvAEQefo0aPo2bOn9HzatGkAgDFjxiAmJgYzZsxAXl4eJk6ciKysLHTu3BlxcXGwtLSUllmyZAmMjIwQGhqKvLw89O7dGzExMTA0NJTKrF27FlOnTpXuzho8eLDO2D2GhobYsWMHJk6ciK5du0KlUiEsLAwLFy6s+lEgIiIiWXqqcXTqOo6jU7s4jg7VNI6jQzWO4+jUilobR4eIiIjoecKgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLLFoENERESyxaBDREREssWgQ0RERLJV7UEnOjoaCoVC5+Hs7CzNF0IgOjoarq6uUKlU8Pf3x19//aWzjvz8fEyZMgX29vYwNzfH4MGDce3aNZ0yWVlZCA8Ph1qthlqtRnh4OO7evVvdu0NERER1WI206LRs2RJpaWnS48SJE9K8+fPnY/Hixfjss89w5MgRODs7o2/fvrh3755UJjIyElu2bMGGDRuwf/9+5OTkICgoCMXFxVKZsLAwJCcnIzY2FrGxsUhOTkZ4eHhN7A4RERHVUUY1slIjI51WHC0hBJYuXYp//vOfGDp0KABg1apVcHJywrp16/D6669Do9FgxYoV+P7779GnTx8AwJo1a+Dm5oZff/0VgYGBOH36NGJjY3Hw4EF07twZAPDNN9/A19cXZ8+ehaenZ03sFhEREdUxNdKic/78ebi6uqJRo0YYMWIELl26BABISUlBeno6AgICpLJKpRJ+fn5ITEwEACQlJaGwsFCnjKurK7y8vKQyBw4cgFqtlkIOAPj4+ECtVktliIiIiKq9Radz585YvXo1PDw8cPPmTcyePRtdunTBX3/9hfT0dACAk5OTzjJOTk5ITU0FAKSnp8PExAQ2NjalymiXT09Ph6OjY6ltOzo6SmX0yc/PR35+vvQ8Ozv7yXaSiIiI6oRqDzr9+/eX/t+qVSv4+vqiSZMmWLVqFXx8fAAACoVCZxkhRKlpj3u8jL7yFa1n7ty5+OCDDyq1H0RERFT31fjt5ebm5mjVqhXOnz8v9dt5vNUlIyNDauVxdnZGQUEBsrKyyi1z8+bNUtu6detWqdaiR82cORMajUZ6XL169an2jYiIiJ5vNR508vPzcfr0abi4uKBRo0ZwdnZGfHy8NL+goAAJCQno0qULAMDb2xvGxsY6ZdLS0nDy5EmpjK+vLzQaDQ4fPiyVOXToEDQajVRGH6VSCSsrK50HERERyVe1X7qKiorCoEGD0KBBA2RkZGD27NnIzs7GmDFjoFAoEBkZiTlz5qBp06Zo2rQp5syZAzMzM4SFhQEA1Go1xo4di+nTp8POzg62traIiopCq1atpLuwmjdvjn79+mHcuHH46quvAADjx49HUFAQ77giIiIiSbUHnWvXrmHkyJG4ffs2HBwc4OPjg4MHD6Jhw4YAgBkzZiAvLw8TJ05EVlYWOnfujLi4OFhaWkrrWLJkCYyMjBAaGoq8vDz07t0bMTExMDQ0lMqsXbsWU6dOle7OGjx4MD777LPq3h0iIiKqwxRCCFHblagt2dnZUKvV0Gg0vIxVC9zf2VHbVSCZu2waVttVILmL1tR2Df6WqvL9zd+6IiIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZYtAhIiIi2WLQISIiItli0CEiIiLZqvNB54svvkCjRo1gamoKb29v7Nu3r7arRERERM+JOh10fvjhB0RGRuKf//wnjh07hu7du6N///64cuVKbVeNiIiIngN1OugsXrwYY8eOxWuvvYbmzZtj6dKlcHNzw/Lly2u7akRERPQcqLNBp6CgAElJSQgICNCZHhAQgMTExFqqFRERET1PjGq7Ak/q9u3bKC4uhpOTk850JycnpKen610mPz8f+fn50nONRgMAyM7OrrmKUplK8u/XdhVI5rIVorarQHLH749aof3eFqLi93idDTpaCoVC57kQotQ0rblz5+KDDz4oNd3Nza1G6kZEtUtd2xUg+fuYr7LadO/ePajV5Z+DOht07O3tYWhoWKr1JiMjo1Qrj9bMmTMxbdo06XlJSQkyMzNhZ2dXZjgioropOzsbbm5uuHr1KqysrGq7OkRUjYQQuHfvHlxdXSssW2eDjomJCby9vREfH4+QkBBpenx8PIYMGaJ3GaVSCaVSqTPN2tq6JqtJRLXMysqKQYdIhipqydGqs0EHAKZNm4bw8HB06NABvr6++Prrr3HlyhVMmDChtqtGREREz4E6HXSGDx+OO3fu4MMPP0RaWhq8vLywc+dONGzYsLarRkRERM8BhahMl2UiojomPz8fc+fOxcyZM0tdsiaivw8GHSIiIpKtOjtgIBEREVFFGHSIiIhIthh0iIiISLYYdIiIiEi2GHSIiIhItur0ODpERFrXrl3D8uXLkZiYiPT0dCgUCjg5OaFLly6YMGECf9OO6G+Kt5cTUZ23f/9+9O/fH25ubggICICTkxOEEMjIyEB8fDyuXr2KXbt2oWvXrrVdVSJ6xhh0iKjO69ixI7p164YlS5bonf/mm29i//79OHLkyDOuGRHVNgYdIqrzVCoVkpOT4enpqXf+mTNn0K5dO+Tl5T3jmhFRbWNnZCKq81xcXJCYmFjm/AMHDsDFxeUZ1oiInhfsjExEdV5UVBQmTJiApKQk9O3bF05OTlAoFEhPT0d8fDy+/fZbLF26tLarSUS1gJeuiEgWfvjhByxZsgRJSUkoLi4GABgaGsLb2xvTpk1DaGhoLdeQiGoDgw4RyUphYSFu374NALC3t4exsXEt14iIahODDhEREckWOyMTERGRbDHoEBERkWwx6BAREZFsMegQUYViYmJgbW0tPY+Ojkbbtm1rrT5/B/7+/oiMjKztahDVeQw6RHVQREQEFAoFFAoFjI2N4eTkhL59++K7775DSUlJjW8/KioKv/32W7Wt7/EgVVeVFU62bt0KhUJRpXVt3rwZH330UTXVjOjvi0GHqI7q168f0tLScPnyZezatQs9e/bEG2+8gaCgIBQVFdXoti0sLGBnZ1ej2/i7s7W1haWlZW1Xg6jOY9AhqqOUSiWcnZ1Rr149tG/fHu+++y7+/e9/Y9euXYiJiQEAXL58GQqFAsnJydJyd+/ehUKhwN69ewEAe/fuhUKhwI4dO9CmTRuYmpqic+fOOHHiRJnb1nfp6rvvvkPLli2hVCrh4uKCyZMnS/MWL16MVq1awdzcHG5ubpg4cSJycnKk7b/yyivQaDRSK1V0dDQAoKCgADNmzEC9evVgbm6Ozp07S/UGgNTUVAwaNAg2NjYwNzdHy5YtsXPnTr11njlzJnx8fEpNb926NWbNmiXVpVOnTjA3N4e1tTW6du2K1NTUMo/Dk9Iev++//x7u7u5Qq9UYMWIE7t27J5V5vHUoIyMDgwYNgkqlQqNGjbB27Vq4u7tLIz5X5lwDwKlTpzBgwABYWFjAyckJ4eHh0rhDRHLEoEMkI7169UKbNm2wefPmKi/71ltvYeHChThy5AgcHR0xePBgFBYWVmrZ5cuXY9KkSRg/fjxOnDiBbdu24YUXXpDmGxgYYNmyZTh58iRWrVqF3bt3Y8aMGQCALl26YOnSpbCyskJaWhrS0tIQFRUFAHjllVfwn//8Bxs2bMDx48cxbNgw9OvXD+fPnwcATJo0Cfn5+fj9999x4sQJzJs3DxYWFnrrOGrUKBw6dAgXL16Upv311184ceIERo0ahaKiIgQHB8PPzw/Hjx/HgQMHMH78+CpfcqqsixcvYuvWrdi+fTu2b9+OhIQEfPzxx2WWj4iIwOXLl7F7925s3LgRX3zxBTIyMqq0zbS0NPj5+aFt27Y4evQoYmNjcfPmTY4aTbLG37oikplmzZrh+PHjVV5u1qxZ6Nu3LwBg1apVqF+/PrZs2VKpL8HZs2dj+vTpeOONN6RpHTt2lP7/aMtEo0aN8NFHH+Ef//gHvvjiC5iYmECtVkOhUMDZ2Vkqd/HiRaxfvx7Xrl2Dq6srgId9g2JjY7Fy5UrMmTMHV65cwYsvvohWrVoBABo3blxmHb28vNC6dWusW7cO77//PgBg7dq16NixIzw8PJCZmQmNRoOgoCA0adIEANC8efMK9/1JlZSUICYmRro8FR4ejt9++w3/93//V6rsuXPnsGvXLhw8eBCdO3cGAKxYsaLK9Vu+fDnat2+POXPmSNO+++47uLm54dy5c/Dw8HiKPSJ6PrFFh0hmhBBP1Arh6+sr/d/W1haenp44ffp0hctlZGTgxo0b6N27d5ll9uzZg759+6JevXqwtLTE6NGjcefOHeTm5pa5zB9//AEhBDw8PGBhYSE9EhISpFaZqVOnYvbs2ejatStmzZpVYcAbNWoU1q5dC+DhcVq/fj1GjRol7XNERAQCAwMxaNAgfPLJJ0hLS6tw/5+Uu7u7Th8cFxeXMltoTp8+DSMjI3To0EGa1qxZsyp34E5KSsKePXt0jmezZs0AQKeli0hOGHSIZOb06dNo1KgRgIeXjICHX+palb0cBaBSgUmlUpU7PzU1FQMGDICXlxc2bdqEpKQkfP755xXWpaSkBIaGhkhKSkJycrL0OH36ND755BMAwGuvvYZLly4hPDwcJ06cQIcOHfDpp5+Wuc6wsDCcO3cOf/zxBxITE3H16lWMGDFCmr9y5UocOHAAXbp0wQ8//AAPDw8cPHiwwmOgZWVlBY1GU2r63bt3YWVlpTPt8d/gUigUZd4xpz1/5Z2PypzrkpISDBo0SOd4Jicn4/z58+jRo0c5e0ZUdzHoEMnI7t27ceLECbz44osAAAcHBwDQaZl4tLPqox79Qs/KysK5c+ekv/bLY2lpCXd39zJvNz969CiKioqwaNEi+Pj4wMPDAzdu3NApY2JiIv3iuFa7du1QXFyMjIwMvPDCCzqPRy9xubm5YcKECdi8eTOmT5+Ob775psy61q9fHz169MDatWuxdu1a9OnTB05OTqW2O3PmTCQmJsLLywvr1q2r8BhoNWvWDEePHi01/ciRI/D09Kz0eh7XvHlzFBUV6az77NmzuHv3rvS8Mue6ffv2+Ouvv+Du7l7qmJqbmz9x/YieZww6RHVUfn4+0tPTcf36dfzxxx+YM2cOhgwZgqCgIIwePRrAw9YWHx8ffPzxxzh16hR+//13vPfee3rX9+GHH+K3337DyZMnERERAXt7ewQHB1eqLtHR0Vi0aBGWLVuG8+fP448//pBaVpo0aYKioiJ8+umnuHTpEr7//nt8+eWXOsu7u7sjJycHv/32G27fvo379+/Dw8MDo0aNwujRo7F582akpKTgyJEjmDdvnnRnVWRkJH755RekpKTgjz/+wO7duyvstzJq1Chs2LABP/30E15++WVpekpKCmbOnIkDBw4gNTUVcXFxOHfunLS+w4cPo1mzZrh+/XqZ6544cSIuXryISZMm4c8//8S5c+fw+eefY8WKFXjrrbcqdSz18fT0RL9+/TBu3DgcOnQISUlJeO2113Ra0ypzridNmoTMzEyMHDkShw8fxqVLlxAXF4dXX321VNAkkg1BRHXOmDFjBAABQBgZGQkHBwfRp08f8d1334ni4mKdsqdOnRI+Pj5CpVKJtm3biri4OAFA7NmzRwghxJ49ewQA8fPPP4uWLVsKExMT0bFjR5GcnCytY+XKlUKtVkvPZ82aJdq0aaOznS+//FJ4enoKY2Nj4eLiIqZMmSLNW7x4sXBxcREqlUoEBgaK1atXCwAiKytLKjNhwgRhZ2cnAIhZs2YJIYQoKCgQ//rXv4S7u7swNjYWzs7OIiQkRBw/flwIIcTkyZNFkyZNhFKpFA4ODiI8PFzcvn273GOXlZUllEqlMDMzE/fu3ZOmp6eni+DgYOHi4iJMTExEw4YNxb/+9S/peGqPU0pKSrnrP3r0qAgMDBSOjo7CyspKdOjQQaxfv16njL7jt2TJEtGwYUPpuZ+fn3jjjTek52lpaWLgwIFCqVSKBg0aiNWrV4uGDRuKJUuWSGUqOtdCCHHu3DkREhIirK2thUqlEs2aNRORkZGipKSk3P0iqqsUQjxyQZeI/nb27t2Lnj17IisrSxajE/+duLu7IzIykj8VQVQOXroiIiIi2WLQISIiItnipSsiIiKSLbboEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbDHoEBERkWwx6BAREZFsMegQERGRbP0/8J/C30R/0JwAAAAASUVORK5CYII=\n", "text/plain": "<Figure size 640x480 with 1 Axes>"}, "metadata": {}, "output_type": "display_data"}], "source": "dups_df = pd.DataFrame.from_dict({'near_dups': [dups_30], 'unique': [uniques]})\nax=dups_df.plot(kind = 'bar',y=['near_dups', 'unique'], fontsize=10, color=['C0', 'C1'], align='center', width=0.8, xlabel=\"Duplicates vs. Unique\")\nax.set_title('Social Media Influencer duplication analysis', fontsize=15)\nfor p in ax.patches:\n       ax.annotate(format(p.get_height(), '.1f'), \n                   (p.get_x() + p.get_width() / 2., p.get_height()/2), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points') "}, {"cell_type": "code", "execution_count": null, "id": "d7a67d5c-f6fc-4ca3-98af-eadb6f3e718f", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "6e7e86b7-cde3-4992-aae1-c92acd7a4e92", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "cda13fb8-52c5-47a9-8975-abb609d44590", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.13"}}, "nbformat": 4, "nbformat_minor": 5}